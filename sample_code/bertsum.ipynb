{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNbsuqrDVhBUiS2I6k3jijB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","cwd = os.getcwd()"],"metadata":{"id":"PV6t4yt3QmkM","executionInfo":{"status":"ok","timestamp":1664959423697,"user_tz":-420,"elapsed":300,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOovIAxxQDZX","executionInfo":{"status":"ok","timestamp":1664959434151,"user_tz":-420,"elapsed":10147,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"c6ccf3c5-becd-46c7-e49c-c8642818cc50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1x0d61LP9UAN389YN00z0Pv-7jQgirVg6\n","To: /content/bertsum_data.zip\n","100% 869M/869M [00:08<00:00, 99.5MB/s]\n"]}],"source":["try:\n","    f = open(cwd+\"/bertsum_data.zip\")\n","    # Do something with the file\n","    f.close()\n","except IOError:\n","    !gdown 1x0d61LP9UAN389YN00z0Pv-7jQgirVg6"]},{"cell_type":"code","source":["!git clone https://github.com/nlpyang/BertSum"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxlnYI5xSFzT","executionInfo":{"status":"ok","timestamp":1664959436208,"user_tz":-420,"elapsed":2076,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"1b4f63f1-e704-4296-fa35-59e8e4461d26"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'BertSum'...\n","remote: Enumerating objects: 301, done.\u001b[K\n","remote: Counting objects: 100% (293/293), done.\u001b[K\n","remote: Compressing objects: 100% (124/124), done.\u001b[K\n","remote: Total 301 (delta 165), reused 290 (delta 164), pack-reused 8\u001b[K\n","Receiving objects: 100% (301/301), 15.05 MiB | 18.95 MiB/s, done.\n","Resolving deltas: 100% (165/165), done.\n"]}]},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile(cwd+\"/bertsum_data.zip\", 'r') as zip_ref:\n","    zip_ref.extractall('/content/BertSum/bert_data/')"],"metadata":{"id":"JY_qif9SQsDR","executionInfo":{"status":"ok","timestamp":1664959455140,"user_tz":-420,"elapsed":18936,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch-pretrained-bert"],"metadata":{"id":"EPoKRzfgUiJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"id":"La_A9_MbU10c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyrouge"],"metadata":{"id":"ZCRtti9hU97Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch==1.1.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0LzkByFWeMZ","executionInfo":{"status":"ok","timestamp":1664960128669,"user_tz":-420,"elapsed":89731,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"6cc8f5b4-e431-4861-dcb6-be78b9c3a89a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.1.0\n","  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n","\u001b[K     |████████████████████████████████| 676.9 MB 3.9 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.1.0) (1.21.6)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.1.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.1.0\n"]}]},{"cell_type":"code","source":["!python /content/BertSum/src/train.py -mode train -encoder transformer -dropout 0.1 -bert_data_path /content/BertSum/bert_data/cnndm -model_path /content/BertSum//models/bert_transformer -lr 2e-3 -visible_gpus 0 -gpu_ranks 0 -world_size 1 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -decay_method noam -train_steps 50000 -accum_count 2 -log_file /content/BertSum/logs/bert_transformer -use_interval true -warmup_steps 10000 -ff_size 2048 -inter_layers 2 -heads 8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WohhIXNRRAgo","executionInfo":{"status":"ok","timestamp":1664963073578,"user_tz":-420,"elapsed":2901181,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"2b943894-3982-4a0e-9927-9111c8df8518"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-10-05 08:56:13,273 INFO] Device ID 0\n","[2022-10-05 08:56:13,274 INFO] Device cuda\n","[2022-10-05 08:56:13,494 INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","[2022-10-05 08:56:13,495 INFO] extracting archive file ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpea2260pw\n","[2022-10-05 08:56:17,776 INFO] Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","[2022-10-05 08:56:23,323 INFO] Summarizer(\n","  (bert): Bert(\n","    (model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): BertLayerNorm()\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (encoder): TransformerInterEncoder(\n","    (pos_emb): PositionalEncoding(\n","      (dropout): Dropout(p=0.1)\n","    )\n","    (transformer_inter): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1)\n","    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","    (wo): Linear(in_features=768, out_features=1, bias=True)\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","gpu_rank 0\n","[2022-10-05 08:56:23,412 INFO] * number of parameters: 120512513\n","[2022-10-05 08:56:23,412 INFO] Start training...\n","[2022-10-05 08:56:23,612 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.123.bert.pt, number of examples: 2001\n","[2022-10-05 08:57:22,344 INFO] Step 50/50000; xent: 4.22; lr: 0.0000001;  17 docs/s;     59 sec\n","[2022-10-05 08:58:27,045 INFO] Step 100/50000; xent: 3.74; lr: 0.0000002;  15 docs/s;    123 sec\n","[2022-10-05 08:59:31,146 INFO] Step 150/50000; xent: 3.57; lr: 0.0000003;  16 docs/s;    188 sec\n","[2022-10-05 09:00:34,412 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.91.bert.pt, number of examples: 1998\n","[2022-10-05 09:00:35,705 INFO] Step 200/50000; xent: 3.55; lr: 0.0000004;  16 docs/s;    252 sec\n","[2022-10-05 09:01:39,482 INFO] Step 250/50000; xent: 3.48; lr: 0.0000005;  16 docs/s;    316 sec\n","[2022-10-05 09:02:44,320 INFO] Step 300/50000; xent: 3.44; lr: 0.0000006;  15 docs/s;    381 sec\n","[2022-10-05 09:03:47,751 INFO] Step 350/50000; xent: 3.39; lr: 0.0000007;  16 docs/s;    444 sec\n","[2022-10-05 09:04:49,508 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.39.bert.pt, number of examples: 2000\n","[2022-10-05 09:04:51,965 INFO] Step 400/50000; xent: 3.32; lr: 0.0000008;  16 docs/s;    508 sec\n","[2022-10-05 09:05:56,465 INFO] Step 450/50000; xent: 3.32; lr: 0.0000009;  16 docs/s;    573 sec\n","[2022-10-05 09:07:00,944 INFO] Step 500/50000; xent: 3.17; lr: 0.0000010;  16 docs/s;    637 sec\n","[2022-10-05 09:08:05,351 INFO] Step 550/50000; xent: 3.19; lr: 0.0000011;  16 docs/s;    702 sec\n","[2022-10-05 09:09:06,515 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.6.bert.pt, number of examples: 2001\n","[2022-10-05 09:09:10,423 INFO] Step 600/50000; xent: 3.22; lr: 0.0000012;  16 docs/s;    767 sec\n","[2022-10-05 09:10:14,962 INFO] Step 650/50000; xent: 3.24; lr: 0.0000013;  16 docs/s;    831 sec\n","[2022-10-05 09:11:19,672 INFO] Step 700/50000; xent: 3.20; lr: 0.0000014;  16 docs/s;    896 sec\n","[2022-10-05 09:12:23,845 INFO] Step 750/50000; xent: 3.22; lr: 0.0000015;  16 docs/s;    960 sec\n","[2022-10-05 09:13:22,094 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.81.bert.pt, number of examples: 2000\n","[2022-10-05 09:13:28,567 INFO] Step 800/50000; xent: 3.17; lr: 0.0000016;  16 docs/s;   1025 sec\n","[2022-10-05 09:14:33,083 INFO] Step 850/50000; xent: 3.13; lr: 0.0000017;  16 docs/s;   1089 sec\n","[2022-10-05 09:15:37,117 INFO] Step 900/50000; xent: 3.12; lr: 0.0000018;  16 docs/s;   1154 sec\n","[2022-10-05 09:16:41,547 INFO] Step 950/50000; xent: 3.11; lr: 0.0000019;  16 docs/s;   1218 sec\n","[2022-10-05 09:17:38,670 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.98.bert.pt, number of examples: 2000\n","[2022-10-05 09:17:46,529 INFO] Step 1000/50000; xent: 3.11; lr: 0.0000020;  16 docs/s;   1283 sec\n","[2022-10-05 09:17:46,531 INFO] Saving checkpoint /content/BertSum//models/bert_transformer/model_step_1000.pt\n","[2022-10-05 09:18:56,574 INFO] Step 1050/50000; xent: 3.27; lr: 0.0000021;  14 docs/s;   1353 sec\n","[2022-10-05 09:20:00,878 INFO] Step 1100/50000; xent: 3.12; lr: 0.0000022;  16 docs/s;   1417 sec\n","[2022-10-05 09:21:05,360 INFO] Step 1150/50000; xent: 3.23; lr: 0.0000023;  16 docs/s;   1482 sec\n","[2022-10-05 09:21:59,474 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.93.bert.pt, number of examples: 1997\n","[2022-10-05 09:22:09,799 INFO] Step 1200/50000; xent: 3.16; lr: 0.0000024;  16 docs/s;   1546 sec\n","[2022-10-05 09:23:14,055 INFO] Step 1250/50000; xent: 3.11; lr: 0.0000025;  16 docs/s;   1610 sec\n","[2022-10-05 09:24:18,351 INFO] Step 1300/50000; xent: 3.12; lr: 0.0000026;  16 docs/s;   1675 sec\n","[2022-10-05 09:25:22,324 INFO] Step 1350/50000; xent: 3.10; lr: 0.0000027;  16 docs/s;   1739 sec\n","[2022-10-05 09:26:14,543 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.63.bert.pt, number of examples: 2001\n","[2022-10-05 09:26:27,517 INFO] Step 1400/50000; xent: 3.12; lr: 0.0000028;  16 docs/s;   1804 sec\n","[2022-10-05 09:27:31,897 INFO] Step 1450/50000; xent: 3.06; lr: 0.0000029;  16 docs/s;   1868 sec\n","[2022-10-05 09:28:36,060 INFO] Step 1500/50000; xent: 3.09; lr: 0.0000030;  16 docs/s;   1932 sec\n","[2022-10-05 09:29:40,690 INFO] Step 1550/50000; xent: 3.10; lr: 0.0000031;  16 docs/s;   1997 sec\n","[2022-10-05 09:30:30,822 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.15.bert.pt, number of examples: 1999\n","[2022-10-05 09:30:45,128 INFO] Step 1600/50000; xent: 3.16; lr: 0.0000032;  15 docs/s;   2062 sec\n","[2022-10-05 09:31:48,976 INFO] Step 1650/50000; xent: 3.10; lr: 0.0000033;  16 docs/s;   2125 sec\n","[2022-10-05 09:32:53,589 INFO] Step 1700/50000; xent: 3.08; lr: 0.0000034;  16 docs/s;   2190 sec\n","[2022-10-05 09:33:57,638 INFO] Step 1750/50000; xent: 3.10; lr: 0.0000035;  16 docs/s;   2254 sec\n","[2022-10-05 09:34:46,467 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.64.bert.pt, number of examples: 2001\n","[2022-10-05 09:35:01,964 INFO] Step 1800/50000; xent: 3.04; lr: 0.0000036;  16 docs/s;   2318 sec\n","[2022-10-05 09:36:06,395 INFO] Step 1850/50000; xent: 3.17; lr: 0.0000037;  15 docs/s;   2383 sec\n","[2022-10-05 09:37:11,216 INFO] Step 1900/50000; xent: 3.00; lr: 0.0000038;  16 docs/s;   2448 sec\n","[2022-10-05 09:38:15,424 INFO] Step 1950/50000; xent: 3.04; lr: 0.0000039;  15 docs/s;   2512 sec\n","[2022-10-05 09:39:02,016 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.28.bert.pt, number of examples: 2000\n","[2022-10-05 09:39:20,166 INFO] Step 2000/50000; xent: 3.04; lr: 0.0000040;  16 docs/s;   2577 sec\n","[2022-10-05 09:39:20,168 INFO] Saving checkpoint /content/BertSum//models/bert_transformer/model_step_2000.pt\n","[2022-10-05 09:40:30,314 INFO] Step 2050/50000; xent: 3.01; lr: 0.0000041;  14 docs/s;   2647 sec\n","[2022-10-05 09:41:34,531 INFO] Step 2100/50000; xent: 3.10; lr: 0.0000042;  16 docs/s;   2711 sec\n","[2022-10-05 09:42:37,833 INFO] Step 2150/50000; xent: 3.04; lr: 0.0000043;  15 docs/s;   2774 sec\n","[2022-10-05 09:43:24,439 INFO] Loading train dataset from /content/BertSum/bert_data/cnndm.train.32.bert.pt, number of examples: 1998\n","[2022-10-05 09:43:42,440 INFO] Step 2200/50000; xent: 3.05; lr: 0.0000044;  16 docs/s;   2839 sec\n","Traceback (most recent call last):\n","  File \"/content/BertSum/src/train.py\", line 340, in <module>\n","    train(args, device_id)\n","  File \"/content/BertSum/src/train.py\", line 272, in train\n","    trainer.train(train_iter_fct, args.train_steps)\n","  File \"/content/BertSum/src/models/trainer.py\", line 157, in train\n","    report_stats)\n","  File \"/content/BertSum/src/models/trainer.py\", line 325, in _gradient_accumulation\n","    (loss/loss.numel()).backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 107, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 93, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}]}]}