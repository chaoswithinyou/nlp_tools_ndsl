{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24232,"status":"ok","timestamp":1663395924288,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"},"user_tz":-420},"id":"dL72O0FtqJcD","outputId":"0028337a-3f66-4b01-be1a-46010da0e1bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (1.21.6)\n","Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["!pip install pytorch-nlp\n","from torchnlp.datasets import imdb_dataset\n","from tqdm import tqdm\n","import re\n","from nltk import tokenize\n","import nltk\n","import pickle\n","from google.colab import drive\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","import numpy as np\n","################################################################################\n","drive.mount('/content/drive', force_remount=True)\n","nltk.download('punkt')\n","train = imdb_dataset(train=True)\n","test = imdb_dataset(test=True)\n","################################################################################\n","def tokenizing(data, mode=0):\n","    if mode==1:\n","        text = ' '.join([s[\"text\"] for s in data])\n","    else:\n","        text = data\n","    text = text.replace('<br /><br />',' ')\n","    text = text.replace('\\x85','')\n","    text = text.lower()\n","    tokenized_sentence = re.compile('[.!?()]').split(text)\n","    tokenized_corpus = [None]*len(tokenized_sentence)\n","    if mode==1:\n","        for i in tqdm(range(len(tokenized_sentence))):\n","            tokenized_corpus[i] = tokenize.word_tokenize(tokenized_sentence[i])\n","    else:\n","        for i in range(len(tokenized_sentence)):\n","            tokenized_corpus[i] = tokenize.word_tokenize(tokenized_sentence[i])\n","    return tokenized_corpus\n","################################################################################\n","class MyDataset(Dataset):\n","  def __init__(self, x, y, z):\n","    self.data = x\n","    self.labels = y\n","    self.lengths = z\n","\n","  def __len__(self):\n","    return len(self.labels)\n","  \n","  def __getitem__(self, index):\n","    return self.data[index], self.labels[index], self.lengths[index]\n","################################################################################\n","def custom_collate_fn(data):\n","    \"\"\"\n","       data: is a list of tuples with (example, label, length)\n","             where 'example' is a tensor of arbitrary shape\n","             and label/length are scalars\n","    \"\"\"\n","    _, labels, lengths = zip(*data)\n","    max_len = max(lengths)\n","    fix_size = data[0][0].size(1)\n","    features = torch.zeros((len(data), 1, fix_size, max_len))\n","    labels = torch.tensor(labels)\n","    lengths = torch.tensor(lengths)\n","\n","    for i in range(len(data)):\n","      k, j = data[i][0][0].size(0), data[i][0][0].size(1)\n","      features[i][0] = torch.cat((data[i][0][0], torch.zeros((k, max_len - j))),1)\n","\n","    return features.float(), labels.long(), lengths.long()\n","################################################################################\n","class Accuracy:\n","    \"\"\"A class to keep track of the accuracy while training\"\"\"\n","    def __init__(self):\n","        self.correct = 0\n","        self.total = 0\n","        \n","    def reset(self):\n","        \"\"\"Resets the internal state\"\"\"\n","        self.correct = 0\n","        self.total = 0\n","        \n","    def update(self, outputs, labels):\n","        \"\"\"\n","        Updates the internal state to later compute the overall accuracy\n","        \n","        output: the output of the network for a batch\n","        labels: the target labels\n","        \"\"\"\n","        _, predicted = torch.max(outputs.data, 1) # predicted now contains the predicted class index/label\n","        \n","        self.total += labels.size(0)\n","        self.correct += (predicted == labels).sum().item() # .item() gets the number, not the tensor\n","        #self.correct += ((outputs.data > 0.5) == labels).sum().item()\n","\n","    def compute(self):\n","        return self.correct/self.total\n","################################################################################\n","def eval_accu():\n","  net.eval()\n","  eval_accuracy = Accuracy()\n","  eval_accuracy.reset()        \n","  with torch.no_grad():\n","      for eval_data in val_loader:\n","          # get the data points\n","          eval_inputs, eval_labels, eval_lengths = eval_data\n","          eval_inputs, eval_labels = eval_inputs.to(device), eval_labels.to(device)\n","          # forward the data through the network\n","          eval_outputs = net(eval_inputs.float())\n","          \n","          eval_accuracy.update(eval_outputs, eval_labels)\n","          \n","  print(\"\\nTesting Accuracy: {:.2f}%\".format(100 * eval_accuracy.compute()))\n","################################################################################\n","def vec(word):\n","  try:\n","    a = model.wv[word]\n","  except:\n","    a = np.zeros(300)\n","  return a"]},{"cell_type":"code","source":["model = pickle.load(open('/content/drive/MyDrive/NLP/w2v_model_gensim.p','rb'))"],"metadata":{"id":"qbiwDcCwOUNV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = pickle.load(open('/content/drive/MyDrive/NLP/glove-wiki-gigaword-300.p','rb'))"],"metadata":{"id":"qnAMsaoePzWU","executionInfo":{"status":"ok","timestamp":1663395928426,"user_tz":-420,"elapsed":4144,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["c = 0\n","for a in tqdm(train):\n","  doc = tokenize.word_tokenize(a['text'])\n","  if len(doc)<301:\n","    c+=1\n","c"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ey1ZMeZ9RzaL","executionInfo":{"status":"ok","timestamp":1663352993356,"user_tz":-420,"elapsed":53174,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"9bee0136-3dc8-478e-8ac1-7b1b07fd8476"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 25000/25000 [00:52<00:00, 474.85it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["17259"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYzOZkDAlceA","outputId":"17c019a1-1587-44ba-817a-034de2ce977c","executionInfo":{"status":"ok","timestamp":1663396025735,"user_tz":-420,"elapsed":97320,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/25000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:116: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","100%|██████████| 25000/25000 [01:34<00:00, 264.95it/s]\n"]}],"source":["random.shuffle(train)\n","vector_size = 300\n","x = torch.zeros((17259,1,300,300))\n","xindex = 0\n","y = []\n","z = []\n","for i in tqdm(range(25000)):\n","  doc = tokenize.word_tokenize(train[i]['text'])\n","  if len(doc)<301:\n","    x[xindex] = torch.cat((torch.reshape(torch.tensor(np.array([vec(word) for word in doc])), (1,vector_size, len(doc))),torch.zeros((1,300,300-len(doc)))),2)\n","    xindex += 1\n","    y.append(int(train[i]['sentiment']=='pos'))\n","    z.append(len(doc))\n","train_dataset = MyDataset(x,y,z)"]},{"cell_type":"code","source":["random.shuffle(test)\n","x = []\n","y = []\n","z = []\n","for i in tqdm(range(2500)):\n","  doc = tokenize.word_tokenize(test[i]['text'])\n","  if len(doc)<301:\n","    doc = tokenize.word_tokenize(test[i]['text'])\n","    x.append(torch.cat((torch.reshape(torch.tensor(np.array([vec(word) for word in doc])), (1,vector_size, len(doc))),torch.zeros((1,300,300-len(doc)))),2))\n","    y.append(int(test[i]['sentiment']=='pos'))\n","    z.append(len(doc))\n","val_dataset = MyDataset(x,y,z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWVFMOr2lL3_","executionInfo":{"status":"ok","timestamp":1663396033734,"user_tz":-420,"elapsed":7722,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"58b7fac6-08ca-42a0-a92b-27a479e7d089"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/2500 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:116: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","100%|██████████| 2500/2500 [00:07<00:00, 318.66it/s]\n"]}]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True, num_workers=2)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=50, shuffle=True, num_workers=2)"],"metadata":{"id":"deChIDGQQreH","executionInfo":{"status":"ok","timestamp":1663396033735,"user_tz":-420,"elapsed":47,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["net.eval()\n","i = 16\n","with torch.no_grad():\n","  a = F.softmax(net(train_dataset.data[i].to(device).float()),0)\n","print(a)\n","print(train_dataset.labels[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QIW0ZscG-k7T","executionInfo":{"status":"ok","timestamp":1663396259312,"user_tz":-420,"elapsed":351,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"722f07d9-9522-4824-fc47-c7df65ae0d52"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.6954, 0.3046], device='cuda:0')\n","0\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4229,"status":"ok","timestamp":1663396037920,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"},"user_tz":-420},"id":"R2XXwFPmm095"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (vector_size,2))\n","        self.conv2 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (vector_size,3))\n","        self.conv3 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (vector_size,4))\n","        self.conv4 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (vector_size,5))\n","        self.fc1 = nn.Linear(400, 2)\n","        self.dropout1 = nn.Dropout(0.30)\n","        self.dropout2 = nn.Dropout(0.30)\n","        self.dropout3 = nn.Dropout(0.30)\n","        self.dropout4 = nn.Dropout(0.30)\n","        self.dropout5 = nn.Dropout(0.30)\n","    def forward(self, x):\n","        x1 = F.relu(self.conv1(x))\n","        x1 = self.dropout1(F.max_pool2d(x1, (1,x1.size()[-1])))\n","        x2 = F.relu(self.conv2(x))\n","        x2 = self.dropout2(F.max_pool2d(x2, (1,x2.size()[-1])))\n","        x3 = F.relu(self.conv3(x))\n","        x3 = self.dropout3(F.max_pool2d(x3, (1,x3.size()[-1])))\n","        x4 = F.relu(self.conv4(x))\n","        x4 = self.dropout4(F.max_pool2d(x4, (1,x4.size()[-1])))\n","        x = torch.flatten(torch.cat((x1,x2,x3,x4),-3),start_dim=-3)\n","        x = self.fc1(self.dropout5(x))\n","        return x\n","\n","net = Net()\n","net = net.to(device)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":953},"id":"4u4HH-yEm3d2","outputId":"872fcaec-19d2-45c0-cd1b-baa76563ee52","executionInfo":{"status":"error","timestamp":1663396128733,"user_tz":-420,"elapsed":90847,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.01435|acc: 49.78%: 100%|██████████| 346/346 [00:19<00:00, 17.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 49.92%\n","\n","Starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.01391|acc: 55.31%: 100%|██████████| 346/346 [00:11<00:00, 29.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 49.92%\n","\n","Starting epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.01363|acc: 58.57%: 100%|██████████| 346/346 [00:11<00:00, 29.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 50.59%\n","\n","Starting epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.01322|acc: 61.60%: 100%|██████████| 346/346 [00:11<00:00, 29.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 50.99%\n","\n","Starting epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.01260|acc: 65.48%: 100%|██████████| 346/346 [00:11<00:00, 29.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 53.07%\n","\n","Starting epoch 6\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.01209|acc: 67.74%: 100%|██████████| 346/346 [00:11<00:00, 29.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 50.82%\n","\n","Starting epoch 7\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.01139|acc: 69.85%:   4%|▍         | 13/346 [00:00<00:14, 22.73it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-c94d099b73f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# forward the data through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# calculate the loss given the output of the network and the target labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-9cd9a5928c53>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.5)\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","net = net.float()\n","net.train()\n","live_accuracy = Accuracy()\n","\n","for epoch in range(100):  # loop over the dataset multiple times\n","    print(\"\\nStarting epoch {}\".format(epoch+1))\n","\n","    live_accuracy.reset()\n","    total = 0\n","    running_loss = 0.0\n","\n","    # to make a beautiful progress bar\n","    loader = tqdm(enumerate(train_loader), total=len(train_loader))\n","    for i, data in loader:\n","        # get the data points\n","        inputs, labels, lengths = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # zero the parameter gradients (else, they are accumulated)\n","        optimizer.zero_grad()\n","\n","        # forward the data through the network\n","        outputs = net(inputs.float())\n","        # calculate the loss given the output of the network and the target labels\n","        loss = criterion(outputs, labels)\n","        # calculate the gradients of the network w.r.t. its parameters\n","        loss.backward()\n","        # Let the optimiser take an optimization step using the calculated gradients\n","        optimizer.step()\n","        \n","        running_loss += loss\n","        total += outputs.size(0)\n","\n","        live_accuracy.update(outputs, labels)\n","        loader.set_description(\"loss: {:.5f}|acc: {:.2f}%\".format(running_loss/total,100 * live_accuracy.compute()))\n","    eval_accu()\n","    net.train()\n","\n","print('Finished Training')"]},{"cell_type":"code","source":["outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZII64-lKDXIc","executionInfo":{"status":"ok","timestamp":1663394740611,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"1df82df6-e224-4899-b29a-339c7ed846dc"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0815, -0.5144],\n","        [ 0.2936, -0.0418],\n","        [ 0.0778, -0.0859],\n","        [ 0.1929, -0.5197],\n","        [ 0.1572,  0.0132],\n","        [ 0.1573, -0.6022],\n","        [ 0.3199,  0.1860],\n","        [ 0.5097, -0.8992],\n","        [ 0.2845, -0.4515],\n","        [-0.0651, -0.5852],\n","        [ 0.1037, -0.4975],\n","        [ 0.2961, -0.5361],\n","        [-0.1337, -0.4059],\n","        [ 0.2122, -0.0481],\n","        [ 0.4725,  0.0370],\n","        [ 0.3058, -0.3289],\n","        [ 0.7525,  0.0973],\n","        [ 0.2638, -0.2552],\n","        [ 0.7091, -0.1995],\n","        [-0.0984, -0.5223],\n","        [-0.1585, -0.0996],\n","        [ 0.0875, -0.4442],\n","        [-0.0515, -0.2641],\n","        [-0.0311,  0.0681],\n","        [ 0.4020, -0.7152],\n","        [ 0.2946, -0.3320],\n","        [ 0.3060, -0.3803],\n","        [ 0.3780, -0.6711],\n","        [-0.2936, -0.6758],\n","        [-0.1163, -0.4441],\n","        [ 0.0651,  0.1365],\n","        [ 0.1517, -0.2749],\n","        [ 0.2903, -0.3572],\n","        [ 0.6116, -0.2276],\n","        [ 0.1154,  0.0687],\n","        [ 0.2862, -0.4624],\n","        [-0.1862, -0.0292],\n","        [-0.3108, -0.4750],\n","        [-0.6411, -0.2192],\n","        [ 0.2597, -0.3064],\n","        [-0.3719, -0.7439],\n","        [ 0.3548, -0.7658],\n","        [ 0.1148, -0.6936],\n","        [ 0.2197, -0.2769],\n","        [-0.1892, -0.2515],\n","        [ 0.7309, -0.0967],\n","        [ 0.3695,  0.0653],\n","        [-0.0997, -0.5983],\n","        [ 0.1942, -0.0875],\n","        [-0.0211, -0.3939]], device='cuda:0', grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["pickle.dump(net,open('/content/drive/MyDrive/NLP/imdb_sentiment.p','wb'))"],"metadata":{"id":"BkpPeqMfi_2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = pickle.load(open('/content/drive/MyDrive/NLP/imdb_sentiment.p','rb'))"],"metadata":{"id":"QTKCFS0EjLmA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLuV4Acmm6QU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663359197571,"user_tz":-420,"elapsed":9556,"user":{"displayName":"Lam","userId":"17841603162440265686"}},"outputId":"10e571e8-166d-49fc-899e-6d6b16fc837a"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 346/346 [00:09<00:00, 37.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Accuracy: 85.30%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["net.eval()\n","accuracy = Accuracy()\n","accuracy.reset()\n","# Gradients are calculated on the forward pass for every iteration.\n","# As we do not need gradients now, we can disable the calculation.\n","with torch.no_grad():\n","    for data in tqdm(train_loader):\n","        # get the data points\n","        inputs, labels, lengths = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # forward the data through the network\n","        outputs = net(inputs.float())\n","        \n","        accuracy.update(outputs, labels)\n","\n","print(\"Training Accuracy: {:.2f}%\".format(100 * accuracy.compute()))"]},{"cell_type":"code","source":["net.eval()\n","accuracy = Accuracy()\n","accuracy.reset()        \n","with torch.no_grad():\n","    for data in tqdm(val_loader):\n","        # get the data points\n","        inputs, labels, lengths = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # forward the data through the network\n","        outputs = net(inputs.float())\n","        \n","        accuracy.update(outputs, labels)\n","        \n","print(\"\\nTesting Accuracy: {:.2f}%\".format(100 * accuracy.compute()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTX3Ue_2QU1t","executionInfo":{"status":"ok","timestamp":1663394990436,"user_tz":-420,"elapsed":1867,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"472fd8f5-e99c-42ae-ef96-33c58ff42e8f"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 36/36 [00:01<00:00, 20.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 50.33%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1yYE4Wigl28XOxQhO-WOVW6-q5BzOMnl8","timestamp":1663185324787},{"file_id":"1mQAurto3EVGoG1RP2XU7I624AXaacgmx","timestamp":1660668415917},{"file_id":"1D1w4S3z06bVH05AqJwBa9aFf5CzcDiK4","timestamp":1660548913907}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}