{"cells":[{"cell_type":"markdown","source":["#Initial procedure"],"metadata":{"id":"h5_O0aEkL-eR"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"PV6t4yt3QmkM","executionInfo":{"status":"ok","timestamp":1665992495275,"user_tz":-420,"elapsed":372,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"outputs":[],"source":["import os\n","cwd = os.getcwd()"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17865,"status":"ok","timestamp":1666001804326,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"},"user_tz":-420},"id":"VSNz-gV1KcXn","outputId":"c6732223-3232-4ff0-94bc-62b01012ff18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","#!cp /content/corpus-cate-csv-2019-24-03.7z /content/drive/MyDrive/NLP"]},{"cell_type":"code","source":["from IPython.display import clear_output "],"metadata":{"id":"cDG4QCIMjWcQ","executionInfo":{"status":"ok","timestamp":1665992511958,"user_tz":-420,"elapsed":11,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["#Setup presumm"],"metadata":{"id":"iqrkv9UPLpZM"}},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2788,"status":"ok","timestamp":1666001510057,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"},"user_tz":-420},"id":"zxlnYI5xSFzT","outputId":"83e10901-a124-4ce7-e083-3a2a2e7439c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'PreSumm'...\n","remote: Enumerating objects: 291, done.\u001b[K\n","remote: Counting objects: 100% (77/77), done.\u001b[K\n","remote: Compressing objects: 100% (54/54), done.\u001b[K\n","remote: Total 291 (delta 47), reused 48 (delta 22), pack-reused 214\u001b[K\n","Receiving objects: 100% (291/291), 13.08 MiB | 16.92 MiB/s, done.\n","Resolving deltas: 100% (146/146), done.\n"]}],"source":["!git clone https://github.com/chaoswithinyou/PreSumm"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"rGYPpdNLz9_5","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1666001638899,"user_tz":-420,"elapsed":126891,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"3f5560a5-db0f-4a5f-cd23-7b8117e1896c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting multiprocess==0.70.9\n","  Downloading multiprocess-0.70.9.tar.gz (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 8.7 MB/s \n","\u001b[?25hCollecting numpy==1.17.2\n","  Downloading numpy-1.17.2-cp37-cp37m-manylinux1_x86_64.whl (20.3 MB)\n","\u001b[K     |████████████████████████████████| 20.3 MB 1.2 MB/s \n","\u001b[?25hCollecting pyrouge==0.1.3\n","  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 7.3 MB/s \n","\u001b[?25hCollecting transformers==2.10.0\n","  Downloading transformers-2.10.0-py3-none-any.whl (660 kB)\n","\u001b[K     |████████████████████████████████| 660 kB 46.0 MB/s \n","\u001b[?25hCollecting tensorboardX==1.9\n","  Downloading tensorboardX-1.9-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 58.8 MB/s \n","\u001b[?25hCollecting torch==1.1.0\n","  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n","\u001b[K     |████████████████████████████████| 676.9 MB 3.4 kB/s \n","\u001b[?25hCollecting pytorch-transformers==1.2.0\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[K     |████████████████████████████████| 176 kB 58.1 MB/s \n","\u001b[?25hRequirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from multiprocess==0.70.9->-r /content/PreSumm/requirements.txt (line 1)) (0.3.5.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (2022.6.2)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 59.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (4.64.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 58.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (2.23.0)\n","Collecting tokenizers==0.7.0\n","  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 37.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.9->-r /content/PreSumm/requirements.txt (line 5)) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.9->-r /content/PreSumm/requirements.txt (line 5)) (3.17.3)\n","Collecting boto3\n","  Downloading boto3-1.24.91-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 54.3 MB/s \n","\u001b[?25hCollecting botocore<1.28.0,>=1.27.91\n","  Downloading botocore-1.27.91-py3-none-any.whl (9.2 MB)\n","\u001b[K     |████████████████████████████████| 9.2 MB 36.6 MB/s \n","\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 58.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.91->boto3->pytorch-transformers==1.2.0->-r /content/PreSumm/requirements.txt (line 7)) (2.8.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (2022.9.24)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 55.3 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.10.0->-r /content/PreSumm/requirements.txt (line 4)) (1.2.0)\n","Building wheels for collected packages: multiprocess, pyrouge, sacremoses\n","  Building wheel for multiprocess (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for multiprocess: filename=multiprocess-0.70.9-py3-none-any.whl size=108057 sha256=188249c43812df283dc359bd3a81525b0b61135f3339f747cbcb25c202af55f4\n","  Stored in directory: /root/.cache/pip/wheels/83/2b/b4/50d7cae5b9069434454fd36da009832592af4fff58b51db8d9\n","  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191621 sha256=a1ea6b053fcd237c1fee8884040ebd6de648962fc741c1bbba616298199a570f\n","  Stored in directory: /root/.cache/pip/wheels/68/35/6a/ffb9a1f51b2b00fee42e7f67f5a5d8e10c67d048cda09ccd57\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=14c0c309399cd602c55efec9458c90734ac5f9cbf79150b47c23d0478773f54a\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built multiprocess pyrouge sacremoses\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, numpy, torch, tokenizers, sentencepiece, sacremoses, boto3, transformers, tensorboardX, pytorch-transformers, pyrouge, multiprocess\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.17.2 which is incompatible.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.17.2 which is incompatible.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.17.2 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.17.2 which is incompatible.\n","pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.17.2 which is incompatible.\n","plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.17.2 which is incompatible.\n","pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.17.2 which is incompatible.\n","numba 0.56.2 requires numpy<1.24,>=1.18, but you have numpy 1.17.2 which is incompatible.\n","kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.17.2 which is incompatible.\n","jaxlib 0.3.20+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.17.2 which is incompatible.\n","jax 0.3.21 requires numpy>=1.20, but you have numpy 1.17.2 which is incompatible.\n","gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.17.2 which is incompatible.\n","fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.1.0 which is incompatible.\n","cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.17.2 which is incompatible.\n","aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.17.2 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.24.91 botocore-1.27.91 jmespath-1.0.1 multiprocess-0.70.9 numpy-1.17.2 pyrouge-0.1.3 pytorch-transformers-1.2.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 tensorboardX-1.9 tokenizers-0.7.0 torch-1.1.0 transformers-2.10.0 urllib3-1.25.11\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","urllib3"]}}},"metadata":{}},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-b78206f801d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -r /content/PreSumm/requirements.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"]}],"source":["!pip install -r /content/PreSumm/requirements.txt\n","clear_output()"]},{"cell_type":"code","source":["!rm -rf /content/PreSumm"],"metadata":{"id":"1ur6NemJ9_O7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/NLP/cnndm_sample.train.0.bert.pt /content/PreSumm/bert_data"],"metadata":{"id":"3bpaLdFFMzpE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WohhIXNRRAgo"},"outputs":[],"source":["!python /content/PreSumm/src/train.py -other_bert phobert -task ext -mode train -bert_data_path /content/PreSumm/bert_data/cnndm_sample -model_path MODEL_PATH -lr 2e-3 -report_every 1 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -ext_dropout 0.1 -visible_gpus -1 -log_file /content/PreSumm/logs/ext_bert_cnndm -use_interval true -warmup_steps 10000 -max_pos 256"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bIQ-2Wtkldb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8549470e-e02a-499d-f7bd-07f20f9d4a09"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-10-10 01:07:09,988 INFO] Device ID 0\n","[2022-10-10 01:07:09,988 INFO] Device cuda\n","[2022-10-10 01:07:10,950 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/config.json from cache at ../temp/79491498b21ce305d6608cb48027449e179c04ccd8e9bba4a2d70cfd7a5ff8de.5b0cadb81413f220dedd6e1118bc44fa81aa0cdac6d9f9c2007d295cd3b67e6f\n","[2022-10-10 01:07:10,950 INFO] Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 64001\n","}\n","\n","[2022-10-10 01:07:10,989 INFO] loading weights file https://cdn.huggingface.co/vinai/phobert-base/pytorch_model.bin from cache at ../temp/24b36891c4f22e7d527b0b02d9e26312e659c562ff5c5e2234fb9247df41ca26.3acb65d6dcb44dd7bb1dbdeca984082fdc18ca1412f2f81a9cc7f0d2c23fe0f8\n","[2022-10-10 01:07:15,753 INFO] Weights from pretrained model not used in RobertaModel: ['roberta.embeddings.position_ids']\n","[2022-10-10 01:07:21,640 INFO] ExtSummarizer(\n","  (bert): Bert(\n","    (model): RobertaModel(\n","      (embeddings): RobertaEmbeddings(\n","        (word_embeddings): Embedding(64001, 768, padding_idx=1)\n","        (position_embeddings): Embedding(514, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (ext_layer): ExtTransformerEncoder(\n","    (pos_emb): PositionalEncoding(\n","      (dropout): Dropout(p=0.1)\n","    )\n","    (transformer_inter): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1)\n","    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","    (wo): Linear(in_features=768, out_features=1, bias=True)\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","gpu_rank 0\n","[2022-10-10 01:07:21,734 INFO] * number of parameters: 146225921\n","[2022-10-10 01:07:21,734 INFO] Start training...\n","[2022-10-10 01:07:21,852 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.237.bert.pt, number of examples: 1999\n","[2022-10-10 01:08:20,111 INFO] Step 50/50000; xent: 3.62; lr: 0.0000001;  26 docs/s;     58 sec\n","[2022-10-10 01:09:20,225 INFO] Step 100/50000; xent: 2.91; lr: 0.0000002;  24 docs/s;    118 sec\n","[2022-10-10 01:10:06,092 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.177.bert.pt, number of examples: 1999\n","[2022-10-10 01:10:22,266 INFO] Step 150/50000; xent: 2.84; lr: 0.0000003;  23 docs/s;    180 sec\n","[2022-10-10 01:11:25,234 INFO] Step 200/50000; xent: 2.81; lr: 0.0000004;  22 docs/s;    243 sec\n","[2022-10-10 01:12:28,652 INFO] Step 250/50000; xent: 2.87; lr: 0.0000005;  19 docs/s;    307 sec\n","[2022-10-10 01:13:10,735 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.93.bert.pt, number of examples: 1999\n","[2022-10-10 01:13:32,554 INFO] Step 300/50000; xent: 2.68; lr: 0.0000006;  23 docs/s;    371 sec\n","[2022-10-10 01:14:36,760 INFO] Step 350/50000; xent: 2.68; lr: 0.0000007;  23 docs/s;    435 sec\n","[2022-10-10 01:15:41,335 INFO] Step 400/50000; xent: 2.68; lr: 0.0000008;  22 docs/s;    499 sec\n","[2022-10-10 01:16:09,662 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.143.bert.pt, number of examples: 1997\n","[2022-10-10 01:16:45,770 INFO] Step 450/50000; xent: 2.67; lr: 0.0000009;  22 docs/s;    564 sec\n","[2022-10-10 01:17:49,747 INFO] Step 500/50000; xent: 2.75; lr: 0.0000010;  22 docs/s;    628 sec\n","[2022-10-10 01:18:54,022 INFO] Step 550/50000; xent: 2.75; lr: 0.0000011;  22 docs/s;    692 sec\n","[2022-10-10 01:19:12,026 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.150.bert.pt, number of examples: 1999\n","[2022-10-10 01:19:58,279 INFO] Step 600/50000; xent: 2.56; lr: 0.0000012;  23 docs/s;    756 sec\n","[2022-10-10 01:21:02,406 INFO] Step 650/50000; xent: 2.67; lr: 0.0000013;  22 docs/s;    821 sec\n","[2022-10-10 01:22:06,038 INFO] Step 700/50000; xent: 2.61; lr: 0.0000014;  22 docs/s;    884 sec\n","[2022-10-10 01:22:09,010 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.84.bert.pt, number of examples: 1999\n","[2022-10-10 01:23:10,625 INFO] Step 750/50000; xent: 2.72; lr: 0.0000015;  22 docs/s;    949 sec\n","[2022-10-10 01:24:14,501 INFO] Step 800/50000; xent: 2.66; lr: 0.0000016;  24 docs/s;   1013 sec\n","[2022-10-10 01:25:06,324 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.96.bert.pt, number of examples: 1999\n","[2022-10-10 01:25:19,145 INFO] Step 850/50000; xent: 2.65; lr: 0.0000017;  22 docs/s;   1077 sec\n","[2022-10-10 01:26:23,577 INFO] Step 900/50000; xent: 2.59; lr: 0.0000018;  24 docs/s;   1142 sec\n","[2022-10-10 01:27:27,584 INFO] Step 950/50000; xent: 2.63; lr: 0.0000019;  23 docs/s;   1206 sec\n","[2022-10-10 01:27:57,558 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.74.bert.pt, number of examples: 1999\n","[2022-10-10 01:28:32,341 INFO] Step 1000/50000; xent: 2.70; lr: 0.0000020;  22 docs/s;   1270 sec\n","[2022-10-10 01:28:32,351 INFO] Saving checkpoint MODEL_PATH/model_step_1000.pt\n","[2022-10-10 01:29:43,366 INFO] Step 1050/50000; xent: 2.58; lr: 0.0000021;  21 docs/s;   1342 sec\n","[2022-10-10 01:30:46,894 INFO] Step 1100/50000; xent: 2.66; lr: 0.0000022;  23 docs/s;   1405 sec\n","[2022-10-10 01:30:59,881 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.249.bert.pt, number of examples: 1988\n","[2022-10-10 01:31:50,780 INFO] Step 1150/50000; xent: 2.51; lr: 0.0000023;  23 docs/s;   1469 sec\n","[2022-10-10 01:32:54,925 INFO] Step 1200/50000; xent: 2.53; lr: 0.0000024;  24 docs/s;   1533 sec\n","[2022-10-10 01:33:47,828 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.55.bert.pt, number of examples: 1999\n","[2022-10-10 01:33:59,346 INFO] Step 1250/50000; xent: 2.55; lr: 0.0000025;  23 docs/s;   1597 sec\n","[2022-10-10 01:35:03,183 INFO] Step 1300/50000; xent: 2.56; lr: 0.0000026;  22 docs/s;   1661 sec\n","[2022-10-10 01:36:07,229 INFO] Step 1350/50000; xent: 2.62; lr: 0.0000027;  21 docs/s;   1725 sec\n","[2022-10-10 01:36:53,629 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.77.bert.pt, number of examples: 1999\n","[2022-10-10 01:37:11,576 INFO] Step 1400/50000; xent: 2.59; lr: 0.0000028;  22 docs/s;   1790 sec\n","[2022-10-10 01:38:15,700 INFO] Step 1450/50000; xent: 2.63; lr: 0.0000029;  23 docs/s;   1854 sec\n","[2022-10-10 01:39:19,769 INFO] Step 1500/50000; xent: 2.66; lr: 0.0000030;  22 docs/s;   1918 sec\n","[2022-10-10 01:39:54,298 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.248.bert.pt, number of examples: 1988\n","[2022-10-10 01:40:23,403 INFO] Step 1550/50000; xent: 2.55; lr: 0.0000031;  22 docs/s;   1982 sec\n","[2022-10-10 01:41:26,997 INFO] Step 1600/50000; xent: 2.47; lr: 0.0000032;  23 docs/s;   2045 sec\n","[2022-10-10 01:42:30,820 INFO] Step 1650/50000; xent: 2.54; lr: 0.0000033;  23 docs/s;   2109 sec\n","[2022-10-10 01:42:48,521 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.64.bert.pt, number of examples: 1999\n","[2022-10-10 01:43:34,710 INFO] Step 1700/50000; xent: 2.56; lr: 0.0000034;  23 docs/s;   2173 sec\n","[2022-10-10 01:44:38,913 INFO] Step 1750/50000; xent: 2.63; lr: 0.0000035;  23 docs/s;   2237 sec\n","[2022-10-10 01:45:43,103 INFO] Step 1800/50000; xent: 2.60; lr: 0.0000036;  22 docs/s;   2301 sec\n","[2022-10-10 01:45:43,508 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.173.bert.pt, number of examples: 1999\n","[2022-10-10 01:46:46,923 INFO] Step 1850/50000; xent: 2.58; lr: 0.0000037;  23 docs/s;   2365 sec\n","[2022-10-10 01:47:50,796 INFO] Step 1900/50000; xent: 2.64; lr: 0.0000038;  19 docs/s;   2429 sec\n","[2022-10-10 01:48:47,458 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.215.bert.pt, number of examples: 1999\n","[2022-10-10 01:48:54,891 INFO] Step 1950/50000; xent: 2.59; lr: 0.0000039;  23 docs/s;   2493 sec\n","[2022-10-10 01:49:59,202 INFO] Step 2000/50000; xent: 2.55; lr: 0.0000040;  24 docs/s;   2557 sec\n","[2022-10-10 01:49:59,212 INFO] Saving checkpoint MODEL_PATH/model_step_2000.pt\n","[2022-10-10 01:51:09,501 INFO] Step 2050/50000; xent: 2.65; lr: 0.0000041;  19 docs/s;   2628 sec\n","[2022-10-10 01:51:49,070 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.191.bert.pt, number of examples: 1999\n","[2022-10-10 01:52:13,343 INFO] Step 2100/50000; xent: 2.58; lr: 0.0000042;  23 docs/s;   2691 sec\n","[2022-10-10 01:53:17,455 INFO] Step 2150/50000; xent: 2.60; lr: 0.0000043;  22 docs/s;   2756 sec\n","[2022-10-10 01:54:21,276 INFO] Step 2200/50000; xent: 2.62; lr: 0.0000044;  21 docs/s;   2819 sec\n","[2022-10-10 01:54:53,692 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.228.bert.pt, number of examples: 1999\n","[2022-10-10 01:55:25,675 INFO] Step 2250/50000; xent: 2.64; lr: 0.0000045;  22 docs/s;   2884 sec\n","[2022-10-10 01:56:29,535 INFO] Step 2300/50000; xent: 2.57; lr: 0.0000046;  22 docs/s;   2948 sec\n","[2022-10-10 01:57:32,929 INFO] Step 2350/50000; xent: 2.71; lr: 0.0000047;  21 docs/s;   3011 sec\n","[2022-10-10 01:57:57,144 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.169.bert.pt, number of examples: 1999\n","[2022-10-10 01:58:36,852 INFO] Step 2400/50000; xent: 2.61; lr: 0.0000048;  22 docs/s;   3075 sec\n","[2022-10-10 01:59:41,099 INFO] Step 2450/50000; xent: 2.65; lr: 0.0000049;  21 docs/s;   3139 sec\n","[2022-10-10 02:00:44,812 INFO] Step 2500/50000; xent: 2.61; lr: 0.0000050;  23 docs/s;   3203 sec\n","[2022-10-10 02:01:01,342 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.8.bert.pt, number of examples: 1999\n","[2022-10-10 02:01:48,860 INFO] Step 2550/50000; xent: 2.66; lr: 0.0000051;  20 docs/s;   3267 sec\n","[2022-10-10 02:02:52,433 INFO] Step 2600/50000; xent: 2.58; lr: 0.0000052;  22 docs/s;   3331 sec\n","[2022-10-10 02:03:56,543 INFO] Step 2650/50000; xent: 2.63; lr: 0.0000053;  20 docs/s;   3395 sec\n","[2022-10-10 02:04:17,356 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.28.bert.pt, number of examples: 1999\n","[2022-10-10 02:05:00,653 INFO] Step 2700/50000; xent: 2.60; lr: 0.0000054;  22 docs/s;   3459 sec\n","[2022-10-10 02:06:04,295 INFO] Step 2750/50000; xent: 2.68; lr: 0.0000055;  22 docs/s;   3522 sec\n","[2022-10-10 02:07:07,733 INFO] Step 2800/50000; xent: 2.56; lr: 0.0000056;  23 docs/s;   3586 sec\n","[2022-10-10 02:07:14,512 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.92.bert.pt, number of examples: 1999\n","[2022-10-10 02:08:12,427 INFO] Step 2850/50000; xent: 2.54; lr: 0.0000057;  23 docs/s;   3651 sec\n","[2022-10-10 02:09:16,073 INFO] Step 2900/50000; xent: 2.59; lr: 0.0000058;  23 docs/s;   3714 sec\n","[2022-10-10 02:10:09,878 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.190.bert.pt, number of examples: 1999\n","[2022-10-10 02:10:20,198 INFO] Step 2950/50000; xent: 2.55; lr: 0.0000059;  22 docs/s;   3778 sec\n","[2022-10-10 02:11:24,253 INFO] Step 3000/50000; xent: 2.65; lr: 0.0000060;  21 docs/s;   3842 sec\n","[2022-10-10 02:11:24,264 INFO] Saving checkpoint MODEL_PATH/model_step_3000.pt\n","[2022-10-10 02:12:34,271 INFO] Step 3050/50000; xent: 2.50; lr: 0.0000061;  21 docs/s;   3912 sec\n","[2022-10-10 02:13:17,979 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.98.bert.pt, number of examples: 1998\n","[2022-10-10 02:13:38,466 INFO] Step 3100/50000; xent: 2.57; lr: 0.0000062;  23 docs/s;   3977 sec\n","[2022-10-10 02:14:42,809 INFO] Step 3150/50000; xent: 2.52; lr: 0.0000063;  24 docs/s;   4041 sec\n","[2022-10-10 02:15:46,568 INFO] Step 3200/50000; xent: 2.44; lr: 0.0000064;  23 docs/s;   4105 sec\n","[2022-10-10 02:16:07,390 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.254.bert.pt, number of examples: 1998\n","[2022-10-10 02:16:50,792 INFO] Step 3250/50000; xent: 2.48; lr: 0.0000065;  24 docs/s;   4169 sec\n","[2022-10-10 02:17:54,731 INFO] Step 3300/50000; xent: 2.48; lr: 0.0000066;  23 docs/s;   4233 sec\n","[2022-10-10 02:18:57,915 INFO] Step 3350/50000; xent: 2.46; lr: 0.0000067;  24 docs/s;   4296 sec\n","[2022-10-10 02:18:58,275 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.12.bert.pt, number of examples: 1999\n","[2022-10-10 02:20:02,162 INFO] Step 3400/50000; xent: 2.67; lr: 0.0000068;  21 docs/s;   4360 sec\n","[2022-10-10 02:21:06,225 INFO] Step 3450/50000; xent: 2.54; lr: 0.0000069;  23 docs/s;   4424 sec\n","[2022-10-10 02:21:59,091 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.139.bert.pt, number of examples: 1999\n","[2022-10-10 02:22:10,785 INFO] Step 3500/50000; xent: 2.55; lr: 0.0000070;  23 docs/s;   4489 sec\n","[2022-10-10 02:23:14,402 INFO] Step 3550/50000; xent: 2.61; lr: 0.0000071;  21 docs/s;   4553 sec\n","[2022-10-10 02:24:18,387 INFO] Step 3600/50000; xent: 2.50; lr: 0.0000072;  23 docs/s;   4617 sec\n","[2022-10-10 02:24:59,721 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.91.bert.pt, number of examples: 1999\n","[2022-10-10 02:25:23,049 INFO] Step 3650/50000; xent: 2.51; lr: 0.0000073;  22 docs/s;   4681 sec\n","[2022-10-10 02:26:26,774 INFO] Step 3700/50000; xent: 2.56; lr: 0.0000074;  22 docs/s;   4745 sec\n","[2022-10-10 02:27:30,653 INFO] Step 3750/50000; xent: 2.49; lr: 0.0000075;  22 docs/s;   4809 sec\n","[2022-10-10 02:27:57,928 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.235.bert.pt, number of examples: 1997\n","[2022-10-10 02:28:35,177 INFO] Step 3800/50000; xent: 2.48; lr: 0.0000076;  25 docs/s;   4873 sec\n","[2022-10-10 02:29:38,730 INFO] Step 3850/50000; xent: 2.46; lr: 0.0000077;  24 docs/s;   4937 sec\n","[2022-10-10 02:30:41,742 INFO] Step 3900/50000; xent: 2.50; lr: 0.0000078;  24 docs/s;   5000 sec\n","[2022-10-10 02:30:42,099 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.172.bert.pt, number of examples: 1999\n","[2022-10-10 02:31:46,061 INFO] Step 3950/50000; xent: 2.49; lr: 0.0000079;  24 docs/s;   5064 sec\n","[2022-10-10 02:32:49,801 INFO] Step 4000/50000; xent: 2.50; lr: 0.0000080;  23 docs/s;   5128 sec\n","[2022-10-10 02:32:49,812 INFO] Saving checkpoint MODEL_PATH/model_step_4000.pt\n","[2022-10-10 02:33:44,856 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.111.bert.pt, number of examples: 1999\n","[2022-10-10 02:34:00,032 INFO] Step 4050/50000; xent: 2.54; lr: 0.0000081;  19 docs/s;   5198 sec\n","[2022-10-10 02:35:03,911 INFO] Step 4100/50000; xent: 2.42; lr: 0.0000082;  24 docs/s;   5262 sec\n","[2022-10-10 02:36:07,968 INFO] Step 4150/50000; xent: 2.46; lr: 0.0000083;  23 docs/s;   5326 sec\n","[2022-10-10 02:36:38,495 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.86.bert.pt, number of examples: 1999\n","[2022-10-10 02:37:12,024 INFO] Step 4200/50000; xent: 2.51; lr: 0.0000084;  23 docs/s;   5390 sec\n","[2022-10-10 02:38:16,351 INFO] Step 4250/50000; xent: 2.47; lr: 0.0000085;  23 docs/s;   5454 sec\n","[2022-10-10 02:39:20,361 INFO] Step 4300/50000; xent: 2.56; lr: 0.0000086;  23 docs/s;   5519 sec\n","[2022-10-10 02:39:30,646 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.127.bert.pt, number of examples: 1999\n","[2022-10-10 02:40:24,377 INFO] Step 4350/50000; xent: 2.37; lr: 0.0000087;  23 docs/s;   5583 sec\n","[2022-10-10 02:41:28,199 INFO] Step 4400/50000; xent: 2.47; lr: 0.0000088;  23 docs/s;   5646 sec\n","[2022-10-10 02:42:29,795 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.122.bert.pt, number of examples: 1999\n","[2022-10-10 02:42:32,337 INFO] Step 4450/50000; xent: 2.60; lr: 0.0000089;  22 docs/s;   5710 sec\n","[2022-10-10 02:43:36,450 INFO] Step 4500/50000; xent: 2.49; lr: 0.0000090;  22 docs/s;   5775 sec\n","[2022-10-10 02:44:40,327 INFO] Step 4550/50000; xent: 2.57; lr: 0.0000091;  23 docs/s;   5838 sec\n","[2022-10-10 02:45:30,383 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.103.bert.pt, number of examples: 1999\n","[2022-10-10 02:45:44,515 INFO] Step 4600/50000; xent: 2.49; lr: 0.0000092;  22 docs/s;   5903 sec\n","[2022-10-10 02:46:48,009 INFO] Step 4650/50000; xent: 2.52; lr: 0.0000093;  24 docs/s;   5966 sec\n","[2022-10-10 02:47:52,022 INFO] Step 4700/50000; xent: 2.69; lr: 0.0000094;  20 docs/s;   6030 sec\n","[2022-10-10 02:48:28,251 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.219.bert.pt, number of examples: 1999\n","[2022-10-10 02:48:56,252 INFO] Step 4750/50000; xent: 2.53; lr: 0.0000095;  23 docs/s;   6094 sec\n","[2022-10-10 02:49:59,828 INFO] Step 4800/50000; xent: 2.58; lr: 0.0000096;  23 docs/s;   6158 sec\n","[2022-10-10 02:51:03,790 INFO] Step 4850/50000; xent: 2.74; lr: 0.0000097;  21 docs/s;   6222 sec\n","[2022-10-10 02:51:33,617 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.45.bert.pt, number of examples: 1999\n","[2022-10-10 02:52:07,394 INFO] Step 4900/50000; xent: 2.61; lr: 0.0000098;  21 docs/s;   6286 sec\n","[2022-10-10 02:53:11,313 INFO] Step 4950/50000; xent: 2.64; lr: 0.0000099;  20 docs/s;   6349 sec\n","[2022-10-10 02:54:15,591 INFO] Step 5000/50000; xent: 2.63; lr: 0.0000100;  22 docs/s;   6414 sec\n","[2022-10-10 02:54:15,602 INFO] Saving checkpoint MODEL_PATH/model_step_5000.pt\n","[2022-10-10 02:54:48,914 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.222.bert.pt, number of examples: 1996\n","[2022-10-10 02:55:25,957 INFO] Step 5050/50000; xent: 2.55; lr: 0.0000101;  20 docs/s;   6484 sec\n","[2022-10-10 02:56:29,785 INFO] Step 5100/50000; xent: 2.57; lr: 0.0000102;  23 docs/s;   6548 sec\n","[2022-10-10 02:57:32,958 INFO] Step 5150/50000; xent: 2.65; lr: 0.0000103;  21 docs/s;   6611 sec\n","[2022-10-10 02:57:49,635 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.247.bert.pt, number of examples: 1997\n","[2022-10-10 02:58:36,544 INFO] Step 5200/50000; xent: 2.52; lr: 0.0000104;  24 docs/s;   6675 sec\n","[2022-10-10 02:59:40,557 INFO] Step 5250/50000; xent: 2.54; lr: 0.0000105;  23 docs/s;   6739 sec\n","[2022-10-10 03:00:40,782 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.161.bert.pt, number of examples: 1999\n","[2022-10-10 03:00:44,643 INFO] Step 5300/50000; xent: 2.49; lr: 0.0000106;  23 docs/s;   6803 sec\n","[2022-10-10 03:01:48,477 INFO] Step 5350/50000; xent: 2.51; lr: 0.0000107;  20 docs/s;   6867 sec\n","[2022-10-10 03:02:52,794 INFO] Step 5400/50000; xent: 2.50; lr: 0.0000108;  24 docs/s;   6931 sec\n","[2022-10-10 03:03:45,562 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.49.bert.pt, number of examples: 1998\n","[2022-10-10 03:03:57,106 INFO] Step 5450/50000; xent: 2.58; lr: 0.0000109;  21 docs/s;   6995 sec\n","[2022-10-10 03:05:01,220 INFO] Step 5500/50000; xent: 2.47; lr: 0.0000110;  22 docs/s;   7059 sec\n","[2022-10-10 03:06:04,830 INFO] Step 5550/50000; xent: 2.61; lr: 0.0000111;  21 docs/s;   7123 sec\n","[2022-10-10 03:06:52,639 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.221.bert.pt, number of examples: 1998\n","[2022-10-10 03:07:09,188 INFO] Step 5600/50000; xent: 2.53; lr: 0.0000112;  21 docs/s;   7187 sec\n","[2022-10-10 03:08:12,596 INFO] Step 5650/50000; xent: 2.72; lr: 0.0000113;  21 docs/s;   7251 sec\n","[2022-10-10 03:09:16,486 INFO] Step 5700/50000; xent: 2.62; lr: 0.0000114;  23 docs/s;   7315 sec\n","[2022-10-10 03:10:01,406 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.246.bert.pt, number of examples: 1996\n","[2022-10-10 03:10:20,602 INFO] Step 5750/50000; xent: 2.57; lr: 0.0000115;  22 docs/s;   7379 sec\n","[2022-10-10 03:11:24,322 INFO] Step 5800/50000; xent: 2.54; lr: 0.0000116;  22 docs/s;   7442 sec\n","[2022-10-10 03:12:28,098 INFO] Step 5850/50000; xent: 2.49; lr: 0.0000117;  24 docs/s;   7506 sec\n","[2022-10-10 03:12:51,030 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.85.bert.pt, number of examples: 1999\n","[2022-10-10 03:13:32,233 INFO] Step 5900/50000; xent: 2.49; lr: 0.0000118;  25 docs/s;   7570 sec\n","[2022-10-10 03:14:35,581 INFO] Step 5950/50000; xent: 2.58; lr: 0.0000119;  22 docs/s;   7634 sec\n","[2022-10-10 03:15:39,199 INFO] Step 6000/50000; xent: 2.53; lr: 0.0000120;  24 docs/s;   7697 sec\n","[2022-10-10 03:15:39,201 INFO] Saving checkpoint MODEL_PATH/model_step_6000.pt\n","[2022-10-10 03:15:49,234 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.149.bert.pt, number of examples: 1999\n","[2022-10-10 03:16:50,883 INFO] Step 6050/50000; xent: 2.50; lr: 0.0000121;  21 docs/s;   7769 sec\n","[2022-10-10 03:17:54,000 INFO] Step 6100/50000; xent: 2.51; lr: 0.0000122;  22 docs/s;   7832 sec\n","[2022-10-10 03:18:49,067 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.20.bert.pt, number of examples: 1999\n","[2022-10-10 03:18:57,935 INFO] Step 6150/50000; xent: 2.51; lr: 0.0000123;  21 docs/s;   7896 sec\n","[2022-10-10 03:20:01,602 INFO] Step 6200/50000; xent: 2.40; lr: 0.0000124;  22 docs/s;   7960 sec\n","[2022-10-10 03:21:05,678 INFO] Step 6250/50000; xent: 2.47; lr: 0.0000125;  22 docs/s;   8024 sec\n","[2022-10-10 03:21:55,775 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.9.bert.pt, number of examples: 1999\n","[2022-10-10 03:22:09,868 INFO] Step 6300/50000; xent: 2.56; lr: 0.0000126;  21 docs/s;   8088 sec\n","[2022-10-10 03:23:13,778 INFO] Step 6350/50000; xent: 2.51; lr: 0.0000127;  21 docs/s;   8152 sec\n","[2022-10-10 03:24:17,528 INFO] Step 6400/50000; xent: 2.63; lr: 0.0000128;  21 docs/s;   8216 sec\n","[2022-10-10 03:25:09,892 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.116.bert.pt, number of examples: 1998\n","[2022-10-10 03:25:21,488 INFO] Step 6450/50000; xent: 2.54; lr: 0.0000129;  20 docs/s;   8280 sec\n","[2022-10-10 03:26:25,048 INFO] Step 6500/50000; xent: 2.40; lr: 0.0000130;  23 docs/s;   8343 sec\n","[2022-10-10 03:27:28,849 INFO] Step 6550/50000; xent: 2.49; lr: 0.0000131;  22 docs/s;   8407 sec\n","[2022-10-10 03:28:07,671 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.110.bert.pt, number of examples: 1999\n","[2022-10-10 03:28:33,353 INFO] Step 6600/50000; xent: 2.44; lr: 0.0000132;  23 docs/s;   8472 sec\n","[2022-10-10 03:29:37,115 INFO] Step 6650/50000; xent: 2.60; lr: 0.0000133;  22 docs/s;   8535 sec\n","[2022-10-10 03:30:41,288 INFO] Step 6700/50000; xent: 2.54; lr: 0.0000134;  24 docs/s;   8599 sec\n","[2022-10-10 03:31:00,547 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.141.bert.pt, number of examples: 1999\n","[2022-10-10 03:31:45,125 INFO] Step 6750/50000; xent: 2.54; lr: 0.0000135;  23 docs/s;   8663 sec\n","[2022-10-10 03:32:48,882 INFO] Step 6800/50000; xent: 2.59; lr: 0.0000136;  21 docs/s;   8727 sec\n","[2022-10-10 03:33:52,918 INFO] Step 6850/50000; xent: 2.58; lr: 0.0000137;  24 docs/s;   8791 sec\n","[2022-10-10 03:33:57,119 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt, number of examples: 1999\n","[2022-10-10 03:34:57,200 INFO] Step 6900/50000; xent: 2.58; lr: 0.0000138;  21 docs/s;   8855 sec\n","[2022-10-10 03:36:00,855 INFO] Step 6950/50000; xent: 2.58; lr: 0.0000139;  21 docs/s;   8919 sec\n","[2022-10-10 03:37:05,186 INFO] Step 7000/50000; xent: 2.53; lr: 0.0000140;  20 docs/s;   8983 sec\n","[2022-10-10 03:37:05,188 INFO] Saving checkpoint MODEL_PATH/model_step_7000.pt\n","[2022-10-10 03:37:20,288 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.241.bert.pt, number of examples: 1999\n","[2022-10-10 03:38:15,528 INFO] Step 7050/50000; xent: 2.54; lr: 0.0000141;  19 docs/s;   9054 sec\n","[2022-10-10 03:39:18,790 INFO] Step 7100/50000; xent: 2.48; lr: 0.0000142;  23 docs/s;   9117 sec\n","[2022-10-10 03:40:13,467 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.159.bert.pt, number of examples: 1999\n","[2022-10-10 03:40:22,462 INFO] Step 7150/50000; xent: 2.52; lr: 0.0000143;  24 docs/s;   9181 sec\n","[2022-10-10 03:41:26,155 INFO] Step 7200/50000; xent: 2.56; lr: 0.0000144;  22 docs/s;   9244 sec\n","[2022-10-10 03:42:30,200 INFO] Step 7250/50000; xent: 2.55; lr: 0.0000145;  22 docs/s;   9308 sec\n","[2022-10-10 03:43:13,277 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.167.bert.pt, number of examples: 1999\n","[2022-10-10 03:43:33,756 INFO] Step 7300/50000; xent: 2.63; lr: 0.0000146;  22 docs/s;   9372 sec\n","[2022-10-10 03:44:37,304 INFO] Step 7350/50000; xent: 2.55; lr: 0.0000147;  22 docs/s;   9435 sec\n","[2022-10-10 03:45:41,336 INFO] Step 7400/50000; xent: 2.57; lr: 0.0000148;  22 docs/s;   9499 sec\n","[2022-10-10 03:46:17,215 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.73.bert.pt, number of examples: 1999\n","[2022-10-10 03:46:45,399 INFO] Step 7450/50000; xent: 2.59; lr: 0.0000149;  21 docs/s;   9564 sec\n","[2022-10-10 03:47:49,234 INFO] Step 7500/50000; xent: 2.51; lr: 0.0000150;  23 docs/s;   9627 sec\n","[2022-10-10 03:48:53,281 INFO] Step 7550/50000; xent: 2.65; lr: 0.0000151;  21 docs/s;   9691 sec\n","[2022-10-10 03:49:19,160 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.125.bert.pt, number of examples: 1999\n","[2022-10-10 03:49:57,616 INFO] Step 7600/50000; xent: 2.57; lr: 0.0000152;  22 docs/s;   9756 sec\n","[2022-10-10 03:51:01,515 INFO] Step 7650/50000; xent: 2.49; lr: 0.0000153;  23 docs/s;   9820 sec\n","[2022-10-10 03:52:05,291 INFO] Step 7700/50000; xent: 2.52; lr: 0.0000154;  22 docs/s;   9883 sec\n","[2022-10-10 03:52:17,320 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.72.bert.pt, number of examples: 1999\n","[2022-10-10 03:53:09,844 INFO] Step 7750/50000; xent: 2.58; lr: 0.0000155;  22 docs/s;   9948 sec\n","[2022-10-10 03:54:13,734 INFO] Step 7800/50000; xent: 2.54; lr: 0.0000156;  22 docs/s;  10012 sec\n","[2022-10-10 03:55:17,450 INFO] Step 7850/50000; xent: 2.49; lr: 0.0000157;  23 docs/s;  10076 sec\n","[2022-10-10 03:55:17,816 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.95.bert.pt, number of examples: 1999\n","[2022-10-10 03:56:21,957 INFO] Step 7900/50000; xent: 2.43; lr: 0.0000158;  23 docs/s;  10140 sec\n","[2022-10-10 03:57:26,299 INFO] Step 7950/50000; xent: 2.59; lr: 0.0000159;  23 docs/s;  10204 sec\n","[2022-10-10 03:58:12,290 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.31.bert.pt, number of examples: 1999\n","[2022-10-10 03:58:30,076 INFO] Step 8000/50000; xent: 2.51; lr: 0.0000160;  23 docs/s;  10268 sec\n","[2022-10-10 03:58:30,087 INFO] Saving checkpoint MODEL_PATH/model_step_8000.pt\n","[2022-10-10 03:59:40,286 INFO] Step 8050/50000; xent: 2.55; lr: 0.0000161;  21 docs/s;  10338 sec\n","[2022-10-10 04:00:43,961 INFO] Step 8100/50000; xent: 2.60; lr: 0.0000162;  23 docs/s;  10402 sec\n","[2022-10-10 04:01:14,722 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.23.bert.pt, number of examples: 1999\n","[2022-10-10 04:01:47,805 INFO] Step 8150/50000; xent: 2.54; lr: 0.0000163;  23 docs/s;  10466 sec\n","[2022-10-10 04:02:51,608 INFO] Step 8200/50000; xent: 2.47; lr: 0.0000164;  21 docs/s;  10530 sec\n","[2022-10-10 04:03:55,008 INFO] Step 8250/50000; xent: 2.48; lr: 0.0000165;  22 docs/s;  10593 sec\n","[2022-10-10 04:04:15,214 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.56.bert.pt, number of examples: 1999\n","[2022-10-10 04:04:58,470 INFO] Step 8300/50000; xent: 2.56; lr: 0.0000166;  20 docs/s;  10657 sec\n","[2022-10-10 04:06:03,126 INFO] Step 8350/50000; xent: 2.51; lr: 0.0000167;  22 docs/s;  10721 sec\n","[2022-10-10 04:07:07,012 INFO] Step 8400/50000; xent: 2.56; lr: 0.0000168;  21 docs/s;  10785 sec\n","[2022-10-10 04:07:22,763 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.119.bert.pt, number of examples: 1999\n","[2022-10-10 04:08:11,247 INFO] Step 8450/50000; xent: 2.43; lr: 0.0000169;  23 docs/s;  10849 sec\n","[2022-10-10 04:09:15,265 INFO] Step 8500/50000; xent: 2.55; lr: 0.0000170;  22 docs/s;  10913 sec\n","[2022-10-10 04:10:18,992 INFO] Step 8550/50000; xent: 2.49; lr: 0.0000171;  22 docs/s;  10977 sec\n","[2022-10-10 04:10:20,591 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.218.bert.pt, number of examples: 1998\n","[2022-10-10 04:11:22,717 INFO] Step 8600/50000; xent: 2.58; lr: 0.0000172;  21 docs/s;  11041 sec\n","[2022-10-10 04:12:26,478 INFO] Step 8650/50000; xent: 2.60; lr: 0.0000173;  21 docs/s;  11105 sec\n","[2022-10-10 04:13:20,706 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.200.bert.pt, number of examples: 1999\n","[2022-10-10 04:13:30,938 INFO] Step 8700/50000; xent: 2.58; lr: 0.0000174;  24 docs/s;  11169 sec\n","[2022-10-10 04:14:35,206 INFO] Step 8750/50000; xent: 2.57; lr: 0.0000175;  22 docs/s;  11233 sec\n","[2022-10-10 04:15:39,042 INFO] Step 8800/50000; xent: 2.64; lr: 0.0000176;  21 docs/s;  11297 sec\n","[2022-10-10 04:16:28,564 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.66.bert.pt, number of examples: 1999\n","[2022-10-10 04:16:42,488 INFO] Step 8850/50000; xent: 2.53; lr: 0.0000177;  22 docs/s;  11361 sec\n","[2022-10-10 04:17:46,341 INFO] Step 8900/50000; xent: 2.62; lr: 0.0000178;  22 docs/s;  11424 sec\n","[2022-10-10 04:18:50,564 INFO] Step 8950/50000; xent: 2.54; lr: 0.0000179;  22 docs/s;  11489 sec\n","[2022-10-10 04:19:27,809 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.209.bert.pt, number of examples: 1996\n","[2022-10-10 04:19:54,447 INFO] Step 9000/50000; xent: 2.57; lr: 0.0000180;  23 docs/s;  11553 sec\n","[2022-10-10 04:19:54,458 INFO] Saving checkpoint MODEL_PATH/model_step_9000.pt\n","[2022-10-10 04:21:05,011 INFO] Step 9050/50000; xent: 2.63; lr: 0.0000181;  20 docs/s;  11623 sec\n","[2022-10-10 04:22:08,606 INFO] Step 9100/50000; xent: 2.72; lr: 0.0000182;  21 docs/s;  11687 sec\n","[2022-10-10 04:22:39,143 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.114.bert.pt, number of examples: 1999\n","[2022-10-10 04:23:11,900 INFO] Step 9150/50000; xent: 2.72; lr: 0.0000183;  20 docs/s;  11750 sec\n","[2022-10-10 04:24:15,860 INFO] Step 9200/50000; xent: 2.50; lr: 0.0000184;  24 docs/s;  11814 sec\n","[2022-10-10 04:25:19,742 INFO] Step 9250/50000; xent: 2.52; lr: 0.0000185;  22 docs/s;  11878 sec\n","[2022-10-10 04:25:35,558 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.50.bert.pt, number of examples: 1999\n","[2022-10-10 04:26:24,225 INFO] Step 9300/50000; xent: 2.46; lr: 0.0000186;  24 docs/s;  11942 sec\n","[2022-10-10 04:27:28,368 INFO] Step 9350/50000; xent: 2.66; lr: 0.0000187;  21 docs/s;  12007 sec\n","[2022-10-10 04:28:32,056 INFO] Step 9400/50000; xent: 2.57; lr: 0.0000188;  21 docs/s;  12070 sec\n","[2022-10-10 04:28:40,049 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.3.bert.pt, number of examples: 1997\n","[2022-10-10 04:29:36,505 INFO] Step 9450/50000; xent: 2.62; lr: 0.0000189;  20 docs/s;  12135 sec\n","[2022-10-10 04:30:40,406 INFO] Step 9500/50000; xent: 2.56; lr: 0.0000190;  21 docs/s;  12199 sec\n","[2022-10-10 04:31:43,867 INFO] Step 9550/50000; xent: 2.60; lr: 0.0000191;  21 docs/s;  12262 sec\n","[2022-10-10 04:31:54,232 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.236.bert.pt, number of examples: 1998\n","[2022-10-10 04:32:47,615 INFO] Step 9600/50000; xent: 2.52; lr: 0.0000192;  22 docs/s;  12326 sec\n","[2022-10-10 04:33:50,971 INFO] Step 9650/50000; xent: 2.51; lr: 0.0000193;  24 docs/s;  12389 sec\n","[2022-10-10 04:34:49,057 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.21.bert.pt, number of examples: 1998\n","[2022-10-10 04:34:54,165 INFO] Step 9700/50000; xent: 2.54; lr: 0.0000194;  21 docs/s;  12452 sec\n","[2022-10-10 04:35:57,879 INFO] Step 9750/50000; xent: 2.49; lr: 0.0000195;  22 docs/s;  12516 sec\n","[2022-10-10 04:37:01,733 INFO] Step 9800/50000; xent: 2.31; lr: 0.0000196;  22 docs/s;  12580 sec\n","[2022-10-10 04:37:48,920 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.242.bert.pt, number of examples: 1998\n","[2022-10-10 04:38:05,718 INFO] Step 9850/50000; xent: 2.51; lr: 0.0000197;  23 docs/s;  12644 sec\n","[2022-10-10 04:39:09,636 INFO] Step 9900/50000; xent: 2.54; lr: 0.0000198;  24 docs/s;  12708 sec\n","[2022-10-10 04:40:13,275 INFO] Step 9950/50000; xent: 2.60; lr: 0.0000199;  23 docs/s;  12771 sec\n","[2022-10-10 04:40:40,239 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.62.bert.pt, number of examples: 1999\n","[2022-10-10 04:41:17,451 INFO] Step 10000/50000; xent: 2.41; lr: 0.0000200;  24 docs/s;  12836 sec\n","[2022-10-10 04:41:17,462 INFO] Saving checkpoint MODEL_PATH/model_step_10000.pt\n","[2022-10-10 04:42:28,271 INFO] Step 10050/50000; xent: 2.59; lr: 0.0000200;  19 docs/s;  12906 sec\n","[2022-10-10 04:43:32,149 INFO] Step 10100/50000; xent: 2.62; lr: 0.0000199;  22 docs/s;  12970 sec\n","[2022-10-10 04:43:49,002 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.230.bert.pt, number of examples: 1999\n","[2022-10-10 04:44:36,598 INFO] Step 10150/50000; xent: 2.48; lr: 0.0000199;  23 docs/s;  13035 sec\n","[2022-10-10 04:45:40,381 INFO] Step 10200/50000; xent: 2.63; lr: 0.0000198;  21 docs/s;  13099 sec\n","[2022-10-10 04:46:43,752 INFO] Step 10250/50000; xent: 2.55; lr: 0.0000198;  23 docs/s;  13162 sec\n","[2022-10-10 04:46:45,371 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.132.bert.pt, number of examples: 1999\n","[2022-10-10 04:47:47,871 INFO] Step 10300/50000; xent: 2.44; lr: 0.0000197;  23 docs/s;  13226 sec\n","[2022-10-10 04:48:51,558 INFO] Step 10350/50000; xent: 2.53; lr: 0.0000197;  22 docs/s;  13290 sec\n","[2022-10-10 04:49:44,075 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.227.bert.pt, number of examples: 1999\n","[2022-10-10 04:49:55,357 INFO] Step 10400/50000; xent: 2.50; lr: 0.0000196;  21 docs/s;  13354 sec\n","[2022-10-10 04:50:58,859 INFO] Step 10450/50000; xent: 2.65; lr: 0.0000196;  21 docs/s;  13417 sec\n","[2022-10-10 04:52:02,339 INFO] Step 10500/50000; xent: 2.51; lr: 0.0000195;  25 docs/s;  13480 sec\n","[2022-10-10 04:52:39,410 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.258.bert.pt, number of examples: 1999\n","[2022-10-10 04:53:06,139 INFO] Step 10550/50000; xent: 2.54; lr: 0.0000195;  23 docs/s;  13544 sec\n","[2022-10-10 04:54:09,889 INFO] Step 10600/50000; xent: 2.55; lr: 0.0000194;  22 docs/s;  13608 sec\n","[2022-10-10 04:55:13,014 INFO] Step 10650/50000; xent: 2.54; lr: 0.0000194;  21 docs/s;  13671 sec\n","[2022-10-10 04:55:47,333 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.123.bert.pt, number of examples: 1999\n","[2022-10-10 04:56:16,338 INFO] Step 10700/50000; xent: 2.52; lr: 0.0000193;  22 docs/s;  13734 sec\n","[2022-10-10 04:57:20,342 INFO] Step 10750/50000; xent: 2.39; lr: 0.0000193;  24 docs/s;  13798 sec\n","[2022-10-10 04:58:24,526 INFO] Step 10800/50000; xent: 2.39; lr: 0.0000192;  22 docs/s;  13863 sec\n","[2022-10-10 04:58:38,711 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.154.bert.pt, number of examples: 1999\n","[2022-10-10 04:59:28,406 INFO] Step 10850/50000; xent: 2.45; lr: 0.0000192;  22 docs/s;  13927 sec\n","[2022-10-10 05:00:31,892 INFO] Step 10900/50000; xent: 2.47; lr: 0.0000192;  23 docs/s;  13990 sec\n","[2022-10-10 05:01:36,252 INFO] Step 10950/50000; xent: 2.60; lr: 0.0000191;  22 docs/s;  14054 sec\n","[2022-10-10 05:01:37,861 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.87.bert.pt, number of examples: 1998\n","[2022-10-10 05:02:40,665 INFO] Step 11000/50000; xent: 2.49; lr: 0.0000191;  22 docs/s;  14119 sec\n","[2022-10-10 05:02:40,676 INFO] Saving checkpoint MODEL_PATH/model_step_11000.pt\n","[2022-10-10 05:03:50,967 INFO] Step 11050/50000; xent: 2.53; lr: 0.0000190;  20 docs/s;  14189 sec\n","[2022-10-10 05:04:43,209 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.129.bert.pt, number of examples: 1997\n","[2022-10-10 05:04:54,789 INFO] Step 11100/50000; xent: 2.50; lr: 0.0000190;  22 docs/s;  14253 sec\n","[2022-10-10 05:05:58,884 INFO] Step 11150/50000; xent: 2.49; lr: 0.0000189;  23 docs/s;  14317 sec\n","[2022-10-10 05:07:02,797 INFO] Step 11200/50000; xent: 2.53; lr: 0.0000189;  22 docs/s;  14381 sec\n","[2022-10-10 05:07:41,310 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.1.bert.pt, number of examples: 1999\n","[2022-10-10 05:08:06,905 INFO] Step 11250/50000; xent: 2.52; lr: 0.0000189;  22 docs/s;  14445 sec\n","[2022-10-10 05:09:10,560 INFO] Step 11300/50000; xent: 2.52; lr: 0.0000188;  21 docs/s;  14509 sec\n","[2022-10-10 05:10:14,361 INFO] Step 11350/50000; xent: 2.59; lr: 0.0000188;  21 docs/s;  14573 sec\n","[2022-10-10 05:10:52,835 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.152.bert.pt, number of examples: 1999\n","[2022-10-10 05:11:18,472 INFO] Step 11400/50000; xent: 2.67; lr: 0.0000187;  20 docs/s;  14637 sec\n","[2022-10-10 05:12:21,500 INFO] Step 11450/50000; xent: 2.50; lr: 0.0000187;  23 docs/s;  14700 sec\n","[2022-10-10 05:13:24,959 INFO] Step 11500/50000; xent: 2.44; lr: 0.0000187;  22 docs/s;  14763 sec\n","[2022-10-10 05:13:54,461 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.208.bert.pt, number of examples: 1996\n","[2022-10-10 05:14:28,756 INFO] Step 11550/50000; xent: 2.59; lr: 0.0000186;  22 docs/s;  14827 sec\n","[2022-10-10 05:15:32,749 INFO] Step 11600/50000; xent: 2.65; lr: 0.0000186;  24 docs/s;  14891 sec\n","[2022-10-10 05:16:35,787 INFO] Step 11650/50000; xent: 2.61; lr: 0.0000185;  22 docs/s;  14954 sec\n","[2022-10-10 05:16:47,604 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.112.bert.pt, number of examples: 1999\n","[2022-10-10 05:17:40,073 INFO] Step 11700/50000; xent: 2.44; lr: 0.0000185;  24 docs/s;  15018 sec\n","[2022-10-10 05:18:43,568 INFO] Step 11750/50000; xent: 2.41; lr: 0.0000185;  24 docs/s;  15082 sec\n","[2022-10-10 05:19:39,625 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.53.bert.pt, number of examples: 1999\n","[2022-10-10 05:19:47,289 INFO] Step 11800/50000; xent: 2.46; lr: 0.0000184;  21 docs/s;  15145 sec\n","[2022-10-10 05:20:50,892 INFO] Step 11850/50000; xent: 2.48; lr: 0.0000184;  22 docs/s;  15209 sec\n","[2022-10-10 05:21:54,966 INFO] Step 11900/50000; xent: 2.50; lr: 0.0000183;  21 docs/s;  15273 sec\n","[2022-10-10 05:22:45,014 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.67.bert.pt, number of examples: 1999\n","[2022-10-10 05:22:58,911 INFO] Step 11950/50000; xent: 2.49; lr: 0.0000183;  22 docs/s;  15337 sec\n","[2022-10-10 05:24:02,768 INFO] Step 12000/50000; xent: 2.51; lr: 0.0000183;  22 docs/s;  15401 sec\n","[2022-10-10 05:24:02,780 INFO] Saving checkpoint MODEL_PATH/model_step_12000.pt\n","[2022-10-10 05:25:13,847 INFO] Step 12050/50000; xent: 2.46; lr: 0.0000182;  21 docs/s;  15472 sec\n","[2022-10-10 05:25:48,043 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.27.bert.pt, number of examples: 1999\n","[2022-10-10 05:26:17,347 INFO] Step 12100/50000; xent: 2.50; lr: 0.0000182;  22 docs/s;  15535 sec\n","[2022-10-10 05:27:20,934 INFO] Step 12150/50000; xent: 2.54; lr: 0.0000181;  21 docs/s;  15599 sec\n","[2022-10-10 05:28:24,249 INFO] Step 12200/50000; xent: 2.53; lr: 0.0000181;  20 docs/s;  15662 sec\n","[2022-10-10 05:29:03,615 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.144.bert.pt, number of examples: 1999\n","[2022-10-10 05:29:27,941 INFO] Step 12250/50000; xent: 2.54; lr: 0.0000181;  21 docs/s;  15726 sec\n","[2022-10-10 05:30:31,375 INFO] Step 12300/50000; xent: 2.56; lr: 0.0000180;  23 docs/s;  15790 sec\n","[2022-10-10 05:31:34,681 INFO] Step 12350/50000; xent: 2.53; lr: 0.0000180;  22 docs/s;  15853 sec\n","[2022-10-10 05:32:02,742 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.113.bert.pt, number of examples: 1998\n","[2022-10-10 05:32:38,412 INFO] Step 12400/50000; xent: 2.57; lr: 0.0000180;  20 docs/s;  15917 sec\n","[2022-10-10 05:33:42,781 INFO] Step 12450/50000; xent: 2.52; lr: 0.0000179;  24 docs/s;  15981 sec\n","[2022-10-10 05:34:46,121 INFO] Step 12500/50000; xent: 2.50; lr: 0.0000179;  24 docs/s;  16044 sec\n","[2022-10-10 05:34:54,251 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.238.bert.pt, number of examples: 1998\n","[2022-10-10 05:35:50,036 INFO] Step 12550/50000; xent: 2.57; lr: 0.0000179;  24 docs/s;  16108 sec\n","[2022-10-10 05:36:53,742 INFO] Step 12600/50000; xent: 2.56; lr: 0.0000178;  24 docs/s;  16172 sec\n","[2022-10-10 05:37:44,530 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.42.bert.pt, number of examples: 1999\n","[2022-10-10 05:37:57,163 INFO] Step 12650/50000; xent: 2.50; lr: 0.0000178;  23 docs/s;  16235 sec\n","[2022-10-10 05:39:00,610 INFO] Step 12700/50000; xent: 2.53; lr: 0.0000177;  24 docs/s;  16299 sec\n","[2022-10-10 05:40:03,790 INFO] Step 12750/50000; xent: 2.47; lr: 0.0000177;  24 docs/s;  16362 sec\n","[2022-10-10 05:40:31,497 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.252.bert.pt, number of examples: 1978\n","[2022-10-10 05:41:07,163 INFO] Step 12800/50000; xent: 2.47; lr: 0.0000177;  23 docs/s;  16425 sec\n","[2022-10-10 05:42:10,076 INFO] Step 12850/50000; xent: 2.24; lr: 0.0000176;  26 docs/s;  16488 sec\n","[2022-10-10 05:43:13,756 INFO] Step 12900/50000; xent: 2.42; lr: 0.0000176;  23 docs/s;  16552 sec\n","[2022-10-10 05:43:15,412 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.41.bert.pt, number of examples: 1999\n","[2022-10-10 05:44:17,550 INFO] Step 12950/50000; xent: 2.40; lr: 0.0000176;  23 docs/s;  16616 sec\n","[2022-10-10 05:45:21,057 INFO] Step 13000/50000; xent: 2.46; lr: 0.0000175;  24 docs/s;  16679 sec\n","[2022-10-10 05:45:21,068 INFO] Saving checkpoint MODEL_PATH/model_step_13000.pt\n","[2022-10-10 05:46:12,537 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.251.bert.pt, number of examples: 1984\n","[2022-10-10 05:46:31,795 INFO] Step 13050/50000; xent: 2.41; lr: 0.0000175;  21 docs/s;  16750 sec\n","[2022-10-10 05:47:35,018 INFO] Step 13100/50000; xent: 2.39; lr: 0.0000175;  23 docs/s;  16813 sec\n","[2022-10-10 05:48:39,073 INFO] Step 13150/50000; xent: 2.39; lr: 0.0000174;  24 docs/s;  16877 sec\n","[2022-10-10 05:49:03,341 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.57.bert.pt, number of examples: 1998\n","[2022-10-10 05:49:42,744 INFO] Step 13200/50000; xent: 2.58; lr: 0.0000174;  21 docs/s;  16941 sec\n","[2022-10-10 05:50:46,418 INFO] Step 13250/50000; xent: 2.54; lr: 0.0000174;  23 docs/s;  17005 sec\n","[2022-10-10 05:51:49,909 INFO] Step 13300/50000; xent: 2.51; lr: 0.0000173;  22 docs/s;  17068 sec\n","[2022-10-10 05:52:02,833 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.179.bert.pt, number of examples: 1999\n","[2022-10-10 05:52:53,725 INFO] Step 13350/50000; xent: 2.48; lr: 0.0000173;  23 docs/s;  17132 sec\n","[2022-10-10 05:53:57,583 INFO] Step 13400/50000; xent: 2.51; lr: 0.0000173;  22 docs/s;  17196 sec\n","[2022-10-10 05:55:00,131 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.226.bert.pt, number of examples: 1992\n","[2022-10-10 05:55:01,422 INFO] Step 13450/50000; xent: 2.48; lr: 0.0000172;  22 docs/s;  17260 sec\n","[2022-10-10 05:56:04,876 INFO] Step 13500/50000; xent: 2.63; lr: 0.0000172;  23 docs/s;  17323 sec\n","[2022-10-10 05:57:08,384 INFO] Step 13550/50000; xent: 2.66; lr: 0.0000172;  22 docs/s;  17387 sec\n","[2022-10-10 05:57:59,074 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.232.bert.pt, number of examples: 1999\n","[2022-10-10 05:58:11,869 INFO] Step 13600/50000; xent: 2.61; lr: 0.0000171;  22 docs/s;  17450 sec\n","[2022-10-10 05:59:15,401 INFO] Step 13650/50000; xent: 2.63; lr: 0.0000171;  20 docs/s;  17514 sec\n","[2022-10-10 06:00:18,581 INFO] Step 13700/50000; xent: 2.55; lr: 0.0000171;  22 docs/s;  17577 sec\n","[2022-10-10 06:00:58,067 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.180.bert.pt, number of examples: 1999\n","[2022-10-10 06:01:22,618 INFO] Step 13750/50000; xent: 2.42; lr: 0.0000171;  24 docs/s;  17641 sec\n","[2022-10-10 06:02:26,196 INFO] Step 13800/50000; xent: 2.52; lr: 0.0000170;  21 docs/s;  17704 sec\n","[2022-10-10 06:03:30,021 INFO] Step 13850/50000; xent: 2.40; lr: 0.0000170;  22 docs/s;  17768 sec\n","[2022-10-10 06:04:04,855 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.212.bert.pt, number of examples: 1997\n","[2022-10-10 06:04:33,809 INFO] Step 13900/50000; xent: 2.54; lr: 0.0000170;  20 docs/s;  17832 sec\n","[2022-10-10 06:05:37,397 INFO] Step 13950/50000; xent: 2.57; lr: 0.0000169;  22 docs/s;  17896 sec\n","[2022-10-10 06:06:41,131 INFO] Step 14000/50000; xent: 2.54; lr: 0.0000169;  23 docs/s;  17959 sec\n","[2022-10-10 06:06:41,142 INFO] Saving checkpoint MODEL_PATH/model_step_14000.pt\n","[2022-10-10 06:07:13,448 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.131.bert.pt, number of examples: 1999\n","[2022-10-10 06:07:52,042 INFO] Step 14050/50000; xent: 2.50; lr: 0.0000169;  20 docs/s;  18030 sec\n","[2022-10-10 06:08:55,395 INFO] Step 14100/50000; xent: 2.45; lr: 0.0000168;  22 docs/s;  18094 sec\n","[2022-10-10 06:09:58,914 INFO] Step 14150/50000; xent: 2.51; lr: 0.0000168;  21 docs/s;  18157 sec\n","[2022-10-10 06:10:15,787 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.174.bert.pt, number of examples: 1998\n","[2022-10-10 06:11:03,246 INFO] Step 14200/50000; xent: 2.59; lr: 0.0000168;  22 docs/s;  18221 sec\n","[2022-10-10 06:12:06,709 INFO] Step 14250/50000; xent: 2.53; lr: 0.0000168;  22 docs/s;  18285 sec\n","[2022-10-10 06:13:09,937 INFO] Step 14300/50000; xent: 2.56; lr: 0.0000167;  23 docs/s;  18348 sec\n","[2022-10-10 06:13:15,391 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.40.bert.pt, number of examples: 1998\n","[2022-10-10 06:14:14,187 INFO] Step 14350/50000; xent: 2.58; lr: 0.0000167;  21 docs/s;  18412 sec\n","[2022-10-10 06:15:17,359 INFO] Step 14400/50000; xent: 2.40; lr: 0.0000167;  25 docs/s;  18476 sec\n","[2022-10-10 06:16:09,553 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.18.bert.pt, number of examples: 1999\n","[2022-10-10 06:16:21,179 INFO] Step 14450/50000; xent: 2.55; lr: 0.0000166;  22 docs/s;  18539 sec\n","[2022-10-10 06:17:25,000 INFO] Step 14500/50000; xent: 2.75; lr: 0.0000166;  21 docs/s;  18603 sec\n","[2022-10-10 06:18:28,769 INFO] Step 14550/50000; xent: 2.75; lr: 0.0000166;  20 docs/s;  18667 sec\n","[2022-10-10 06:19:24,829 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.185.bert.pt, number of examples: 1999\n","[2022-10-10 06:19:32,650 INFO] Step 14600/50000; xent: 2.66; lr: 0.0000166;  21 docs/s;  18731 sec\n","[2022-10-10 06:20:35,988 INFO] Step 14650/50000; xent: 2.52; lr: 0.0000165;  22 docs/s;  18794 sec\n","[2022-10-10 06:21:39,828 INFO] Step 14700/50000; xent: 2.45; lr: 0.0000165;  22 docs/s;  18858 sec\n","[2022-10-10 06:22:27,004 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.32.bert.pt, number of examples: 1999\n","[2022-10-10 06:22:43,560 INFO] Step 14750/50000; xent: 2.48; lr: 0.0000165;  23 docs/s;  18922 sec\n","[2022-10-10 06:23:47,438 INFO] Step 14800/50000; xent: 2.60; lr: 0.0000164;  22 docs/s;  18986 sec\n","[2022-10-10 06:24:50,649 INFO] Step 14850/50000; xent: 2.44; lr: 0.0000164;  23 docs/s;  19049 sec\n","[2022-10-10 06:25:22,707 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.142.bert.pt, number of examples: 1999\n","[2022-10-10 06:25:54,769 INFO] Step 14900/50000; xent: 2.48; lr: 0.0000164;  23 docs/s;  19113 sec\n","[2022-10-10 06:26:58,366 INFO] Step 14950/50000; xent: 2.50; lr: 0.0000164;  22 docs/s;  19177 sec\n","[2022-10-10 06:28:02,173 INFO] Step 15000/50000; xent: 2.53; lr: 0.0000163;  22 docs/s;  19240 sec\n","[2022-10-10 06:28:02,175 INFO] Saving checkpoint MODEL_PATH/model_step_15000.pt\n","[2022-10-10 06:28:30,496 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.192.bert.pt, number of examples: 1998\n","[2022-10-10 06:29:12,706 INFO] Step 15050/50000; xent: 2.58; lr: 0.0000163;  20 docs/s;  19311 sec\n","[2022-10-10 06:30:16,945 INFO] Step 15100/50000; xent: 2.70; lr: 0.0000163;  21 docs/s;  19375 sec\n","[2022-10-10 06:31:20,282 INFO] Step 15150/50000; xent: 2.67; lr: 0.0000162;  23 docs/s;  19438 sec\n","[2022-10-10 06:31:32,229 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.136.bert.pt, number of examples: 1999\n","[2022-10-10 06:32:24,783 INFO] Step 15200/50000; xent: 2.75; lr: 0.0000162;  20 docs/s;  19503 sec\n","[2022-10-10 06:33:28,596 INFO] Step 15250/50000; xent: 2.62; lr: 0.0000162;  22 docs/s;  19567 sec\n","[2022-10-10 06:34:31,987 INFO] Step 15300/50000; xent: 2.55; lr: 0.0000162;  24 docs/s;  19630 sec\n","[2022-10-10 06:34:35,001 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.36.bert.pt, number of examples: 1999\n","[2022-10-10 06:35:36,194 INFO] Step 15350/50000; xent: 2.57; lr: 0.0000161;  20 docs/s;  19694 sec\n","[2022-10-10 06:36:39,418 INFO] Step 15400/50000; xent: 2.44; lr: 0.0000161;  22 docs/s;  19758 sec\n","[2022-10-10 06:37:42,430 INFO] Step 15450/50000; xent: 2.56; lr: 0.0000161;  21 docs/s;  19821 sec\n","[2022-10-10 06:37:42,896 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.189.bert.pt, number of examples: 1999\n","[2022-10-10 06:38:46,147 INFO] Step 15500/50000; xent: 2.59; lr: 0.0000161;  22 docs/s;  19884 sec\n","[2022-10-10 06:39:50,091 INFO] Step 15550/50000; xent: 2.62; lr: 0.0000160;  21 docs/s;  19948 sec\n","[2022-10-10 06:40:47,938 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.250.bert.pt, number of examples: 1986\n","[2022-10-10 06:40:54,352 INFO] Step 15600/50000; xent: 2.52; lr: 0.0000160;  22 docs/s;  20012 sec\n","[2022-10-10 06:41:57,684 INFO] Step 15650/50000; xent: 2.52; lr: 0.0000160;  22 docs/s;  20076 sec\n","[2022-10-10 06:43:01,572 INFO] Step 15700/50000; xent: 2.43; lr: 0.0000160;  24 docs/s;  20140 sec\n","[2022-10-10 06:43:41,116 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.63.bert.pt, number of examples: 1999\n","[2022-10-10 06:44:05,097 INFO] Step 15750/50000; xent: 2.53; lr: 0.0000159;  22 docs/s;  20203 sec\n","[2022-10-10 06:45:09,203 INFO] Step 15800/50000; xent: 2.46; lr: 0.0000159;  23 docs/s;  20267 sec\n","[2022-10-10 06:46:13,163 INFO] Step 15850/50000; xent: 2.55; lr: 0.0000159;  22 docs/s;  20331 sec\n","[2022-10-10 06:46:41,391 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.88.bert.pt, number of examples: 1999\n","[2022-10-10 06:47:17,232 INFO] Step 15900/50000; xent: 2.54; lr: 0.0000159;  21 docs/s;  20395 sec\n","[2022-10-10 06:48:21,282 INFO] Step 15950/50000; xent: 2.62; lr: 0.0000158;  21 docs/s;  20459 sec\n","[2022-10-10 06:49:25,473 INFO] Step 16000/50000; xent: 2.63; lr: 0.0000158;  23 docs/s;  20524 sec\n","[2022-10-10 06:49:25,475 INFO] Saving checkpoint MODEL_PATH/model_step_16000.pt\n","[2022-10-10 06:49:52,607 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.81.bert.pt, number of examples: 1999\n","[2022-10-10 06:50:36,315 INFO] Step 16050/50000; xent: 2.58; lr: 0.0000158;  20 docs/s;  20594 sec\n","[2022-10-10 06:51:39,787 INFO] Step 16100/50000; xent: 2.59; lr: 0.0000158;  22 docs/s;  20658 sec\n","[2022-10-10 06:52:44,138 INFO] Step 16150/50000; xent: 2.65; lr: 0.0000157;  21 docs/s;  20722 sec\n","[2022-10-10 06:52:58,399 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.19.bert.pt, number of examples: 1999\n","[2022-10-10 06:53:47,419 INFO] Step 16200/50000; xent: 2.45; lr: 0.0000157;  22 docs/s;  20786 sec\n","[2022-10-10 06:54:51,238 INFO] Step 16250/50000; xent: 2.54; lr: 0.0000157;  22 docs/s;  20849 sec\n","[2022-10-10 06:55:54,809 INFO] Step 16300/50000; xent: 2.56; lr: 0.0000157;  21 docs/s;  20913 sec\n","[2022-10-10 06:56:02,729 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.38.bert.pt, number of examples: 1999\n","[2022-10-10 06:56:58,649 INFO] Step 16350/50000; xent: 2.47; lr: 0.0000156;  23 docs/s;  20977 sec\n","[2022-10-10 06:58:02,251 INFO] Step 16400/50000; xent: 2.47; lr: 0.0000156;  25 docs/s;  21040 sec\n","[2022-10-10 06:58:51,831 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.5.bert.pt, number of examples: 1999\n","[2022-10-10 06:59:05,787 INFO] Step 16450/50000; xent: 2.56; lr: 0.0000156;  21 docs/s;  21104 sec\n","[2022-10-10 07:00:09,240 INFO] Step 16500/50000; xent: 2.58; lr: 0.0000156;  21 docs/s;  21167 sec\n","[2022-10-10 07:01:13,448 INFO] Step 16550/50000; xent: 2.60; lr: 0.0000155;  22 docs/s;  21232 sec\n","[2022-10-10 07:01:59,277 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.80.bert.pt, number of examples: 1999\n","[2022-10-10 07:02:17,445 INFO] Step 16600/50000; xent: 2.59; lr: 0.0000155;  21 docs/s;  21296 sec\n","[2022-10-10 07:03:20,743 INFO] Step 16650/50000; xent: 2.52; lr: 0.0000155;  22 docs/s;  21359 sec\n","[2022-10-10 07:04:24,345 INFO] Step 16700/50000; xent: 2.57; lr: 0.0000155;  21 docs/s;  21422 sec\n","[2022-10-10 07:05:08,808 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.54.bert.pt, number of examples: 1999\n","[2022-10-10 07:05:27,973 INFO] Step 16750/50000; xent: 2.61; lr: 0.0000155;  20 docs/s;  21486 sec\n","[2022-10-10 07:06:31,574 INFO] Step 16800/50000; xent: 2.62; lr: 0.0000154;  21 docs/s;  21550 sec\n"]}],"source":["!python /content/PreSumm/src/train.py -other_bert phobert -task ext -mode train -bert_data_path /content/PreSumm/bert_data/cnndm_sample -model_path MODEL_PATH -lr 2e-3 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -ext_dropout 0.1 -visible_gpus 0 -log_file /content/PreSumm/logs/ext_bert_cnndm -use_interval true -warmup_steps 10000 -max_pos 512"]},{"cell_type":"markdown","source":["#Download presumm dataset\n"],"metadata":{"id":"dUashisuLdGz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOovIAxxQDZX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665289324970,"user_tz":-420,"elapsed":7344,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"da8439b4-2732-4cbc-f08a-b39b665c16dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1DN7ClZCCXsk2KegmC6t4ClBwtAf5galI\n","To: /content/bert_data_cnndm_final.zip\n","100% 1.14G/1.14G [00:05<00:00, 202MB/s]\n"]}],"source":["try:\n","    f = open(cwd+\"/bert_data_cnndm_final.zip\")\n","    # Do something with the file\n","    f.close()\n","except IOError:\n","    !gdown 1DN7ClZCCXsk2KegmC6t4ClBwtAf5galI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JY_qif9SQsDR"},"outputs":[],"source":["import zipfile\n","with zipfile.ZipFile(cwd+\"/bert_data_cnndm_final.zip\", 'r') as zip_ref:\n","    zip_ref.extractall('/content/PreSumm/bert_data')"]},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile('/content/drive/MyDrive/NLP/cong_nghe.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/PreSumm/bert_data')"],"metadata":{"id":"T_GfRJEvaoCH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Fix bug"],"metadata":{"id":"hCjZhpnLTC6f"}},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"IleITM8W4Jnx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkZ5438a98nQ","executionInfo":{"status":"ok","timestamp":1665308039973,"user_tz":-420,"elapsed":380,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"8a110c45-7778-40e3-eaa5-4c292382b80b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/PreSumm/src\n"]}]},{"cell_type":"code","source":["%cd /content/PreSumm/src"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BeLwnnO-FMc","executionInfo":{"status":"ok","timestamp":1665308038117,"user_tz":-420,"elapsed":400,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"97f1bc34-ae10-4dbd-9a97-60d82d2caca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/PreSumm/src\n"]}]},{"cell_type":"code","source":["!python www.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOEnrdCsCFZ6","executionInfo":{"status":"ok","timestamp":1665308545115,"user_tz":-420,"elapsed":11778,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"0aac831a-64f4-4a8b-f60f-4cd368f78fa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"www.py\", line 13, in <module>\n","    sent_scores, mask = model(src1, src1, src1, mm, mm)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/PreSumm/src/models/model_builder.py\", line 207, in forward\n","    top_vec = self.bert(src, segs, mask_src)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/PreSumm/src/models/model_builder.py\", line 163, in forward\n","    top_vec, _ = self.model(input_ids=x, token_type_ids=segs, attention_mask=mask)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\", line 727, in forward\n","    input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\", line 65, in forward\n","    input_ids, token_type_ids=token_type_ids, position_ids=position_ids, inputs_embeds=inputs_embeds\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\", line 174, in forward\n","    position_embeddings = self.position_embeddings(position_ids)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\", line 117, in forward\n","    self.norm_type, self.scale_grad_by_freq, self.sparse)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1506, in embedding\n","    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n","RuntimeError: index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:193\n"]}]},{"cell_type":"code","source":["# 256 khong loi 257 loi"],"metadata":{"id":"ADvq2-RhTah-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","    sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n","except:\n","    pickle.dump(self.model,open('/content/model.p','wb'))\n","    pickle.dump(src,open('/content/src.p','wb'))\n","    pickle.dump(segs,open('/content/segs.p','wb'))\n","    pickle.dump(clss,open('/content/clss.p','wb'))\n","    pickle.dump(mask,open('/content/mask.p','wb'))\n","    pickle.dump(mask_cls,open('/content/mask_cls.p','wb'))"],"metadata":{"id":"QkD3UddQRw0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import torch\n","\n","src = pickle.load(open('/content/src.p','rb'))\n","src1 = torch.zeros(11,256).long()\n","mm = torch.zeros((11,256),dtype=torch.uint8)\n","model = pickle.load(open('/content/model.p','rb'))\n","segs = pickle.load(open('/content/segs.p','rb'))\n","clss = pickle.load(open('/content/clss.p','rb'))\n","mask = pickle.load(open('/content/mask.p','rb'))\n","mask_cls = pickle.load(open('/content/mask_cls.p','rb'))\n","\n","sent_scores, mask = model(src, src1, clss, mask, mask_cls)\n","#sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","\n","#print(model)\n","# print(src)\n","# print(segs)\n","# print(clss)\n","# print(mask)\n","# print(mask_cls)\n","\n","#print(model.bert.model.config.vocab_size)"],"metadata":{"id":"IJaD99IDOuqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["src = pickle.load(open('/content/src.p','rb'))\n","segs = pickle.load(open('/content/segs.p','rb'))\n","clss = pickle.load(open('/content/clss.p','rb'))\n","mask = pickle.load(open('/content/mask.p','rb'))\n","mask_cls = pickle.load(open('/content/mask_cls.p','rb'))"],"metadata":{"id":"MXQV4kbJ3_64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent_scores, mask = model(src, segs, clss, mask, mask_cls)"],"metadata":{"id":"0ZzAsJh8HS8L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"GX4hlQ0CPqxA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.max(src)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIj5tjI54ZL1","executionInfo":{"status":"ok","timestamp":1665136739543,"user_tz":-420,"elapsed":427,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"ade034ff-a929-49fe-8df8-59922fe4db12"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(59318)"]},"metadata":{},"execution_count":171}]},{"cell_type":"code","source":["torch.zeros(11,258).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrHE0k1LEj2g","executionInfo":{"status":"ok","timestamp":1665139927089,"user_tz":-420,"elapsed":348,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"5cf8053c-b722-4598-838b-64bb94e25e92"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([11, 258])"]},"metadata":{},"execution_count":255}]},{"cell_type":"code","source":["src.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2u-6TyKERbh","executionInfo":{"status":"ok","timestamp":1665308098508,"user_tz":-420,"elapsed":375,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"ceed929e-e4b3-4ff3-8193-187c2be2c043"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 512])"]},"metadata":{},"execution_count":141}]},{"cell_type":"markdown","source":["#Prepare dataset"],"metadata":{"id":"e5QV5XENTP7z"}},{"cell_type":"code","source":["!git clone https://github.com/ThanhChinhBK/vietnews"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUrt-lwS4Hqf","executionInfo":{"status":"ok","timestamp":1665999399090,"user_tz":-420,"elapsed":28824,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"153ad664-3a7e-4306-8668-a43d14e6e0b6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'vietnews'...\n","remote: Enumerating objects: 143827, done.\u001b[K\n","remote: Total 143827 (delta 0), reused 0 (delta 0), pack-reused 143827\u001b[K\n","Receiving objects: 100% (143827/143827), 194.68 MiB | 13.50 MiB/s, done.\n","Resolving deltas: 100% (11/11), done.\n","Checking out files: 100% (150704/150704), done.\n"]}]},{"cell_type":"code","source":["#!mkdir valid_data\n","import zipfile\n","with zipfile.ZipFile('/content/VietnameseMDS/KTLAB-200document-clusters.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/valid_data')"],"metadata":{"id":"5PtqmMoX5P_z","executionInfo":{"status":"ok","timestamp":1665992627698,"user_tz":-420,"elapsed":979,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!pip3 install py_vncorenlp\n","clear_output()"],"metadata":{"id":"SnN3CtiCVp9a","executionInfo":{"status":"ok","timestamp":1665992636518,"user_tz":-420,"elapsed":5733,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# import py_vncorenlp\n","# # import os\n","# # cwd = os.getcwd()\n","# py_vncorenlp.download_model(save_dir='/content')\n","# rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/content')\n","from nltk import tokenize\n","import nltk\n","nltk.download('punkt')\n","from tqdm import tqdm\n","!mkdir json"],"metadata":{"id":"fH8aGVNCVo7v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666000717683,"user_tz":-420,"elapsed":2784,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"213a10ca-d131-456f-a757-af1b666f48e1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘json’: File exists\n"]}]},{"cell_type":"code","source":["from os import listdir\n","from os.path import isfile, join\n","onlyfiles = [f for f in listdir('/content/vietnews/data/test_tokenized') if isfile(join('/content/vietnews/data/test_tokenized', f))]"],"metadata":{"id":"uJ2vEHznVAOn","executionInfo":{"status":"ok","timestamp":1665999952328,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import json\n","part = []\n","part_index = 0\n","count = 0\n","for file in onlyfiles:\n","    with open('/content/vietnews/data/test_tokenized/'+file,'r') as f:\n","        doc = f.readlines()\n","        title = doc[0].replace('\\n','')\n","        sum = doc[2].replace('\\n','')\n","        content = []\n","        for i in range(4,len(doc)):\n","            if doc[i] != '\\n':\n","                content.append(doc[i].replace('\\n',''))\n","            else:\n","                break\n","    if len(content)>5:\n","        segmented_goldsum = [title] + tokenize.sent_tokenize(sum)\n","        part.append({\"src\":[tokenize.word_tokenize(x) for x in content], \"tgt\":[tokenize.word_tokenize(x) for x in segmented_goldsum]})\n","        count += 1\n","        if count == 2000:\n","            with open(f\"/content/json/cnndm_sample.test.{part_index}.json\", \"w+\") as outfile:\n","                json.dump(part, outfile)\n","            part = []\n","            part_index += 1\n","            count = 0\n","with open(f\"/content/json/cnndm_sample.test.{part_index}.json\", \"w+\") as outfile:\n","    json.dump(part, outfile)\n","part_index += 1"],"metadata":{"id":"I61-lVgrUSKj","executionInfo":{"status":"ok","timestamp":1666003312715,"user_tz":-420,"elapsed":99953,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["!rm -rf json"],"metadata":{"id":"sqY_OXfsaxno","executionInfo":{"status":"ok","timestamp":1666003155115,"user_tz":-420,"elapsed":547,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["content = []\n","for i in range(4,len(doc)):\n","    if doc[i] != '\\n':\n","        content.append(doc[i].replace('\\n',''))\n","    else:\n","        break"],"metadata":{"id":"j6E1eF04W33H","executionInfo":{"status":"ok","timestamp":1666000376510,"user_tz":-420,"elapsed":637,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["title = doc[0].replace('\\n','')\n","sum = doc[2].replace('\\n','')"],"metadata":{"id":"QU7BeisQYPfL","executionInfo":{"status":"ok","timestamp":1666000685450,"user_tz":-420,"elapsed":2,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["title"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"e7YLRseUYRhK","executionInfo":{"status":"ok","timestamp":1666000691065,"user_tz":-420,"elapsed":380,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"c76aa2f9-d1e9-4d5a-f181-b435149b343c"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Bản_án cho đối_tượng giả_danh công_an để lừa_đảo'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["[title] + tokenize.sent_tokenize(sum)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfmjT_F8YSz0","executionInfo":{"status":"ok","timestamp":1666000990692,"user_tz":-420,"elapsed":2,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"dcb23386-c5af-4275-9087-e6ce42d6341f"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Bản_án cho đối_tượng giả_danh công_an để lừa_đảo',\n"," 'Ngày 25/2 , TAND TP.',\n"," 'Đà_Nẵng tuyên_phạt Hồ_Xuân_Huy ( SN 1994 ) , ngụ quận Hải_Châu , 12 năm tù về tội Lừa_đảo chiếm_đoạt tài_sản .']"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIEUTBINW8WE","executionInfo":{"status":"ok","timestamp":1666000383583,"user_tz":-420,"elapsed":369,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"7c7c2786-abf0-4d3b-ae8c-181c9171c953"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Theo lời khai của Huy tại phiên_toà , để có tiền sử_dụng cá_nhân , Huy “ nổ ” là sĩ_quan cục Phòng_chống ma_tuý của bộ Công_an đóng tại TP. Đà_Nẵng , có nguồn mua ô_tô thanh_lý giá rẻ , và khả_năng chạy việc vào ngành công_an .',\n"," 'Chỉ với lời “ nổ ” này , từ tháng 10/2016 đến 9/2017 , nhiều người đã bị lừa_đảo với tổng_số tiền 3,2 tỷ đồng .',\n"," 'Trong đó , người bị Huy lừa nhiều nhất là vợ_chồng ông Bảo_Th . , ngụ quận Hải_Châu .',\n"," 'Huy giới_thiệu với cặp vợ_chồng này mình có suất mua ô_tô thanh_lý giá rẻ và rủ họ mua cùng .',\n"," 'Tin lời , vợ_chồng ông Th .',\n"," 'đưa cho Huy hơn 1 tỷ đồng .',\n"," 'Cùng thủ_đoạn , Huy lừa thêm ông Nguyễn_Tấn_T. 970 triệu đồng , Lê_Quốc_Th .',\n"," '400 triệu đồng , Trần_Nhật_S. 300 triệu đồng …',\n"," 'Sau chiêu_thức mua xe thanh_lý , Huy chuyển sang giả_vờ có khả_năng xin việc vào ngành công_an .',\n"," 'Với chiêu_thức này , Huy lừa vợ_chồng ông Đinh_Ngọc_H. 250 triệu đồng .',\n"," 'Ngoài_ra , Huy hứa_hẹn , tháng 3/2017 sẽ đưa kết_quả cho con ông H. đi làm_việc .',\n"," 'Tuy_nhiên , sau nhiều lần hẹn mà không có quyết_định tuyển_dụng , ông H. đã gửi đơn tố_cáo đến cơ_quan Công_an .',\n"," 'Từ đó , những hành_vi sai_trái của Huy lần_lượt được truy ra .']"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["doc[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SaeNctAbUshs","executionInfo":{"status":"ok","timestamp":1666000582848,"user_tz":-420,"elapsed":13,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"f0aa0c67-98d5-4cc6-ed82-bc711ff8186f"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Bản_án cho đối_tượng giả_danh công_an để lừa_đảo\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["doc[4:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2EzjwEIVm-o","executionInfo":{"status":"ok","timestamp":1666000177385,"user_tz":-420,"elapsed":364,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"9128ff8b-d472-4930-b02c-ed39d2568682"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Theo lời khai của Huy tại phiên_toà , để có tiền sử_dụng cá_nhân , Huy “ nổ ” là sĩ_quan cục Phòng_chống ma_tuý của bộ Công_an đóng tại TP. Đà_Nẵng , có nguồn mua ô_tô thanh_lý giá rẻ , và khả_năng chạy việc vào ngành công_an .\\n',\n"," 'Chỉ với lời “ nổ ” này , từ tháng 10/2016 đến 9/2017 , nhiều người đã bị lừa_đảo với tổng_số tiền 3,2 tỷ đồng .\\n',\n"," 'Trong đó , người bị Huy lừa nhiều nhất là vợ_chồng ông Bảo_Th . , ngụ quận Hải_Châu .\\n',\n"," 'Huy giới_thiệu với cặp vợ_chồng này mình có suất mua ô_tô thanh_lý giá rẻ và rủ họ mua cùng .\\n',\n"," 'Tin lời , vợ_chồng ông Th .\\n',\n"," 'đưa cho Huy hơn 1 tỷ đồng .\\n',\n"," 'Cùng thủ_đoạn , Huy lừa thêm ông Nguyễn_Tấn_T. 970 triệu đồng , Lê_Quốc_Th .\\n',\n"," '400 triệu đồng , Trần_Nhật_S. 300 triệu đồng …\\n',\n"," 'Sau chiêu_thức mua xe thanh_lý , Huy chuyển sang giả_vờ có khả_năng xin việc vào ngành công_an .\\n',\n"," 'Với chiêu_thức này , Huy lừa vợ_chồng ông Đinh_Ngọc_H. 250 triệu đồng .\\n',\n"," 'Ngoài_ra , Huy hứa_hẹn , tháng 3/2017 sẽ đưa kết_quả cho con ông H. đi làm_việc .\\n',\n"," 'Tuy_nhiên , sau nhiều lần hẹn mà không có quyết_định tuyển_dụng , ông H. đã gửi đơn tố_cáo đến cơ_quan Công_an .\\n',\n"," 'Từ đó , những hành_vi sai_trái của Huy lần_lượt được truy ra .\\n',\n"," '\\n',\n"," 'Huy tại phiên_toà .\\n']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import json\n","part = []\n","part_index = 0\n","count = 0\n","#for i in tqdm(range(len(df.index))):\n","for i in tqdm(range(len(df.index))):\n","    segmented_content = rdrsegmenter.word_segment(df.iloc[i]['content'])[:-2]\n","    len(segmented_content)\n","    if len(segmented_content)>5:\n","        sapo = df.iloc[i]['sapo']\n","        if sapo == df.iloc[i]['sapo']:\n","            segmented_goldsum = [rdrsegmenter.word_segment(df.iloc[i]['title'])[0]+'.']+rdrsegmenter.word_segment(sapo)\n","            part.append({\"src\":[tokenize.word_tokenize(x) for x in segmented_content], \"tgt\":[tokenize.word_tokenize(x) for x in segmented_goldsum]})\n","            count += 1\n","    if count == 2000:\n","        with open(f\"/content/json/cnndm_sample.train.{part_index}.json\", \"w+\") as outfile:\n","            json.dump(part, outfile)\n","        part = []\n","        part_index += 1\n","        count = 0\n","with open(f\"/content/json/cnndm_sample.train.{part_index}.json\", \"w+\") as outfile:\n","    json.dump(part, outfile)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5KTh3sKXkZ5","executionInfo":{"status":"ok","timestamp":1665673713150,"user_tz":-420,"elapsed":5810162,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"3d9ebe50-a120-49fe-84ca-4ab1df4bb886"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1721156/1721156 [10:52:50<00:00, 43.94it/s]\n"]}]},{"cell_type":"code","source":["!cp /content/PreSumm/src/others/added_vocab.txt /content"],"metadata":{"id":"Wbk_niCQj4cP","executionInfo":{"status":"ok","timestamp":1666001671005,"user_tz":-420,"elapsed":335,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/chaoswithinyou/PreSumm/master/src/others/added_vocab.txt"],"metadata":{"id":"xHzY9fl_7eml","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666001672973,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"cc4addae-3822-4542-a23b-5752d633d668"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-17 10:14:33--  https://raw.githubusercontent.com/chaoswithinyou/PreSumm/master/src/others/added_vocab.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 23 [text/plain]\n","Saving to: ‘added_vocab.txt.1’\n","\n","\radded_vocab.txt.1     0%[                    ]       0  --.-KB/s               \radded_vocab.txt.1   100%[===================>]      23  --.-KB/s    in 0s      \n","\n","2022-10-17 10:14:33 (813 KB/s) - ‘added_vocab.txt.1’ saved [23/23]\n","\n"]}]},{"cell_type":"code","source":["!python /content/PreSumm/src/preprocess.py -mode format_to_bert -raw_path /content/json -save_path /content/bert  -lower -n_cpus 1 -log_file /content/PreSumm/logs/preprocess.log"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSOGgNCplU3q","executionInfo":{"status":"ok","timestamp":1666003420686,"user_tz":-420,"elapsed":87224,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"4a4b99a0-ed57-44f3-c89e-bf23979589da"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n","[]\n","[('test', '/content/json/cnndm_sample.test.4.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.4.bert.pt'), ('test', '/content/json/cnndm_sample.test.3.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.3.bert.pt'), ('test', '/content/json/cnndm_sample.test.11.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.11.bert.pt'), ('test', '/content/json/cnndm_sample.test.7.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.7.bert.pt'), ('test', '/content/json/cnndm_sample.test.2.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.2.bert.pt'), ('test', '/content/json/cnndm_sample.test.5.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.5.bert.pt'), ('test', '/content/json/cnndm_sample.test.9.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.9.bert.pt'), ('test', '/content/json/cnndm_sample.test.10.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.10.bert.pt'), ('test', '/content/json/cnndm_sample.test.1.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.1.bert.pt'), ('test', '/content/json/cnndm_sample.test.0.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.0.bert.pt'), ('test', '/content/json/cnndm_sample.test.6.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.6.bert.pt'), ('test', '/content/json/cnndm_sample.test.8.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/bert', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/bert/cnndm_sample.test.8.bert.pt')]\n","[2022-10-17 10:42:15,422 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:42:15,617 INFO] Processing /content/json/cnndm_sample.test.4.json\n","[2022-10-17 10:42:21,372 INFO] Processed instances 2000\n","[2022-10-17 10:42:21,372 INFO] Saving to /content/bert/cnndm_sample.test.4.bert.pt\n","[2022-10-17 10:42:22,691 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:42:22,805 INFO] Processing /content/json/cnndm_sample.test.3.json\n","[2022-10-17 10:42:28,323 INFO] Processed instances 2000\n","[2022-10-17 10:42:28,323 INFO] Saving to /content/bert/cnndm_sample.test.3.bert.pt\n","[2022-10-17 10:42:29,557 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:42:29,674 INFO] Processing /content/json/cnndm_sample.test.11.json\n","[2022-10-17 10:42:31,399 INFO] Processed instances 626\n","[2022-10-17 10:42:31,399 INFO] Saving to /content/bert/cnndm_sample.test.11.bert.pt\n","[2022-10-17 10:42:31,986 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:42:32,104 INFO] Processing /content/json/cnndm_sample.test.7.json\n","[2022-10-17 10:42:37,691 INFO] Processed instances 2000\n","[2022-10-17 10:42:37,691 INFO] Saving to /content/bert/cnndm_sample.test.7.bert.pt\n","[2022-10-17 10:42:38,924 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:42:39,042 INFO] Processing /content/json/cnndm_sample.test.2.json\n","[2022-10-17 10:42:44,795 INFO] Processed instances 2000\n","[2022-10-17 10:42:44,795 INFO] Saving to /content/bert/cnndm_sample.test.2.bert.pt\n","[2022-10-17 10:42:46,100 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:42:46,213 INFO] Processing /content/json/cnndm_sample.test.5.json\n","[2022-10-17 10:42:52,160 INFO] Processed instances 2000\n","[2022-10-17 10:42:52,160 INFO] Saving to /content/bert/cnndm_sample.test.5.bert.pt\n","[2022-10-17 10:42:53,638 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:42:53,806 INFO] Processing /content/json/cnndm_sample.test.9.json\n","[2022-10-17 10:43:02,174 INFO] Processed instances 2000\n","[2022-10-17 10:43:02,174 INFO] Saving to /content/bert/cnndm_sample.test.9.bert.pt\n","[2022-10-17 10:43:03,429 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:43:03,549 INFO] Processing /content/json/cnndm_sample.test.10.json\n","[2022-10-17 10:43:09,256 INFO] Processed instances 2000\n","[2022-10-17 10:43:09,256 INFO] Saving to /content/bert/cnndm_sample.test.10.bert.pt\n","[2022-10-17 10:43:10,498 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:43:10,729 INFO] Processing /content/json/cnndm_sample.test.1.json\n","[2022-10-17 10:43:18,808 INFO] Processed instances 2000\n","[2022-10-17 10:43:18,808 INFO] Saving to /content/bert/cnndm_sample.test.1.bert.pt\n","[2022-10-17 10:43:20,105 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:43:20,217 INFO] Processing /content/json/cnndm_sample.test.0.json\n","[2022-10-17 10:43:25,873 INFO] Processed instances 2000\n","[2022-10-17 10:43:25,873 INFO] Saving to /content/bert/cnndm_sample.test.0.bert.pt\n","[2022-10-17 10:43:27,135 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:43:27,251 INFO] Processing /content/json/cnndm_sample.test.6.json\n","[2022-10-17 10:43:32,816 INFO] Processed instances 2000\n","[2022-10-17 10:43:32,817 INFO] Saving to /content/bert/cnndm_sample.test.6.bert.pt\n","[2022-10-17 10:43:34,069 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-17 10:43:34,184 INFO] Processing /content/json/cnndm_sample.test.8.json\n","[2022-10-17 10:43:39,782 INFO] Processed instances 2000\n","[2022-10-17 10:43:39,782 INFO] Saving to /content/bert/cnndm_sample.test.8.bert.pt\n"]}]},{"cell_type":"code","source":["import shutil\n","shutil.make_archive('test_vnds', 'zip', '/content/bert')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"pT3JiVY1kx0C","executionInfo":{"status":"ok","timestamp":1666003450361,"user_tz":-420,"elapsed":8210,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"bfa33221-5239-4b97-bad5-951bbe809611"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/test_vnds.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["!cp /content/test_vnds.zip /content/drive/MyDrive/z_inf_data"],"metadata":{"id":"Grg8-jYGuKfi","executionInfo":{"status":"ok","timestamp":1666003467261,"user_tz":-420,"elapsed":391,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"uNhYSgGjcrFk","executionInfo":{"status":"ok","timestamp":1666001868246,"user_tz":-420,"elapsed":566,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["dataset = torch.load('/content/PreSumm/bert_data/cnndm_sample.test.0.bert.pt')"],"metadata":{"id":"6wE9v4eZcsUw","executionInfo":{"status":"ok","timestamp":1666001869912,"user_tz":-420,"elapsed":534,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["dataset[0]"],"metadata":{"id":"QJfhZfhZcvzC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Check lendoc"],"metadata":{"id":"v36CnYkiUjvh"}},{"cell_type":"code","source":["lendoc = []\n","for i in part:\n","    a = [item for sublist in i['src'] for item in sublist]\n","    lendoc.append(len(a))"],"metadata":{"id":"m9Yl8Ab-CS6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","for i in lendoc:\n","    if i>1000:\n","        count += 1\n","count"],"metadata":{"id":"skON6oQz9OOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lendoc"],"metadata":{"id":"3DoS3FrAKUzc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Fix vocab problems"],"metadata":{"id":"ti932c5TTdBM"}},{"cell_type":"code","source":["!pip install -U transformers"],"metadata":{"id":"d_TdQu_nrJRL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip show transformers"],"metadata":{"id":"4uXvi2oD3u5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzSAVX23eCjQ"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7k_P5JsRw8Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665304790323,"user_tz":-420,"elapsed":1918,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"3f920f34-aecb-4de4-b345-e25fa1ec76d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8789"]},"metadata":{},"execution_count":108}],"source":["dataset = torch.load(\"/content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt\")\n","len(dataset)"]},{"cell_type":"code","source":["dataset = torch.load(\"/content/drive/MyDrive/NLP/cnndm_sample.train.0.bert.pt\")\n","len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABP6Rjq0hfTx","executionInfo":{"status":"ok","timestamp":1665332044356,"user_tz":-420,"elapsed":2741,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"d56f38cf-3a15-4f9a-8c82-5ff19b146c7e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8328"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["dataset = torch.load('/content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.122.bert.pt')\n","len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kuqDwyRu_E-m","executionInfo":{"status":"ok","timestamp":1665289521017,"user_tz":-420,"elapsed":363,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"2ef5bd03-d02d-4657-c28b-e1058760b8de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHrfuY06eJPL"},"outputs":[],"source":["dataset[0]"]},{"cell_type":"code","source":["!pip install -U transformers"],"metadata":{"id":"FMYIdaGUJIbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModel, AutoTokenizer, PhobertTokenizer\n","\n","phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n","sentence = 'Chúng_tôi là những nghiên_cứu_viên .'  \n","\n","input_ids = torch.tensor([tokenizer.encode(sentence)])\n","\n","with torch.no_grad():\n","    features = phobert(input_ids)  # Models outputs are now tuples\n","\n","## With TensorFlow 2.0+:\n","# from transformers import TFAutoModel\n","# phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")"],"metadata":{"id":"LLdET1xttdNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import collections\n","def load_vocab(vocab_file):\n","    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n","    vocab = collections.OrderedDict()\n","    index = 0\n","    with open('/content/PreSumm/src/others/added_vocab.txt', \"r\", encoding=\"utf-8\") as reader:\n","        while True:\n","            token = reader.readline()\n","            if not token:\n","                break\n","            token = token.strip()\n","            token = token.split()\n","            vocab[token[0]] = index\n","            index += 1\n","    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n","        while True:\n","            token = reader.readline()\n","            if not token:\n","                break\n","            token = token.strip()\n","            token = token.split()\n","            vocab[token[0]] = index\n","            index += 1\n","    last_1 = list(vocab.keys())[-1]\n","    last_2 = list(vocab.keys())[-2]\n","    last_3 = list(vocab.keys())[-3]\n","    vocab['[unused0]'] = vocab[last_3]\n","    vocab['[unused1]'] = vocab[last_2]\n","    vocab['[unused2]'] = vocab[last_1]\n","    del vocab[last_1]\n","    del vocab[last_2]\n","    del vocab[last_3]\n","    vocab['[mask]'] = index\n","    return vocab"],"metadata":{"id":"Mr3q11ABJNVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRGlE6rKJys5","executionInfo":{"status":"ok","timestamp":1665124690435,"user_tz":-420,"elapsed":1001,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"b3a8d64d-75c8-4358-f1f0-c726e9102bd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-07 06:38:08--  https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt\n","Resolving huggingface.co (huggingface.co)... 52.5.54.249, 54.210.225.113, 44.195.102.200, ...\n","Connecting to huggingface.co (huggingface.co)|52.5.54.249|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 895321 (874K) [text/plain]\n","Saving to: ‘vocab.txt’\n","\n","vocab.txt           100%[===================>] 874.34K  --.-KB/s    in 0.1s    \n","\n","2022-10-07 06:38:09 (6.34 MB/s) - ‘vocab.txt’ saved [895321/895321]\n","\n"]}]},{"cell_type":"code","source":["!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt"],"metadata":{"id":"zJTQWMpnR_uw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab = load_vocab('/content/vocab.txt')"],"metadata":{"id":"3BsB_8g0KHOk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(vocab.items())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0BcJPNLKQU2","executionInfo":{"status":"ok","timestamp":1665142586635,"user_tz":-420,"elapsed":5,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"cc98b724-6537-44a3-9457-4c1fffffa444"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64001"]},"metadata":{},"execution_count":267}]},{"cell_type":"code","source":["idx2word = {v: k for k, v in vocab.items()}"],"metadata":{"id":"_JmaJCkiLW0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx2word[64000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zYblvAC1Lc7L","executionInfo":{"status":"ok","timestamp":1665126562664,"user_tz":-420,"elapsed":6,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"fdd16b70-f208-4bc2-c725-41eec5531052"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[mask]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["vocab['[unused1]'] = vocab.pop(list(vocab.keys())[-2])"],"metadata":{"id":"uh2edijBQIzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab['[unused1]']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNZiiX_xL3Bo","executionInfo":{"status":"ok","timestamp":1665126145819,"user_tz":-420,"elapsed":309,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"d11f622c-5bb7-4e4e-bbd0-0b7235a24f9e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["63997"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","sep_token = '[SEP]'\n","cls_token = '[CLS]'\n","pad_token = '[PAD]'\n","tgt_bos = '[unused0]'\n","tgt_eos = '[unused1]'\n","tgt_sent_split = '[unused2]'\n","sep_vid = tokenizer.vocab[sep_token]\n","cls_vid = tokenizer.vocab[cls_token]\n","pad_vid = tokenizer.vocab[pad_token]"],"metadata":{"id":"H9zYwjMl6QZm"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["h5_O0aEkL-eR","iqrkv9UPLpZM","dUashisuLdGz","hCjZhpnLTC6f","v36CnYkiUjvh","ti932c5TTdBM"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}