{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["yZ0CHzf-nG5F"],"authorship_tag":"ABX9TyPzUhYwoFozuI1vshyq+eCu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9b4830cdb35b42829c413cbed6b76bc2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aeab30ce0ca94ee38b43a716ec60735c","IPY_MODEL_52c380f9a4de4ebc97b8b004f60bb6e9","IPY_MODEL_2c829b54ee594123852f8982f2b6c0d5"],"layout":"IPY_MODEL_81a0f509aa8d4ccca8dba2ca596ef4f1"}},"aeab30ce0ca94ee38b43a716ec60735c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9b266e1d9914686a6fa1b6a8bcde287","placeholder":"​","style":"IPY_MODEL_40f08ddb248b449899280555c558de2f","value":"Downloading: 100%"}},"52c380f9a4de4ebc97b8b004f60bb6e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98ee8c4d002343e995b881dfa19c2aaa","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bc5306fe3e642388f10637810f4a749","value":557}},"2c829b54ee594123852f8982f2b6c0d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_153799631b2e4008aa0360ec1346a640","placeholder":"​","style":"IPY_MODEL_f0c561719b824c119159cd68874e53f3","value":" 557/557 [00:00&lt;00:00, 13.3kB/s]"}},"81a0f509aa8d4ccca8dba2ca596ef4f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b266e1d9914686a6fa1b6a8bcde287":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40f08ddb248b449899280555c558de2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98ee8c4d002343e995b881dfa19c2aaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bc5306fe3e642388f10637810f4a749":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"153799631b2e4008aa0360ec1346a640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0c561719b824c119159cd68874e53f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"036ccc0b6b80413ab97241bbc917fc86":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3216ee31593640a7b034cfbf46685b97","IPY_MODEL_1130a42257c34958a0f9bcb8217dacea","IPY_MODEL_36e06e27fc494816a80f88f22c267dd7"],"layout":"IPY_MODEL_2387b168953646f59bbac35837cd4a33"}},"3216ee31593640a7b034cfbf46685b97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2fc64db290c4f79a260248cce95f01a","placeholder":"​","style":"IPY_MODEL_b9c14618765b4e2782c4891171369511","value":"Downloading: 100%"}},"1130a42257c34958a0f9bcb8217dacea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffbd70c68c1e40b2966af609e67320cf","max":542923308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d317fc8a5744ae88f4c6bfa753c44f8","value":542923308}},"36e06e27fc494816a80f88f22c267dd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8655fdead3420297faec3a2b9380c8","placeholder":"​","style":"IPY_MODEL_c31e6f29ebe74514a6e65064cb079bbf","value":" 543M/543M [00:10&lt;00:00, 47.3MB/s]"}},"2387b168953646f59bbac35837cd4a33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2fc64db290c4f79a260248cce95f01a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c14618765b4e2782c4891171369511":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffbd70c68c1e40b2966af609e67320cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d317fc8a5744ae88f4c6bfa753c44f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df8655fdead3420297faec3a2b9380c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c31e6f29ebe74514a6e65064cb079bbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3edc5490a56144029266a06f66cc6d12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fde0c510116e46519f3dca7a609bff60","IPY_MODEL_5f531cd89ae6445c9fe68cc0a07c6b56","IPY_MODEL_37d12ebc830f485583b4a2afb25219b8"],"layout":"IPY_MODEL_160c30ba4f90453ea17dc377aaf28819"}},"fde0c510116e46519f3dca7a609bff60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7dc15cfa0034816a19d8d513f08e04b","placeholder":"​","style":"IPY_MODEL_31791ebb15d54c3382e71c6e0ec00e3a","value":"Downloading: 100%"}},"5f531cd89ae6445c9fe68cc0a07c6b56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b20768db23dd45eaa8ef5fa3e5cb73d5","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a3868ba46024469a212ade31f06c580","value":895321}},"37d12ebc830f485583b4a2afb25219b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_209c7380212e495cafc171e4cd240152","placeholder":"​","style":"IPY_MODEL_1bcbc6872e91417abd332f3eb383e79d","value":" 895k/895k [00:00&lt;00:00, 1.29MB/s]"}},"160c30ba4f90453ea17dc377aaf28819":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7dc15cfa0034816a19d8d513f08e04b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31791ebb15d54c3382e71c6e0ec00e3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b20768db23dd45eaa8ef5fa3e5cb73d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a3868ba46024469a212ade31f06c580":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"209c7380212e495cafc171e4cd240152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bcbc6872e91417abd332f3eb383e79d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"334f31698d2d4f96abbc943d5d709446":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34d8911b63a5468186a8af6f974ab348","IPY_MODEL_1e65d37d015c43cf91940478bca73050","IPY_MODEL_ca17f119151f4d7c97e1bdb3d9b75ab7"],"layout":"IPY_MODEL_ca26996ac48e4454a7add8e5ca1e771d"}},"34d8911b63a5468186a8af6f974ab348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87664898643442349000852374aee29b","placeholder":"​","style":"IPY_MODEL_a2ce4affc2c64e77b1e2d7158ecfe082","value":"Downloading: 100%"}},"1e65d37d015c43cf91940478bca73050":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d38490c52c14928b329c68d5b7ca6e9","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2a696c4d683433db96f92c0f09c33b5","value":1135173}},"ca17f119151f4d7c97e1bdb3d9b75ab7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33b727c01f0d424aace4f2a5991d44fe","placeholder":"​","style":"IPY_MODEL_c7f20897ada649d9b4a1dbc7025e4a32","value":" 1.14M/1.14M [00:00&lt;00:00, 4.18MB/s]"}},"ca26996ac48e4454a7add8e5ca1e771d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87664898643442349000852374aee29b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ce4affc2c64e77b1e2d7158ecfe082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d38490c52c14928b329c68d5b7ca6e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2a696c4d683433db96f92c0f09c33b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33b727c01f0d424aace4f2a5991d44fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7f20897ada649d9b4a1dbc7025e4a32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#stuff"],"metadata":{"id":"yZ0CHzf-nG5F"}},{"cell_type":"code","source":["!rm -rf /content/..."],"metadata":{"id":"ymhG4-9XnJ2a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Vietnamese Word Segmentation (vncorenlp and UITws)"],"metadata":{"id":"YKtjpO1-gzA1"}},{"cell_type":"markdown","source":["vncorenlp"],"metadata":{"id":"S7QpP3tjhFQY"}},{"cell_type":"code","source":["!pip3 install py_vncorenlp"],"metadata":{"id":"Gv3LYh1XhKdi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import py_vncorenlp\n","import os\n","cwd = os.getcwd()\n","py_vncorenlp.download_model(save_dir=cwd)\n","rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir=cwd)"],"metadata":{"id":"e4QjgrKggyp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for single text\n","segmented_text = rdrsegmenter.word_segment(text)"],"metadata":{"id":"R7A8NzhBhpNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for list of sentences\n","segmented_texts = [rdrsegmenter.word_segment(comment)[0] for comment in dataset['train']['sentence']]"],"metadata":{"id":"twDN3L6DhMpW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["UITws"],"metadata":{"id":"8QmC92nchxjX"}},{"cell_type":"code","source":["!pip3 install --user gitdir\n","!/root/.local/bin/gitdir https://github.com/chaoswithinyou/nlp_tools_ndsl/tree/main/word_segmentation"],"metadata":{"id":"2Rx3T1BZhz6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from word_segmentation.UITws import word_segment"],"metadata":{"id":"wPsK9aUfh70s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for single text\n","word_segment(t, single_text=True)"],"metadata":{"id":"B2N-xYkNiBBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for list of sentence\n","word_segment(t)"],"metadata":{"id":"iX5hon6yiBat"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Vietnamese Word2vec (PhoW2V)"],"metadata":{"id":"R1_KXf5kePMi"}},{"cell_type":"code","source":["import os\n","cwd = os.getcwd()"],"metadata":{"id":"-DTjHqzp9Mz_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile(cwd+'/word2vec_vi_words_100dims.zip', 'r') as zip_ref:\n","    zip_ref.extractall(cwd)"],"metadata":{"id":"5Txyhp-l9AIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pte1zxu0dN26"},"outputs":[],"source":["# download w2v_vi_100dims\n","!gdown --id 1--bdQosASIlc3O4xN5IZ5vLfZ_yEdfBZ"]},{"cell_type":"code","source":["# download w2v_vi_300dims\n","!gdown --id 1rA7rGOEuhzfTzEiSiH-MiqWhQeR_ETTi"],"metadata":{"id":"5e7WHQghdXyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PhoW2V_300dims = pickle.load(open(cwd+'/vietnamese_PhoW2V_300dims.pickle','rb'))"],"metadata":{"id":"4u5kAW0xddPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PhoW2V_100dims = pickle.load(open(cwd+'/vietnamese_PhoW2V_00dims.pickle','rb'))"],"metadata":{"id":"-IdsxW_qdmcL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pickle.dump(net,open('/content/drive/MyDrive/NLP/imdb_sentiment.p','wb'))"],"metadata":{"id":"ItWfUqOh4G5F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#PhoW2V = [words, word2idx, vectors]\n","vietnamese_w2v = {w: PhoW2V[2][PhoW2V[1][w]] for w in PhoW2V[0]}"],"metadata":{"id":"kweuuE6Bdn7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def word2ids(sen_list, maxlen, vector_size):\n","    x = torch.zeros((len(sen_list),1,maxlen))\n","    for i in tqdm(range(len(sen_list))):\n","      doc = tokenize.word_tokenize(sen_list[i])\n","      fil_doc_w2index = []\n","      for word in doc:\n","        try:\n","          fil_doc_w2index.append(PhoW2V[1][word])\n","        except Exception:\n","          pass\n","      if len(fil_doc_w2index)<=maxlen:\n","        x[i] = torch.cat((torch.LongTensor(fil_doc_w2index),torch.zeros(maxlen-len(fil_doc_w2index)))).unsqueeze(0)\n","      else:\n","        x[i] = torch.LongTensor(fil_doc_w2index[-maxlen-1:-1]).unsqueeze(0)\n","    return x"],"metadata":{"id":"JPpZlSWYkTEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = word2ids(sen_list = segmented_texts, maxlen = 50, vector_size = 100)"],"metadata":{"id":"-31byq9jl7Hl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","def create_emb_layer_from_vector_mat(weights_matrix, non_trainable=False):\n","    weights_matrix = torch.Tensor(weights_matrix)\n","    num_embeddings, embedding_dim = weights_matrix.size()\n","    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n","    emb_layer.load_state_dict({'weight': weights_matrix})\n","    if non_trainable:\n","        emb_layer.weight.requires_grad = False\n","\n","    return emb_layer, num_embeddings, embedding_dim"],"metadata":{"id":"7cPxY2nv1u5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def __init__(self):\n","        super(Net, self).__init__()\n","        self.embedding, num_embeddings, vector_size = create_emb_layer(vectors, non_trainable=True)\n","def forward(self, x):\n","        x = self.embedding(x)"],"metadata":{"id":"qO7-x0b510Zo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#PhoBart"],"metadata":{"id":"XgV3IGliiXOZ"}},{"cell_type":"code","source":["!pip install transformers\n","from transformers import AutoModel, AutoTokenizer"],"metadata":{"id":"SVUzWlhbjVHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\")\n","bartpho_word = AutoModel.from_pretrained(\"vinai/bartpho-word\")"],"metadata":{"id":"bbXlWmH7iZsf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# segmentation_text are list of sentences(output of word segmentation), input_ids \n","input_ids = word_tokenizer(segmented_texts, return_tensors='pt', padding=True)['input_ids']"],"metadata":{"id":"YzNk7cSginAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_size = 1024\n","bartpho_word = bartpho_word.to(device)\n","def forward(self, x):\n","    with torch.no_grad():\n","        x = bartpho_word(x).last_hidden_state.unsqueeze(1)"],"metadata":{"id":"9YTB8BEVi7FY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#List of sentences to 2d list of ids"],"metadata":{"id":"hRAbRWrjgUdl"}},{"cell_type":"code","source":["from tqdm import tqdm\n","from nltk import tokenize\n","\n","def word2ids(sen_list, word2idx, maxlen, vector_size):\n","    x = torch.zeros((len(sen_list),1,maxlen))\n","    for i in tqdm(range(len(sen_list))):\n","      doc = tokenize.word_tokenize(sen_list[i])\n","      fil_doc_w2index = []\n","      for word in doc:\n","        try:\n","          fil_doc_w2index.append(word2idx[word])\n","        except Exception:\n","          pass\n","      if len(fil_doc_w2index)<=maxlen:\n","        x[i] = torch.cat((torch.LongTensor(fil_doc_w2index),torch.zeros(maxlen-len(fil_doc_w2index)))).unsqueeze(0)\n","      else:\n","        x[i] = torch.LongTensor(fil_doc_w2index[-maxlen-1:-1]).unsqueeze(0)\n","    return x"],"metadata":{"id":"NIOWVCrrgTaC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#MyDataset class"],"metadata":{"id":"nfvBz8pUzo6M"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"Pw-M2jng0BWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","  def __init__(self, x, y):\n","    self.data = x\n","    self.labels = y\n","\n","  def __len__(self):\n","    return len(self.labels)\n","  \n","  def __getitem__(self, index):\n","    return self.data[index], self.labels[index]"],"metadata":{"id":"TVKxar5uzocz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = MyDataset(input_ids, train_dataset['sentiment'])\n","test_data = MyDataset(input_ids2, test_dataset['sentiment'])"],"metadata":{"id":"KpjpHjAc0K_I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True, num_workers=2)"],"metadata":{"id":"gvm2vjS00Kmk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Accuracy class and usage"],"metadata":{"id":"tnKOF1J60SJr"}},{"cell_type":"code","source":["class Accuracy:\n","    \"\"\"A class to keep track of the accuracy while training\"\"\"\n","    def __init__(self):\n","        self.correct = 0\n","        self.total = 0\n","        \n","    def reset(self):\n","        \"\"\"Resets the internal state\"\"\"\n","        self.correct = 0\n","        self.total = 0\n","        \n","    def update(self, outputs, labels):\n","        \"\"\"\n","        Updates the internal state to later compute the overall accuracy\n","        \n","        output: the output of the network for a batch\n","        labels: the target labels\n","        \"\"\"\n","        _, predicted = torch.max(outputs.data, 1) # predicted now contains the predicted class index/label\n","        \n","        self.total += labels.size(0)\n","        self.correct += (predicted == labels).sum().item() # .item() gets the number, not the tensor\n","        #self.correct += ((outputs.data > 0.5) == labels).sum().item()\n","\n","    def compute(self):\n","        return self.correct/self.total"],"metadata":{"id":"KFVJZUbQ0cSP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_accu():\n","    net.eval()\n","    test_accuracy = Accuracy()\n","    test_accuracy.reset()        \n","    with torch.no_grad():\n","        for test_data in test_loader:\n","            # get the data points\n","            test_inputs, test_labels = test_data\n","            test_inputs, test_labels = test_inputs.to(device).long(), test_labels.to(device)\n","            # forward the data through the network\n","            test_outputs = net(test_inputs)\n","            \n","            test_accuracy.update(test_outputs, test_labels)\n","            \n","    print(\"\\nTesting Accuracy: {:.2f}%\".format(100 * test_accuracy.compute()))"],"metadata":{"id":"EzLPHA150foR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model ini and training"],"metadata":{"id":"DAz-SjyH0hM_"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","bartpho_word = bartpho_word.to(device)\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (2,vector_size))\n","        self.conv2 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (3,vector_size))\n","        self.conv3 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (4,vector_size))\n","        self.conv4 = nn.Conv2d(in_channels = 1,\n","                                out_channels = 100,\n","                                kernel_size = (5,vector_size))\n","        self.fc1 = nn.Linear(400, 3)\n","        self.dropout = nn.Dropout(0.30)\n","        self.dropout1 = nn.Dropout(0.30)\n","        self.dropout2 = nn.Dropout(0.30)\n","        self.dropout3 = nn.Dropout(0.30)\n","        self.dropout4 = nn.Dropout(0.30)\n","        self.dropout5 = nn.Dropout(0.30)\n","    def forward(self, x):\n","        with torch.no_grad():\n","            x = bartpho_word(x).last_hidden_state.unsqueeze(1)\n","        x = self.dropout(x)\n","        x1 = F.relu(self.conv1(x))\n","        x1 = self.dropout1(F.max_pool2d(x1, (x1.size()[-2],1)))\n","        x2 = F.relu(self.conv2(x))\n","        x2 = self.dropout2(F.max_pool2d(x2, (x2.size()[-2],1)))\n","        x3 = F.relu(self.conv3(x))\n","        x3 = self.dropout3(F.max_pool2d(x3, (x3.size()[-2],1)))\n","        x4 = F.relu(self.conv4(x))\n","        x4 = self.dropout4(F.max_pool2d(x4, (x4.size()[-2],1)))\n","        x = torch.flatten(torch.cat((x1,x2,x3,x4),-3),start_dim=-3)\n","        x = self.fc1(self.dropout5(x))\n","        return x\n","\n","net = Net()\n","net = net.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","#optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.5)"],"metadata":{"id":"ldY5wFho0g2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","class LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(LSTM, self).__init__()\n","        self.num_layers =  num_layers\n","        self.hidden_size = hidden_size\n","\n","        #self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","\n","        # x -> (batch_size, sequence_length, input_size) because batch_size = true\n","        self.fc1 = nn.Linear(hidden_size, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        #self.fc = nn.Linear(hidden_size, num_classes)\n","        self.dropout1 = nn.Dropout(0.30)\n","        self.dropout2 = nn.Dropout(0.30)\n","\n","    def forward(self, x):\n","        # initial hidden state size is always (num_layer, batch_size, hidden_size)\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","        #out, _ = self.rnn(x, h0)\n","        #out, _ = self.gru(x, h0)\n","        out, _ = self.lstm(x, (h0,c0))\n","        \n","        # out -> (batch_size, sequence_length, hidden_size) because batch_size = true\n","        out = out[:, -1, :] # only the last time step\n","\n","        out = F.relu(self.fc1(self.dropout1(out)))\n","        out = self.fc2(self.dropout2(out))\n","        #out = self.fc(self.dropout1(out))\n","        return out\n","\n","net = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.5)"],"metadata":{"id":"2B1SDbdh1G5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","class CNNLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(CNNLSTM, self).__init__()\n","\n","        self.weights = ResNet50_Weights.DEFAULT\n","        self.preprocess = self.weights.transforms()\n","        self.pretrained_cnn = resnet50(weights=self.weights)\n","\n","        #self.resnet.fc = nn.Sequential(nn.Linear(self.resnet.fc.in_features, 300))\n","        self.pretrained_cnn.fc = nn.Linear(self.pretrained_cnn.fc.in_features, input_size)\n","\n","        self.num_layers =  num_layers\n","        self.hidden_size = hidden_size\n","\n","\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","\n","        # x -> (batch_size, sequence_length, input_size) because batch_size = true\n","        self.fc1 = nn.Linear(hidden_size, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        self.dropout = nn.Dropout(0.40)\n","\n","    def forward(self, x):\n","        hidden = None\n","        for i in range(x.size(1)):\n","            with torch.no_grad():\n","                out = self.pretrained_cnn(self.preprocess(x[:,i,:,:,:]))\n","            out, hidden = self.lstm(out.unsqueeze(1), hidden)\n","        \n","        # out -> (batch_size, sequence_length, hidden_size) because batch_size = true\n","        out = out[:, -1, :] # only the last time step\n","\n","        out = F.relu(self.fc1(out))\n","        out = self.fc2(self.dropout(out))\n","\n","        return out\n","\n","net = CNNLSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.5)"],"metadata":{"id":"60ALb85T1CxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#net = net.float()\n","net.train()\n","live_accuracy = Accuracy()\n","\n","for epoch in range(100):  # loop over the dataset multiple times\n","    print(\"\\nStarting epoch {}\".format(epoch+1))\n","\n","    live_accuracy.reset()\n","    total = 0\n","    running_loss = 0.0\n","\n","    # to make a beautiful progress bar\n","    loader = tqdm(enumerate(train_loader), total=len(train_loader))\n","    for i, data in loader:\n","        # get the data points\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device).long(), labels.to(device)\n","        # zero the parameter gradients (else, they are accumulated)\n","        optimizer.zero_grad()\n","\n","        # forward the data through the network\n","        outputs = net(inputs)\n","        # calculate the loss given the output of the network and the target labels\n","        loss = criterion(outputs, labels)\n","        # calculate the gradients of the network w.r.t. its parameters\n","        loss.backward()\n","        # Let the optimiser take an optimization step using the calculated gradients\n","        optimizer.step()\n","        \n","        running_loss += loss\n","        total += outputs.size(0)\n","\n","        live_accuracy.update(outputs, labels)\n","        loader.set_description(\"loss: {:.5f}|acc: {:.2f}%\".format(running_loss/total,100 * live_accuracy.compute()))\n","    test_accu()\n","    net.train()\n","\n","print('Finished Training')"],"metadata":{"id":"zc-8G3h80oR8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Visualization"],"metadata":{"id":"aVqU0ksz0tIT"}},{"cell_type":"code","source":["# in test mode, we should set the 'learning_phase' flag to 0 (we don't want to use dropout)\n","get_doc_embedding = copy.deepcopy(net)\n","get_doc_embedding.fc1 = torch.nn.Identity()\n","get_doc_embedding.eval()\n","\n","num_sen = 1000\n","print('plotting embeddings of first',num_sen,'documents')\n","\n","doc_emb = get_doc_embedding(test_data.data[:num_sen].long()).detach().numpy()\n","\n","my_pca = PCA(n_components=10)\n","my_tsne = TSNE(n_components=2,perplexity=30)\n","doc_emb_pca = my_pca.fit_transform(doc_emb)\n","doc_emb_tsne = my_tsne.fit_transform(doc_emb_pca) \n","#doc_emb_tsne = my_tsne.fit_transform(doc_emb)\n","\n","labels_plt = test_data.labels[:num_sen]\n","my_colors = ['red','yellow','green']\n","\n","fig, ax = plt.subplots()\n","\n","for label in list(set(labels_plt)):\n","    idxs = [idx for idx,elt in enumerate(labels_plt) if elt==label]\n","    ax.scatter(doc_emb_tsne[idxs,0], \n","               doc_emb_tsne[idxs,1], \n","               c = my_colors[label],\n","               label=str(label),\n","               alpha=0.7,\n","               s=10)\n","\n","ax.legend(scatterpoints=1)\n","fig.suptitle('t-SNE visualization of CNN-based doc embeddings \\n (first 1000 docs from test set)',fontsize=10)\n","fig.set_size_inches(6,4)\n","#fig.savefig(path_to_plot + 'doc_embeddings_init.pdf',bbox_inches='tight')\n","fig.show()"],"metadata":{"id":"jJO96w5A0vD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zxkCnwnAZVE","executionInfo":{"status":"ok","timestamp":1665305580581,"user_tz":-420,"elapsed":13894,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"0488e2c8-72ae-44cb-d8a8-a59256491b0b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 57.2 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 37.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModel, AutoTokenizer, PhobertTokenizer\n","\n","phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n","sentence = 'Chúng_tôi là những nghiên_cứu_viên .'  \n","\n","input_ids = torch.tensor([tokenizer.encode(sentence)])\n","\n","with torch.no_grad():\n","    features = phobert(input_ids)  # Models outputs are now tuples\n","\n","## With TensorFlow 2.0+:\n","# from transformers import TFAutoModel\n","# phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234,"referenced_widgets":["9b4830cdb35b42829c413cbed6b76bc2","aeab30ce0ca94ee38b43a716ec60735c","52c380f9a4de4ebc97b8b004f60bb6e9","2c829b54ee594123852f8982f2b6c0d5","81a0f509aa8d4ccca8dba2ca596ef4f1","e9b266e1d9914686a6fa1b6a8bcde287","40f08ddb248b449899280555c558de2f","98ee8c4d002343e995b881dfa19c2aaa","8bc5306fe3e642388f10637810f4a749","153799631b2e4008aa0360ec1346a640","f0c561719b824c119159cd68874e53f3","036ccc0b6b80413ab97241bbc917fc86","3216ee31593640a7b034cfbf46685b97","1130a42257c34958a0f9bcb8217dacea","36e06e27fc494816a80f88f22c267dd7","2387b168953646f59bbac35837cd4a33","e2fc64db290c4f79a260248cce95f01a","b9c14618765b4e2782c4891171369511","ffbd70c68c1e40b2966af609e67320cf","2d317fc8a5744ae88f4c6bfa753c44f8","df8655fdead3420297faec3a2b9380c8","c31e6f29ebe74514a6e65064cb079bbf","3edc5490a56144029266a06f66cc6d12","fde0c510116e46519f3dca7a609bff60","5f531cd89ae6445c9fe68cc0a07c6b56","37d12ebc830f485583b4a2afb25219b8","160c30ba4f90453ea17dc377aaf28819","b7dc15cfa0034816a19d8d513f08e04b","31791ebb15d54c3382e71c6e0ec00e3a","b20768db23dd45eaa8ef5fa3e5cb73d5","2a3868ba46024469a212ade31f06c580","209c7380212e495cafc171e4cd240152","1bcbc6872e91417abd332f3eb383e79d","334f31698d2d4f96abbc943d5d709446","34d8911b63a5468186a8af6f974ab348","1e65d37d015c43cf91940478bca73050","ca17f119151f4d7c97e1bdb3d9b75ab7","ca26996ac48e4454a7add8e5ca1e771d","87664898643442349000852374aee29b","a2ce4affc2c64e77b1e2d7158ecfe082","6d38490c52c14928b329c68d5b7ca6e9","c2a696c4d683433db96f92c0f09c33b5","33b727c01f0d424aace4f2a5991d44fe","c7f20897ada649d9b4a1dbc7025e4a32"]},"id":"UXmRFPxUAcei","executionInfo":{"status":"ok","timestamp":1665305653743,"user_tz":-420,"elapsed":17917,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"c917c437-4297-4b27-d10e-8a4d49c52207"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b4830cdb35b42829c413cbed6b76bc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/543M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036ccc0b6b80413ab97241bbc917fc86"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/895k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3edc5490a56144029266a06f66cc6d12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"334f31698d2d4f96abbc943d5d709446"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["a = tokenizer.get_vocab()"],"metadata":{"id":"U9urmHr6AfU7","executionInfo":{"status":"ok","timestamp":1665305660173,"user_tz":-420,"elapsed":372,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["b = {v: k for k, v in a.items()}"],"metadata":{"id":"HazdWK76AzJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a['Nắng']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0_Zx-FRJzTH","executionInfo":{"status":"ok","timestamp":1665305676489,"user_tz":-420,"elapsed":385,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"4050f880-d3c0-48cb-ad6c-3458916f5f84"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15792"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["b[63997]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"dSowCO6ABauV","executionInfo":{"status":"ok","timestamp":1665127138920,"user_tz":-420,"elapsed":352,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"9f946107-12e8-4267-cb49-299efeb1502c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ັ@@'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]}]}