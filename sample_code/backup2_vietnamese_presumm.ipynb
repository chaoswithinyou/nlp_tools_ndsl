{"cells":[{"cell_type":"markdown","source":["#Initial procedure"],"metadata":{"id":"h5_O0aEkL-eR"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"PV6t4yt3QmkM","executionInfo":{"status":"ok","timestamp":1665309041359,"user_tz":-420,"elapsed":332,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"outputs":[],"source":["import os\n","cwd = os.getcwd()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17321,"status":"ok","timestamp":1665309060774,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"},"user_tz":-420},"id":"VSNz-gV1KcXn","outputId":"431c5ae6-7207-4119-ed52-55fd2b1e6370"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","#!cp /content/corpus-cate-csv-2019-24-03.7z /content/drive/MyDrive/NLP"]},{"cell_type":"code","source":["from IPython.display import clear_output "],"metadata":{"id":"cDG4QCIMjWcQ","executionInfo":{"status":"ok","timestamp":1665309060776,"user_tz":-420,"elapsed":23,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Download presumm english dataset\n"],"metadata":{"id":"dUashisuLdGz"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"EOovIAxxQDZX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665289324970,"user_tz":-420,"elapsed":7344,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"da8439b4-2732-4cbc-f08a-b39b665c16dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1DN7ClZCCXsk2KegmC6t4ClBwtAf5galI\n","To: /content/bert_data_cnndm_final.zip\n","100% 1.14G/1.14G [00:05<00:00, 202MB/s]\n"]}],"source":["try:\n","    f = open(cwd+\"/bert_data_cnndm_final.zip\")\n","    # Do something with the file\n","    f.close()\n","except IOError:\n","    !gdown 1DN7ClZCCXsk2KegmC6t4ClBwtAf5galI"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"JY_qif9SQsDR","executionInfo":{"status":"ok","timestamp":1665289363396,"user_tz":-420,"elapsed":35147,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"outputs":[],"source":["import zipfile\n","with zipfile.ZipFile(cwd+\"/bert_data_cnndm_final.zip\", 'r') as zip_ref:\n","    zip_ref.extractall('/content/PreSumm/bert_data')"]},{"cell_type":"markdown","source":["#Setup presumm"],"metadata":{"id":"iqrkv9UPLpZM"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2193,"status":"ok","timestamp":1665309075147,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"},"user_tz":-420},"id":"zxlnYI5xSFzT","outputId":"1eb6bb23-05c5-402a-bf43-bf06aa5772c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'PreSumm'...\n","remote: Enumerating objects: 261, done.\u001b[K\n","remote: Counting objects: 100% (50/50), done.\u001b[K\n","remote: Compressing objects: 100% (33/33), done.\u001b[K\n","remote: Total 261 (delta 29), reused 33 (delta 16), pack-reused 211\u001b[K\n","Receiving objects: 100% (261/261), 13.08 MiB | 19.58 MiB/s, done.\n","Resolving deltas: 100% (125/125), done.\n"]}],"source":["!git clone https://github.com/chaoswithinyou/PreSumm"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"rGYPpdNLz9_5","executionInfo":{"status":"ok","timestamp":1665309181079,"user_tz":-420,"elapsed":103021,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"outputs":[],"source":["!pip install -r /content/PreSumm/requirements.txt\n","clear_output()"]},{"cell_type":"code","source":["!rm -rf /content/PreSumm"],"metadata":{"id":"1ur6NemJ9_O7","executionInfo":{"status":"ok","timestamp":1665305947812,"user_tz":-420,"elapsed":415,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/NLP/cnndm_sample.train.0.bert.pt /content/PreSumm/bert_data"],"metadata":{"id":"3bpaLdFFMzpE","executionInfo":{"status":"ok","timestamp":1665309181614,"user_tz":-420,"elapsed":545,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WohhIXNRRAgo"},"outputs":[],"source":["!python /content/PreSumm/src/train.py -other_bert phobert -task ext -mode train -bert_data_path /content/PreSumm/bert_data/cnndm_sample -model_path MODEL_PATH -lr 2e-3 -report_every 1 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -ext_dropout 0.1 -visible_gpus -1 -log_file /content/PreSumm/logs/ext_bert_cnndm -use_interval true -warmup_steps 10000 -max_pos 256"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"1bIQ-2Wtkldb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665310185508,"user_tz":-420,"elapsed":1003414,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"33ed3f8d-38ae-4f23-fb01-ffb1cf994e6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-10-09 09:53:05,814 INFO] Device ID 0\n","[2022-10-09 09:53:05,814 INFO] Device cuda\n","[2022-10-09 09:53:06,017 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/config.json not found in cache or force_download set to True, downloading to /temp/tmpjtf8iqn_\n","Downloading: 100% 557/557 [00:00<00:00, 380kB/s]\n","[2022-10-09 09:53:06,196 INFO] storing https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/config.json in cache at ../temp/79491498b21ce305d6608cb48027449e179c04ccd8e9bba4a2d70cfd7a5ff8de.5b0cadb81413f220dedd6e1118bc44fa81aa0cdac6d9f9c2007d295cd3b67e6f\n","[2022-10-09 09:53:06,196 INFO] creating metadata file for ../temp/79491498b21ce305d6608cb48027449e179c04ccd8e9bba4a2d70cfd7a5ff8de.5b0cadb81413f220dedd6e1118bc44fa81aa0cdac6d9f9c2007d295cd3b67e6f\n","[2022-10-09 09:53:06,197 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/config.json from cache at ../temp/79491498b21ce305d6608cb48027449e179c04ccd8e9bba4a2d70cfd7a5ff8de.5b0cadb81413f220dedd6e1118bc44fa81aa0cdac6d9f9c2007d295cd3b67e6f\n","[2022-10-09 09:53:06,197 INFO] Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 64001\n","}\n","\n","[2022-10-09 09:53:06,413 INFO] https://cdn.huggingface.co/vinai/phobert-base/pytorch_model.bin not found in cache or force_download set to True, downloading to /temp/tmpyk10txbb\n","Downloading: 100% 543M/543M [00:09<00:00, 59.7MB/s]\n","[2022-10-09 09:53:15,697 INFO] storing https://cdn.huggingface.co/vinai/phobert-base/pytorch_model.bin in cache at ../temp/24b36891c4f22e7d527b0b02d9e26312e659c562ff5c5e2234fb9247df41ca26.3acb65d6dcb44dd7bb1dbdeca984082fdc18ca1412f2f81a9cc7f0d2c23fe0f8\n","[2022-10-09 09:53:15,697 INFO] creating metadata file for ../temp/24b36891c4f22e7d527b0b02d9e26312e659c562ff5c5e2234fb9247df41ca26.3acb65d6dcb44dd7bb1dbdeca984082fdc18ca1412f2f81a9cc7f0d2c23fe0f8\n","[2022-10-09 09:53:15,698 INFO] loading weights file https://cdn.huggingface.co/vinai/phobert-base/pytorch_model.bin from cache at ../temp/24b36891c4f22e7d527b0b02d9e26312e659c562ff5c5e2234fb9247df41ca26.3acb65d6dcb44dd7bb1dbdeca984082fdc18ca1412f2f81a9cc7f0d2c23fe0f8\n","[2022-10-09 09:53:20,575 INFO] Weights from pretrained model not used in RobertaModel: ['roberta.embeddings.position_ids']\n","[2022-10-09 09:53:23,976 INFO] ExtSummarizer(\n","  (bert): Bert(\n","    (model): RobertaModel(\n","      (embeddings): RobertaEmbeddings(\n","        (word_embeddings): Embedding(64001, 768, padding_idx=1)\n","        (position_embeddings): Embedding(514, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (ext_layer): ExtTransformerEncoder(\n","    (pos_emb): PositionalEncoding(\n","      (dropout): Dropout(p=0.1)\n","    )\n","    (transformer_inter): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1)\n","    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","    (wo): Linear(in_features=768, out_features=1, bias=True)\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","gpu_rank 0\n","[2022-10-09 09:53:24,007 INFO] * number of parameters: 146225921\n","[2022-10-09 09:53:24,007 INFO] Start training...\n","[2022-10-09 09:53:24,713 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt, number of examples: 8328\n","[2022-10-09 09:54:26,645 INFO] Step 50/50000; xent: 3.72; lr: 0.0000001;  22 docs/s;     62 sec\n","[2022-10-09 09:55:35,574 INFO] Step 100/50000; xent: 3.06; lr: 0.0000002;  18 docs/s;    131 sec\n","[2022-10-09 09:56:44,212 INFO] Step 150/50000; xent: 2.76; lr: 0.0000003;  19 docs/s;    199 sec\n","[2022-10-09 09:57:52,674 INFO] Step 200/50000; xent: 2.75; lr: 0.0000004;  19 docs/s;    268 sec\n","[2022-10-09 09:59:01,428 INFO] Step 250/50000; xent: 2.76; lr: 0.0000005;  19 docs/s;    337 sec\n","[2022-10-09 10:00:10,597 INFO] Step 300/50000; xent: 2.79; lr: 0.0000006;  19 docs/s;    406 sec\n","[2022-10-09 10:01:18,707 INFO] Step 350/50000; xent: 2.73; lr: 0.0000007;  19 docs/s;    474 sec\n","[2022-10-09 10:02:27,424 INFO] Step 400/50000; xent: 2.73; lr: 0.0000008;  20 docs/s;    543 sec\n","[2022-10-09 10:03:36,007 INFO] Step 450/50000; xent: 2.74; lr: 0.0000009;  20 docs/s;    611 sec\n","[2022-10-09 10:04:43,989 INFO] Step 500/50000; xent: 2.76; lr: 0.0000010;  19 docs/s;    679 sec\n","[2022-10-09 10:05:53,244 INFO] Step 550/50000; xent: 2.66; lr: 0.0000011;  19 docs/s;    749 sec\n","[2022-10-09 10:07:02,062 INFO] Step 600/50000; xent: 2.75; lr: 0.0000012;  19 docs/s;    817 sec\n","[2022-10-09 10:07:45,975 INFO] Loading train dataset from /content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt, number of examples: 8328\n","[2022-10-09 10:08:12,232 INFO] Step 650/50000; xent: 2.73; lr: 0.0000013;  20 docs/s;    888 sec\n","[2022-10-09 10:09:20,775 INFO] Step 700/50000; xent: 2.64; lr: 0.0000014;  19 docs/s;    956 sec\n","Traceback (most recent call last):\n","  File \"/content/PreSumm/src/train.py\", line 151, in <module>\n","    train_ext(args, device_id)\n","  File \"/content/PreSumm/src/train_extractive.py\", line 203, in train_ext\n","    train_single_ext(args, device_id)\n","  File \"/content/PreSumm/src/train_extractive.py\", line 245, in train_single_ext\n","    trainer.train(train_iter_fct, args.train_steps)\n","  File \"/content/PreSumm/src/models/trainer_ext.py\", line 152, in train\n","    report_stats)\n","  File \"/content/PreSumm/src/models/trainer_ext.py\", line 312, in _gradient_accumulation\n","    sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/PreSumm/src/models/model_builder.py\", line 208, in forward\n","    sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n","KeyboardInterrupt\n"]}],"source":["!python /content/PreSumm/src/train.py -other_bert phobert -task ext -mode train -bert_data_path /content/PreSumm/bert_data/cnndm_sample -model_path MODEL_PATH -lr 2e-3 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -ext_dropout 0.1 -visible_gpus 0 -log_file /content/PreSumm/logs/ext_bert_cnndm -use_interval true -warmup_steps 10000 -max_pos 512"]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"IleITM8W4Jnx","executionInfo":{"status":"ok","timestamp":1665307973713,"user_tz":-420,"elapsed":454,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkZ5438a98nQ","executionInfo":{"status":"ok","timestamp":1665308039973,"user_tz":-420,"elapsed":380,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"8a110c45-7778-40e3-eaa5-4c292382b80b"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/PreSumm/src\n"]}]},{"cell_type":"code","source":["%cd /content/PreSumm/src"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BeLwnnO-FMc","executionInfo":{"status":"ok","timestamp":1665308038117,"user_tz":-420,"elapsed":400,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"97f1bc34-ae10-4dbd-9a97-60d82d2caca4"},"execution_count":136,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/PreSumm/src\n"]}]},{"cell_type":"code","source":["!python www.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOEnrdCsCFZ6","executionInfo":{"status":"ok","timestamp":1665308545115,"user_tz":-420,"elapsed":11778,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"0aac831a-64f4-4a8b-f60f-4cd368f78fa3"},"execution_count":151,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"www.py\", line 13, in <module>\n","    sent_scores, mask = model(src1, src1, src1, mm, mm)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/PreSumm/src/models/model_builder.py\", line 207, in forward\n","    top_vec = self.bert(src, segs, mask_src)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/PreSumm/src/models/model_builder.py\", line 163, in forward\n","    top_vec, _ = self.model(input_ids=x, token_type_ids=segs, attention_mask=mask)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\", line 727, in forward\n","    input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\", line 65, in forward\n","    input_ids, token_type_ids=token_type_ids, position_ids=position_ids, inputs_embeds=inputs_embeds\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\", line 174, in forward\n","    position_embeddings = self.position_embeddings(position_ids)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\", line 117, in forward\n","    self.norm_type, self.scale_grad_by_freq, self.sparse)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1506, in embedding\n","    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n","RuntimeError: index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:193\n"]}]},{"cell_type":"code","source":["# 256 khong loi 257 loi"],"metadata":{"id":"ADvq2-RhTah-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","    sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n","except:\n","    pickle.dump(self.model,open('/content/model.p','wb'))\n","    pickle.dump(src,open('/content/src.p','wb'))\n","    pickle.dump(segs,open('/content/segs.p','wb'))\n","    pickle.dump(clss,open('/content/clss.p','wb'))\n","    pickle.dump(mask,open('/content/mask.p','wb'))\n","    pickle.dump(mask_cls,open('/content/mask_cls.p','wb'))"],"metadata":{"id":"QkD3UddQRw0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import torch\n","\n","src = pickle.load(open('/content/src.p','rb'))\n","src1 = torch.zeros(11,256).long()\n","mm = torch.zeros((11,256),dtype=torch.uint8)\n","model = pickle.load(open('/content/model.p','rb'))\n","segs = pickle.load(open('/content/segs.p','rb'))\n","clss = pickle.load(open('/content/clss.p','rb'))\n","mask = pickle.load(open('/content/mask.p','rb'))\n","mask_cls = pickle.load(open('/content/mask_cls.p','rb'))\n","\n","sent_scores, mask = model(src, src1, clss, mask, mask_cls)\n","#sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n","\n","#print(model)\n","# print(src)\n","# print(segs)\n","# print(clss)\n","# print(mask)\n","# print(mask_cls)\n","\n","#print(model.bert.model.config.vocab_size)"],"metadata":{"id":"IJaD99IDOuqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["src = pickle.load(open('/content/src.p','rb'))\n","segs = pickle.load(open('/content/segs.p','rb'))\n","clss = pickle.load(open('/content/clss.p','rb'))\n","mask = pickle.load(open('/content/mask.p','rb'))\n","mask_cls = pickle.load(open('/content/mask_cls.p','rb'))"],"metadata":{"id":"MXQV4kbJ3_64","executionInfo":{"status":"ok","timestamp":1665308093276,"user_tz":-420,"elapsed":543,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":140,"outputs":[]},{"cell_type":"code","source":["sent_scores, mask = model(src, segs, clss, mask, mask_cls)"],"metadata":{"id":"0ZzAsJh8HS8L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"GX4hlQ0CPqxA","executionInfo":{"status":"ok","timestamp":1665226689694,"user_tz":-420,"elapsed":6,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["torch.max(src)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIj5tjI54ZL1","executionInfo":{"status":"ok","timestamp":1665136739543,"user_tz":-420,"elapsed":427,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"ade034ff-a929-49fe-8df8-59922fe4db12"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(59318)"]},"metadata":{},"execution_count":171}]},{"cell_type":"code","source":["torch.zeros(11,258).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrHE0k1LEj2g","executionInfo":{"status":"ok","timestamp":1665139927089,"user_tz":-420,"elapsed":348,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"5cf8053c-b722-4598-838b-64bb94e25e92"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([11, 258])"]},"metadata":{},"execution_count":255}]},{"cell_type":"code","source":["src.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2u-6TyKERbh","executionInfo":{"status":"ok","timestamp":1665308098508,"user_tz":-420,"elapsed":375,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"ceed929e-e4b3-4ff3-8193-187c2be2c043"},"execution_count":141,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 512])"]},"metadata":{},"execution_count":141}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thAQkg4__uM8"},"outputs":[],"source":["try:\n","    f = open(cwd+\"/corpus-cate-csv-2019-24-03.7z\")\n","    # Do something with the file\n","    f.close()\n","except IOError:\n","    !gdown 1-Av37aKdF6j82j1hK-p2XllTtbSNqaSc\n","#full text 1z7QNMT_H_ABKHzm2ydT_wDEI4XY6jGHW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SogcTEUGBqEV"},"outputs":[],"source":["!pip install py7zr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdH9WHQIA5AA"},"outputs":[],"source":["import py7zr\n","with py7zr.SevenZipFile(\"/content/drive/MyDrive/NLP/corpus-cate-csv-2019-24-03.7z\", mode='r') as z:\n","    z.extractall('/content/text')"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10805,"status":"ok","timestamp":1665289885494,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"},"user_tz":-420},"id":"znxu2c7TQjDT","outputId":"46196e15-1257-4169-8a66-79240b7aefbd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}],"source":["import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/NLP/Công_nghệ.csv')"]},{"cell_type":"code","source":["!pip3 install py_vncorenlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnN3CtiCVp9a","executionInfo":{"status":"ok","timestamp":1665289813070,"user_tz":-420,"elapsed":7035,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"81b9be29-407b-4c8c-9769-0643bd733e08"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting py_vncorenlp\n","  Downloading py_vncorenlp-0.1.3.tar.gz (3.9 kB)\n","Collecting pyjnius\n","  Downloading pyjnius-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius->py_vncorenlp) (1.15.0)\n","Building wheels for collected packages: py-vncorenlp\n","  Building wheel for py-vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-vncorenlp: filename=py_vncorenlp-0.1.3-py3-none-any.whl size=4309 sha256=cb4bc0c192ebb8e72dd027832eda4f0732bceb889a8f5ad138e4c5dab3e2f5b4\n","  Stored in directory: /root/.cache/pip/wheels/87/be/55/d5930c1d90a09832e9afd57a9e13801e3d16c88f5a19f777ae\n","Successfully built py-vncorenlp\n","Installing collected packages: pyjnius, py-vncorenlp\n","Successfully installed py-vncorenlp-0.1.3 pyjnius-1.4.2\n"]}]},{"cell_type":"code","source":["import py_vncorenlp\n","# import os\n","# cwd = os.getcwd()\n","py_vncorenlp.download_model(save_dir='/content')\n","rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/content')"],"metadata":{"id":"fH8aGVNCVo7v","executionInfo":{"status":"ok","timestamp":1665289819280,"user_tz":-420,"elapsed":6216,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["segmented_text = rdrsegmenter.word_segment(df.iloc[2500]['content'])"],"metadata":{"id":"pR-IJO9OVxI4","executionInfo":{"status":"ok","timestamp":1665289947076,"user_tz":-420,"elapsed":452,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["segmented_text = segmented_text[:-2]"],"metadata":{"id":"tz1Txx1JV5BQ","executionInfo":{"status":"ok","timestamp":1665289950010,"user_tz":-420,"elapsed":483,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["segmented_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LN6bf9ciBCha","executionInfo":{"status":"ok","timestamp":1665289960622,"user_tz":-420,"elapsed":441,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"f2b7b6b1-2437-4f24-91df-be29144dfbaf"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Vòng đeo tay Helo_LX , mẫu sản_phẩm mới nhất của Tập_đoàn World - một trong những tập_đoàn công_nghệ_thông_tin lớn nhất thế_giới và có uy_tín vừa ra_mắt người tiêu_dùng Việt_Nam được ví_như bác_sĩ di_động , giúp những người có triệu_chứng về huyết_áp , bệnh tim kiểm_soát tốt hơn bệnh_tình của mình .',\n"," 'Ông Antonio_De_Rosa , Giám_đốc thiết_kế đồng_hồ Helo_LX giới_thiệu sản_phẩm trong buổi ra_mắt tại Việt_Nam .',\n"," 'Helo_LX được thiết_kế nhỏ gọn , thời_trang như một chiếc đồng_hồ đeo tay nhưng lại tích_hợp rất nhiều tính_năng như : Đo huyết_áp , đo nhịp tim , đo điện_tâm_đồ , đo năng_lượng , đo tâm_trạng , calo năng_lượng tiêu_thụ và có_thể giúp cảnh_báo nguy_cơ đột_quỵ Vòng đeo tay Helo_LX được nhiều người_yêu thích công_nghệ chọn_lựa .',\n"," 'Helo_LX được đánh_giá là có sự cải_tiến lớn về mẫu_mã thiết_kế và phần_mềm , được trang_bị Chipset :',\n"," 'TZ1041 , CPU : 125 Hz , RAM :',\n"," '256KB , Bluetooth : BLE 4.0 , dung_lượng : 120mAh chế_độ sử_dụng bình_thường có_thể dùng khoảng 4-5 ngày mỗi lần sạc đầy .',\n"," 'Cảm_biến nhiệt : NJR 5310 .',\n"," 'Vòng đeo tay thông_minh cong theo cổ_tay , cảm_biến và định_vị GPS , hỗ_trợ đồng_bộ dữ_liệu với điện_thoại khi kết_nối , chống thấm nước đạt chuẩn IP68 , tương_thích hệ_điều_hành IOS và Andoid .',\n"," 'Bên cạnh đó , vòng đeo tay sử_dụng cảm_biến trọng_lực đếm được bước_đi , đo_lường nhịp sinh_học , tâm_trạng , chất_lượng giấc_ngủ , nhịp thở , nhịp tim và nhiều chỉ_số khác .']"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["len(segmented_text)"],"metadata":{"id":"2UuwgzcYWC6X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665289951084,"user_tz":-420,"elapsed":8,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"cde9f830-e0e7-421c-96c4-fd96ed328a68"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["from nltk import tokenize\n","import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pr-Cw6zWhpQ","executionInfo":{"status":"ok","timestamp":1665289798795,"user_tz":-420,"elapsed":2044,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"5cd81105-0e82-49f5-c600-fbedd706581d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["!cp /content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt /content/drive/MyDrive/NLP"],"metadata":{"id":"vBMl2hvWZHYv","executionInfo":{"status":"ok","timestamp":1665305303071,"user_tz":-420,"elapsed":954,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"JJ2b0G1hbnZF","executionInfo":{"status":"ok","timestamp":1665289787515,"user_tz":-420,"elapsed":372,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import json\n","part = []\n","#for i in tqdm(range(len(df.index))):\n","for i in tqdm(range(9000)):\n","    segmented_content = rdrsegmenter.word_segment(df.iloc[i]['content'])[:-2]\n","    if len(segmented_content)>5:\n","        sapo = df.iloc[i]['sapo']\n","        if sapo == df.iloc[i]['sapo']:\n","            segmented_goldsum = [rdrsegmenter.word_segment(df.iloc[i]['title'])[0]+'.']+rdrsegmenter.word_segment(sapo)\n","            part.append({\"src\":[tokenize.word_tokenize(x) for x in segmented_content], \"tgt\":[tokenize.word_tokenize(x) for x in segmented_goldsum]})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5KTh3sKXkZ5","executionInfo":{"status":"ok","timestamp":1665292364908,"user_tz":-420,"elapsed":219034,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"1ee7c488-2f76-459a-cf67-6c75b347aed7"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9000/9000 [03:38<00:00, 41.13it/s]\n"]}]},{"cell_type":"code","source":["len(part)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLmgB1mqAQ9y","executionInfo":{"status":"ok","timestamp":1665292364909,"user_tz":-420,"elapsed":28,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"5e97fe48-a7b2-4035-aab1-8b6d2d9b6413"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8330"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["lendoc = []\n","for i in part:\n","    a = [item for sublist in i['src'] for item in sublist]\n","    lendoc.append(len(a))"],"metadata":{"id":"m9Yl8Ab-CS6p","executionInfo":{"status":"ok","timestamp":1665292381534,"user_tz":-420,"elapsed":529,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["part[1]"],"metadata":{"id":"sWqb5WYT7RWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","for i in lendoc:\n","    if i>800:\n","        count += 1\n","count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skON6oQz9OOZ","executionInfo":{"status":"ok","timestamp":1665305896950,"user_tz":-420,"elapsed":446,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"b5ad99d9-c891-47f9-d89e-1616d48d32b8"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1302"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["lendoc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DoS3FrAKUzc","executionInfo":{"status":"ok","timestamp":1665292391997,"user_tz":-420,"elapsed":580,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"63c7632b-16d2-4cd5-f98e-07ec0bb77837"},"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[469,\n"," 286,\n"," 423,\n"," 309,\n"," 280,\n"," 244,\n"," 280,\n"," 607,\n"," 808,\n"," 726,\n"," 1024,\n"," 128,\n"," 343,\n"," 289,\n"," 222,\n"," 184,\n"," 216,\n"," 368,\n"," 874,\n"," 656,\n"," 569,\n"," 510,\n"," 180,\n"," 699,\n"," 149,\n"," 355,\n"," 2503,\n"," 307,\n"," 1036,\n"," 847,\n"," 936,\n"," 1313,\n"," 333,\n"," 294,\n"," 404,\n"," 342,\n"," 649,\n"," 171,\n"," 814,\n"," 506,\n"," 357,\n"," 501,\n"," 302,\n"," 381,\n"," 703,\n"," 385,\n"," 325,\n"," 514,\n"," 391,\n"," 446,\n"," 603,\n"," 736,\n"," 838,\n"," 234,\n"," 779,\n"," 247,\n"," 969,\n"," 1001,\n"," 758,\n"," 520,\n"," 348,\n"," 292,\n"," 616,\n"," 208,\n"," 345,\n"," 924,\n"," 420,\n"," 1458,\n"," 401,\n"," 927,\n"," 636,\n"," 195,\n"," 287,\n"," 597,\n"," 287,\n"," 636,\n"," 477,\n"," 291,\n"," 154,\n"," 430,\n"," 790,\n"," 895,\n"," 546,\n"," 193,\n"," 562,\n"," 530,\n"," 117,\n"," 511,\n"," 437,\n"," 625,\n"," 375,\n"," 587,\n"," 552,\n"," 244,\n"," 271,\n"," 561,\n"," 347,\n"," 187,\n"," 355,\n"," 205,\n"," 408,\n"," 654,\n"," 284,\n"," 515,\n"," 241,\n"," 458,\n"," 381,\n"," 486,\n"," 132,\n"," 828,\n"," 710,\n"," 233,\n"," 273,\n"," 1265,\n"," 274,\n"," 627,\n"," 216,\n"," 442,\n"," 627,\n"," 540,\n"," 937,\n"," 195,\n"," 251,\n"," 986,\n"," 254,\n"," 920,\n"," 266,\n"," 367,\n"," 362,\n"," 373,\n"," 387,\n"," 494,\n"," 188,\n"," 237,\n"," 247,\n"," 221,\n"," 138,\n"," 449,\n"," 181,\n"," 353,\n"," 932,\n"," 347,\n"," 891,\n"," 487,\n"," 620,\n"," 609,\n"," 335,\n"," 755,\n"," 639,\n"," 291,\n"," 217,\n"," 426,\n"," 402,\n"," 538,\n"," 644,\n"," 459,\n"," 422,\n"," 190,\n"," 1144,\n"," 608,\n"," 378,\n"," 269,\n"," 288,\n"," 595,\n"," 204,\n"," 354,\n"," 181,\n"," 354,\n"," 285,\n"," 262,\n"," 177,\n"," 193,\n"," 252,\n"," 332,\n"," 287,\n"," 116,\n"," 499,\n"," 505,\n"," 222,\n"," 715,\n"," 318,\n"," 274,\n"," 324,\n"," 460,\n"," 228,\n"," 385,\n"," 405,\n"," 246,\n"," 768,\n"," 301,\n"," 1043,\n"," 1320,\n"," 544,\n"," 536,\n"," 548,\n"," 451,\n"," 941,\n"," 1175,\n"," 725,\n"," 777,\n"," 206,\n"," 315,\n"," 170,\n"," 240,\n"," 260,\n"," 841,\n"," 704,\n"," 795,\n"," 284,\n"," 320,\n"," 159,\n"," 268,\n"," 339,\n"," 420,\n"," 335,\n"," 344,\n"," 704,\n"," 441,\n"," 381,\n"," 509,\n"," 570,\n"," 333,\n"," 479,\n"," 274,\n"," 401,\n"," 421,\n"," 196,\n"," 389,\n"," 523,\n"," 456,\n"," 461,\n"," 560,\n"," 818,\n"," 718,\n"," 479,\n"," 625,\n"," 1154,\n"," 696,\n"," 207,\n"," 314,\n"," 337,\n"," 327,\n"," 575,\n"," 197,\n"," 956,\n"," 388,\n"," 588,\n"," 917,\n"," 903,\n"," 334,\n"," 357,\n"," 365,\n"," 278,\n"," 225,\n"," 623,\n"," 658,\n"," 202,\n"," 284,\n"," 309,\n"," 448,\n"," 571,\n"," 465,\n"," 283,\n"," 645,\n"," 447,\n"," 375,\n"," 599,\n"," 295,\n"," 632,\n"," 381,\n"," 178,\n"," 317,\n"," 227,\n"," 459,\n"," 467,\n"," 276,\n"," 234,\n"," 286,\n"," 655,\n"," 716,\n"," 1101,\n"," 629,\n"," 218,\n"," 323,\n"," 431,\n"," 220,\n"," 196,\n"," 548,\n"," 185,\n"," 298,\n"," 447,\n"," 290,\n"," 475,\n"," 334,\n"," 342,\n"," 460,\n"," 389,\n"," 590,\n"," 1086,\n"," 469,\n"," 303,\n"," 322,\n"," 162,\n"," 661,\n"," 258,\n"," 186,\n"," 424,\n"," 312,\n"," 808,\n"," 1452,\n"," 283,\n"," 390,\n"," 238,\n"," 563,\n"," 255,\n"," 364,\n"," 308,\n"," 231,\n"," 294,\n"," 472,\n"," 587,\n"," 445,\n"," 284,\n"," 219,\n"," 272,\n"," 270,\n"," 225,\n"," 461,\n"," 327,\n"," 398,\n"," 1152,\n"," 915,\n"," 542,\n"," 1232,\n"," 453,\n"," 808,\n"," 487,\n"," 160,\n"," 844,\n"," 261,\n"," 683,\n"," 340,\n"," 709,\n"," 291,\n"," 258,\n"," 880,\n"," 231,\n"," 516,\n"," 451,\n"," 227,\n"," 251,\n"," 1208,\n"," 756,\n"," 431,\n"," 280,\n"," 426,\n"," 484,\n"," 580,\n"," 253,\n"," 394,\n"," 634,\n"," 890,\n"," 495,\n"," 510,\n"," 184,\n"," 263,\n"," 267,\n"," 168,\n"," 533,\n"," 339,\n"," 503,\n"," 474,\n"," 602,\n"," 565,\n"," 364,\n"," 1059,\n"," 947,\n"," 849,\n"," 264,\n"," 276,\n"," 251,\n"," 295,\n"," 437,\n"," 206,\n"," 777,\n"," 611,\n"," 410,\n"," 372,\n"," 570,\n"," 758,\n"," 454,\n"," 452,\n"," 468,\n"," 974,\n"," 644,\n"," 634,\n"," 308,\n"," 974,\n"," 179,\n"," 570,\n"," 351,\n"," 359,\n"," 182,\n"," 224,\n"," 234,\n"," 276,\n"," 571,\n"," 339,\n"," 264,\n"," 248,\n"," 330,\n"," 516,\n"," 233,\n"," 461,\n"," 239,\n"," 277,\n"," 284,\n"," 374,\n"," 2095,\n"," 402,\n"," 234,\n"," 206,\n"," 416,\n"," 197,\n"," 579,\n"," 1505,\n"," 669,\n"," 318,\n"," 792,\n"," 613,\n"," 788,\n"," 554,\n"," 1088,\n"," 302,\n"," 401,\n"," 406,\n"," 392,\n"," 739,\n"," 180,\n"," 389,\n"," 566,\n"," 505,\n"," 633,\n"," 533,\n"," 587,\n"," 570,\n"," 762,\n"," 555,\n"," 630,\n"," 114,\n"," 1278,\n"," 561,\n"," 287,\n"," 287,\n"," 383,\n"," 969,\n"," 164,\n"," 585,\n"," 494,\n"," 470,\n"," 1687,\n"," 553,\n"," 180,\n"," 1491,\n"," 356,\n"," 214,\n"," 185,\n"," 337,\n"," 254,\n"," 106,\n"," 913,\n"," 471,\n"," 437,\n"," 375,\n"," 232,\n"," 317,\n"," 503,\n"," 220,\n"," 476,\n"," 236,\n"," 650,\n"," 151,\n"," 357,\n"," 479,\n"," 335,\n"," 523,\n"," 346,\n"," 325,\n"," 906,\n"," 375,\n"," 360,\n"," 363,\n"," 476,\n"," 204,\n"," 216,\n"," 190,\n"," 426,\n"," 291,\n"," 183,\n"," 320,\n"," 389,\n"," 368,\n"," 441,\n"," 1005,\n"," 557,\n"," 846,\n"," 479,\n"," 955,\n"," 697,\n"," 615,\n"," 1375,\n"," 408,\n"," 473,\n"," 549,\n"," 363,\n"," 837,\n"," 339,\n"," 410,\n"," 561,\n"," 769,\n"," 922,\n"," 587,\n"," 578,\n"," 307,\n"," 752,\n"," 178,\n"," 253,\n"," 1166,\n"," 527,\n"," 675,\n"," 488,\n"," 249,\n"," 386,\n"," 661,\n"," 673,\n"," 330,\n"," 225,\n"," 185,\n"," 307,\n"," 253,\n"," 828,\n"," 231,\n"," 127,\n"," 197,\n"," 606,\n"," 192,\n"," 285,\n"," 563,\n"," 394,\n"," 167,\n"," 425,\n"," 301,\n"," 694,\n"," 327,\n"," 610,\n"," 333,\n"," 201,\n"," 738,\n"," 989,\n"," 781,\n"," 352,\n"," 456,\n"," 291,\n"," 866,\n"," 250,\n"," 284,\n"," 154,\n"," 483,\n"," 301,\n"," 176,\n"," 246,\n"," 818,\n"," 220,\n"," 215,\n"," 209,\n"," 649,\n"," 838,\n"," 761,\n"," 339,\n"," 569,\n"," 230,\n"," 223,\n"," 842,\n"," 64,\n"," 518,\n"," 1250,\n"," 412,\n"," 172,\n"," 199,\n"," 1484,\n"," 332,\n"," 682,\n"," 202,\n"," 373,\n"," 713,\n"," 575,\n"," 1003,\n"," 1582,\n"," 452,\n"," 348,\n"," 377,\n"," 345,\n"," 276,\n"," 507,\n"," 463,\n"," 393,\n"," 1052,\n"," 719,\n"," 413,\n"," 592,\n"," 319,\n"," 191,\n"," 998,\n"," 379,\n"," 398,\n"," 495,\n"," 459,\n"," 356,\n"," 550,\n"," 347,\n"," 158,\n"," 137,\n"," 127,\n"," 265,\n"," 465,\n"," 383,\n"," 584,\n"," 578,\n"," 691,\n"," 390,\n"," 1158,\n"," 1061,\n"," 1124,\n"," 1320,\n"," 582,\n"," 768,\n"," 477,\n"," 331,\n"," 877,\n"," 381,\n"," 171,\n"," 406,\n"," 680,\n"," 678,\n"," 861,\n"," 263,\n"," 238,\n"," 347,\n"," 546,\n"," 277,\n"," 469,\n"," 622,\n"," 1012,\n"," 639,\n"," 653,\n"," 248,\n"," 387,\n"," 254,\n"," 1011,\n"," 648,\n"," 517,\n"," 247,\n"," 190,\n"," 645,\n"," 315,\n"," 737,\n"," 332,\n"," 337,\n"," 264,\n"," 592,\n"," 1056,\n"," 390,\n"," 217,\n"," 919,\n"," 634,\n"," 284,\n"," 533,\n"," 915,\n"," 732,\n"," 519,\n"," 251,\n"," 208,\n"," 237,\n"," 1184,\n"," 888,\n"," 790,\n"," 434,\n"," 1009,\n"," 1477,\n"," 1604,\n"," 411,\n"," 220,\n"," 824,\n"," 1160,\n"," 258,\n"," 629,\n"," 759,\n"," 258,\n"," 679,\n"," 407,\n"," 356,\n"," 248,\n"," 755,\n"," 451,\n"," 1565,\n"," 630,\n"," 1072,\n"," 218,\n"," 268,\n"," 214,\n"," 220,\n"," 585,\n"," 331,\n"," 262,\n"," 518,\n"," 456,\n"," 653,\n"," 430,\n"," 535,\n"," 234,\n"," 402,\n"," 518,\n"," 461,\n"," 288,\n"," 1082,\n"," 642,\n"," 525,\n"," 402,\n"," 537,\n"," 362,\n"," 360,\n"," 179,\n"," 328,\n"," 676,\n"," 290,\n"," 362,\n"," 763,\n"," 713,\n"," 303,\n"," 862,\n"," 307,\n"," 403,\n"," 252,\n"," 752,\n"," 305,\n"," 223,\n"," 219,\n"," 234,\n"," 583,\n"," 295,\n"," 498,\n"," 609,\n"," 1141,\n"," 858,\n"," 293,\n"," 405,\n"," 777,\n"," 766,\n"," 590,\n"," 437,\n"," 1116,\n"," 436,\n"," 449,\n"," 927,\n"," 191,\n"," 929,\n"," 335,\n"," 525,\n"," 1168,\n"," 738,\n"," 829,\n"," 441,\n"," 385,\n"," 347,\n"," 454,\n"," 338,\n"," 584,\n"," 341,\n"," 288,\n"," 425,\n"," 526,\n"," 431,\n"," 528,\n"," 183,\n"," 806,\n"," 284,\n"," 597,\n"," 276,\n"," 314,\n"," 299,\n"," 1046,\n"," 292,\n"," 532,\n"," 183,\n"," 236,\n"," 675,\n"," 508,\n"," 497,\n"," 233,\n"," 661,\n"," 702,\n"," 712,\n"," 482,\n"," 934,\n"," 340,\n"," 497,\n"," 362,\n"," 420,\n"," 291,\n"," 320,\n"," 326,\n"," 360,\n"," 232,\n"," 502,\n"," 231,\n"," 189,\n"," 194,\n"," 614,\n"," 1073,\n"," 168,\n"," 386,\n"," 167,\n"," 697,\n"," 1221,\n"," 551,\n"," 697,\n"," 415,\n"," 181,\n"," 272,\n"," 293,\n"," 742,\n"," 1197,\n"," 780,\n"," 400,\n"," 245,\n"," 542,\n"," 585,\n"," 1182,\n"," 599,\n"," 959,\n"," 323,\n"," 245,\n"," 271,\n"," 222,\n"," 693,\n"," 316,\n"," 208,\n"," 173,\n"," 342,\n"," 610,\n"," 504,\n"," 252,\n"," 1212,\n"," 590,\n"," 827,\n"," 310,\n"," 316,\n"," 219,\n"," 290,\n"," 438,\n"," 471,\n"," 401,\n"," 313,\n"," 1043,\n"," 238,\n"," 849,\n"," 1001,\n"," 717,\n"," 404,\n"," 1316,\n"," 304,\n"," 325,\n"," 222,\n"," 233,\n"," 237,\n"," 952,\n"," 349,\n"," 347,\n"," 712,\n"," 253,\n"," 404,\n"," 390,\n"," 267,\n"," 455,\n"," 151,\n"," 483,\n"," 434,\n"," 385,\n"," 320,\n"," 535,\n"," 470,\n"," 207,\n"," 207,\n"," 326,\n"," 851,\n"," 240,\n"," 445,\n"," 408,\n"," 404,\n"," 316,\n"," 322,\n"," 225,\n"," 169,\n"," 439,\n"," 240,\n"," 346,\n"," 1386,\n"," 443,\n"," 927,\n"," 313,\n"," 671,\n"," 349,\n"," 367,\n"," 296,\n"," 470,\n"," 401,\n"," 764,\n"," 1280,\n"," 891,\n"," 187,\n"," 232,\n"," 464,\n"," 344,\n"," 283,\n"," 300,\n"," 452,\n"," 268,\n"," 232,\n"," 265,\n"," 371,\n"," 526,\n"," 593,\n"," 304,\n"," 531,\n"," 461,\n"," 279,\n"," 240,\n"," 427,\n"," 868,\n"," 288,\n"," 632,\n"," 884,\n"," 344,\n"," 332,\n"," 337,\n"," 265,\n"," 304,\n"," 404,\n"," 355,\n"," 334,\n"," 302,\n"," 248,\n"," 470,\n"," 519,\n"," 427,\n"," 192,\n"," 305,\n"," 313,\n"," 348,\n"," 587,\n"," 431,\n"," 443,\n"," 360,\n"," 392,\n"," 442,\n"," 747,\n"," 366,\n"," 494,\n"," 208,\n"," 331,\n"," 890,\n"," 216,\n"," 908,\n"," 494,\n"," 502,\n"," 240,\n"," 1012,\n"," 634,\n"," 951,\n"," 639,\n"," 701,\n"," 434,\n"," 569,\n"," 577,\n"," 1687,\n"," 500,\n"," 708,\n"," 216,\n"," 278,\n"," 330,\n"," 628,\n"," 164,\n"," 521,\n"," 319,\n"," 189,\n"," 230,\n"," 189,\n"," 895,\n"," 504,\n"," 347,\n"," ...]"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["[tokenize.word_tokenize(x) for x in segmented_content]"],"metadata":{"id":"tbIBzjh2EXYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["segmented_content = rdrsegmenter.word_segment(df.iloc[0]['content'])[:-2]"],"metadata":{"id":"4Fg7LOMHESru","executionInfo":{"status":"ok","timestamp":1665291991650,"user_tz":-420,"elapsed":375,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["with open(\"/content/json/cnndm_sample.train.0.json\", \"w+\") as outfile:\n","    json.dump(part, outfile)"],"metadata":{"id":"7Lo8MTofT6bQ","executionInfo":{"status":"ok","timestamp":1665304667490,"user_tz":-420,"elapsed":5991,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["!python /content/PreSumm/src/preprocess.py -mode format_to_bert -raw_path /content/json -save_path /content/PreSumm/bert_data  -lower -n_cpus 1 -log_file /content/PreSumm/logs/preprocess.log"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSOGgNCplU3q","executionInfo":{"status":"ok","timestamp":1665305230247,"user_tz":-420,"elapsed":40286,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"5044701a-8c04-455c-eb1b-e0e2ce97d78f"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["[('train', '/content/json/cnndm_sample.train.0.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/json', save_path='/content/PreSumm/bert_data', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt')]\n","[2022-10-09 08:46:30,703 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-09 08:46:30,931 INFO] Processing /content/json/cnndm_sample.train.0.json\n","[2022-10-09 08:47:00,613 INFO] Processed instances 8328\n","[2022-10-09 08:47:00,614 INFO] Saving to /content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt\n","[]\n","[]\n"]}]},{"cell_type":"code","source":["!python /content/PreSumm/src/preprocess.py -mode format_to_bert -raw_path /content/PreSumm/json_data -save_path /content/PreSumm/bert_data  -lower -n_cpus 1 -log_file /content/PreSumm/logs/preprocess.log"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5daE1q6UTNWz","executionInfo":{"status":"ok","timestamp":1665126973738,"user_tz":-420,"elapsed":2230,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"cd6d9b27-94be-47ed-a218-a9726fa48d64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('train', '/content/PreSumm/json_data/cnndm_sample.train.0.json', Namespace(dataset='', log_file='/content/PreSumm/logs/preprocess.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=1, pretrained_model='bert', raw_path='/content/PreSumm/json_data', save_path='/content/PreSumm/bert_data', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), '/content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt')]\n","[2022-10-07 07:16:11,661 INFO] loading vocabulary file https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt from cache at /root/.cache/torch/pytorch_transformers/0a34bc276f86df145cf05b9794f10e391ecb455423d9352e9db04f1422b4d42d.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","[2022-10-07 07:16:11,867 INFO] Processing /content/PreSumm/json_data/cnndm_sample.train.0.json\n","[2022-10-07 07:16:11,918 INFO] Processed instances 6\n","[2022-10-07 07:16:11,918 INFO] Saving to /content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt\n","[]\n","[]\n"]}]},{"cell_type":"code","source":["!pip install -U transformers"],"metadata":{"id":"d_TdQu_nrJRL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip show transformers"],"metadata":{"id":"4uXvi2oD3u5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":106,"metadata":{"id":"hzSAVX23eCjQ","executionInfo":{"status":"ok","timestamp":1665304773031,"user_tz":-420,"elapsed":379,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"E7k_P5JsRw8Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665304790323,"user_tz":-420,"elapsed":1918,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"3f920f34-aecb-4de4-b345-e25fa1ec76d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8789"]},"metadata":{},"execution_count":108}],"source":["dataset = torch.load(\"/content/PreSumm/bert_data/cnndm_sample.train.0.bert.pt\")\n","len(dataset)"]},{"cell_type":"code","source":["dataset = torch.load('/content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.122.bert.pt')\n","len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kuqDwyRu_E-m","executionInfo":{"status":"ok","timestamp":1665289521017,"user_tz":-420,"elapsed":363,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"2ef5bd03-d02d-4657-c28b-e1058760b8de"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHrfuY06eJPL"},"outputs":[],"source":["dataset[0]"]},{"cell_type":"code","source":["!pip install -U transformers"],"metadata":{"id":"FMYIdaGUJIbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModel, AutoTokenizer, PhobertTokenizer\n","\n","phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n","sentence = 'Chúng_tôi là những nghiên_cứu_viên .'  \n","\n","input_ids = torch.tensor([tokenizer.encode(sentence)])\n","\n","with torch.no_grad():\n","    features = phobert(input_ids)  # Models outputs are now tuples\n","\n","## With TensorFlow 2.0+:\n","# from transformers import TFAutoModel\n","# phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")"],"metadata":{"id":"LLdET1xttdNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import collections\n","def load_vocab(vocab_file):\n","    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n","    vocab = collections.OrderedDict()\n","    index = 0\n","    with open('/content/PreSumm/src/others/added_vocab.txt', \"r\", encoding=\"utf-8\") as reader:\n","        while True:\n","            token = reader.readline()\n","            if not token:\n","                break\n","            token = token.strip()\n","            token = token.split()\n","            vocab[token[0]] = index\n","            index += 1\n","    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n","        while True:\n","            token = reader.readline()\n","            if not token:\n","                break\n","            token = token.strip()\n","            token = token.split()\n","            vocab[token[0]] = index\n","            index += 1\n","    last_1 = list(vocab.keys())[-1]\n","    last_2 = list(vocab.keys())[-2]\n","    last_3 = list(vocab.keys())[-3]\n","    vocab['[unused0]'] = vocab[last_3]\n","    vocab['[unused1]'] = vocab[last_2]\n","    vocab['[unused2]'] = vocab[last_1]\n","    del vocab[last_1]\n","    del vocab[last_2]\n","    del vocab[last_3]\n","    vocab['[mask]'] = index\n","    return vocab"],"metadata":{"id":"Mr3q11ABJNVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRGlE6rKJys5","executionInfo":{"status":"ok","timestamp":1665124690435,"user_tz":-420,"elapsed":1001,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"b3a8d64d-75c8-4358-f1f0-c726e9102bd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-07 06:38:08--  https://huggingface.co/vinai/phobert-base/raw/main/vocab.txt\n","Resolving huggingface.co (huggingface.co)... 52.5.54.249, 54.210.225.113, 44.195.102.200, ...\n","Connecting to huggingface.co (huggingface.co)|52.5.54.249|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 895321 (874K) [text/plain]\n","Saving to: ‘vocab.txt’\n","\n","vocab.txt           100%[===================>] 874.34K  --.-KB/s    in 0.1s    \n","\n","2022-10-07 06:38:09 (6.34 MB/s) - ‘vocab.txt’ saved [895321/895321]\n","\n"]}]},{"cell_type":"code","source":["!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt"],"metadata":{"id":"zJTQWMpnR_uw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab = load_vocab('/content/vocab.txt')"],"metadata":{"id":"3BsB_8g0KHOk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(vocab.items())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0BcJPNLKQU2","executionInfo":{"status":"ok","timestamp":1665142586635,"user_tz":-420,"elapsed":5,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"cc98b724-6537-44a3-9457-4c1fffffa444"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64001"]},"metadata":{},"execution_count":267}]},{"cell_type":"code","source":["idx2word = {v: k for k, v in vocab.items()}"],"metadata":{"id":"_JmaJCkiLW0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx2word[64000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zYblvAC1Lc7L","executionInfo":{"status":"ok","timestamp":1665126562664,"user_tz":-420,"elapsed":6,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"fdd16b70-f208-4bc2-c725-41eec5531052"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[mask]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["vocab['[unused1]'] = vocab.pop(list(vocab.keys())[-2])"],"metadata":{"id":"uh2edijBQIzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab['[unused1]']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNZiiX_xL3Bo","executionInfo":{"status":"ok","timestamp":1665126145819,"user_tz":-420,"elapsed":309,"user":{"displayName":"Lam Nguyen","userId":"00546238859420742191"}},"outputId":"d11f622c-5bb7-4e4e-bbd0-0b7235a24f9e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["63997"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","sep_token = '[SEP]'\n","cls_token = '[CLS]'\n","pad_token = '[PAD]'\n","tgt_bos = '[unused0]'\n","tgt_eos = '[unused1]'\n","tgt_sent_split = '[unused2]'\n","sep_vid = tokenizer.vocab[sep_token]\n","cls_vid = tokenizer.vocab[cls_token]\n","pad_vid = tokenizer.vocab[pad_token]"],"metadata":{"id":"H9zYwjMl6QZm"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}