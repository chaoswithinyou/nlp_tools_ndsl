{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOuKmJ6O34oGeBYTX6DNkeB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","cwd = os.getcwd()"],"metadata":{"id":"PV6t4yt3QmkM","executionInfo":{"status":"ok","timestamp":1664963263075,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOovIAxxQDZX","executionInfo":{"status":"ok","timestamp":1664959434151,"user_tz":-420,"elapsed":10147,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"c6ccf3c5-becd-46c7-e49c-c8642818cc50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1x0d61LP9UAN389YN00z0Pv-7jQgirVg6\n","To: /content/bertsum_data.zip\n","100% 869M/869M [00:08<00:00, 99.5MB/s]\n"]}],"source":["try:\n","    f = open(cwd+\"/bert_data_cnndm_final.zip\")\n","    # Do something with the file\n","    f.close()\n","except IOError:\n","    !gdown 1DN7ClZCCXsk2KegmC6t4ClBwtAf5galI"]},{"cell_type":"code","source":["!git clone https://github.com/nlpyang/PreSumm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxlnYI5xSFzT","executionInfo":{"status":"ok","timestamp":1664963359319,"user_tz":-420,"elapsed":6616,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"db5428b9-10f8-41a0-eee0-ec6eab60201a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'PreSumm'...\n","remote: Enumerating objects: 420, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 420 (delta 0), reused 0 (delta 0), pack-reused 417\u001b[K\n","Receiving objects: 100% (420/420), 13.00 MiB | 9.09 MiB/s, done.\n","Resolving deltas: 100% (279/279), done.\n"]}]},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile(cwd+\"/bert_data_cnndm_final.zip\", 'r') as zip_ref:\n","    zip_ref.extractall('/content/PreSumm/bert_data')"],"metadata":{"id":"JY_qif9SQsDR","executionInfo":{"status":"ok","timestamp":1664963454969,"user_tz":-420,"elapsed":25061,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch_transformers"],"metadata":{"id":"EPoKRzfgUiJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"id":"La_A9_MbU10c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664963495801,"user_tz":-420,"elapsed":3915,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"1aedfff8-3e19-4c30-c281-4146eb099a2d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 23.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5.1\n"]}]},{"cell_type":"code","source":["!pip install pyrouge"],"metadata":{"id":"ZCRtti9hU97Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664963501536,"user_tz":-420,"elapsed":5746,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"d2b6779f-98dd-495e-eb52-3e2acf2da46a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyrouge\n","  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 7.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyrouge\n","  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191621 sha256=0e5765f00ac89d64314ee60db67c033193fdf6f04c48e1cf784322de37aacd0b\n","  Stored in directory: /root/.cache/pip/wheels/68/35/6a/ffb9a1f51b2b00fee42e7f67f5a5d8e10c67d048cda09ccd57\n","Successfully built pyrouge\n","Installing collected packages: pyrouge\n","Successfully installed pyrouge-0.1.3\n"]}]},{"cell_type":"code","source":["!pip install torch==1.1.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0LzkByFWeMZ","executionInfo":{"status":"ok","timestamp":1664963598006,"user_tz":-420,"elapsed":92779,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"53fc2761-1da8-49b4-8eb9-577f80200275"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.1.0\n","  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n","\u001b[K     |████████████████████████████████| 676.9 MB 4.0 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.1.0) (1.21.6)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n","fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.1.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.1.0\n"]}]},{"cell_type":"code","source":["!python /content/PreSumm/src/train.py -task ext -mode train -bert_data_path BERT_DATA_PATH -ext_dropout 0.1 -model_path MODEL_PATH -lr 2e-3 -visible_gpus -1 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file /content/PreSumm/logs/ext_bert_cnndm -use_interval true -warmup_steps 10000 -max_pos 512"],"metadata":{"id":"WohhIXNRRAgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/PreSumm/src/train.py -task ext -mode train -bert_data_path /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm -ext_dropout 0.1 -model_path MODEL_PATH -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file /content/PreSumm/logs/ext_bert_cnndm -use_interval true -warmup_steps 10000 -max_pos 512"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bIQ-2Wtkldb","executionInfo":{"status":"ok","timestamp":1664967529343,"user_tz":-420,"elapsed":2867767,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"5f922740-90e1-4096-9a7b-056af7dfaf9b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-10-05 10:11:01,577 INFO] Device ID 0\n","[2022-10-05 10:11:01,577 INFO] Device cuda\n","[2022-10-05 10:11:02,599 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","[2022-10-05 10:11:02,600 INFO] Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","[2022-10-05 10:11:03,577 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","[2022-10-05 10:11:09,243 INFO] ExtSummarizer(\n","  (bert): Bert(\n","    (model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (ext_layer): ExtTransformerEncoder(\n","    (pos_emb): PositionalEncoding(\n","      (dropout): Dropout(p=0.1)\n","    )\n","    (transformer_inter): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.1)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1)\n","          (dropout_2): Dropout(p=0.1)\n","        )\n","        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1)\n","    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","    (wo): Linear(in_features=768, out_features=1, bias=True)\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","gpu_rank 0\n","[2022-10-05 10:11:09,334 INFO] * number of parameters: 120512513\n","[2022-10-05 10:11:09,334 INFO] Start training...\n","[2022-10-05 10:11:09,546 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.123.bert.pt, number of examples: 2001\n","[2022-10-05 10:12:07,350 INFO] Step 50/50000; xent: 9.92; lr: 0.0000001;  18 docs/s;     58 sec\n","[2022-10-05 10:13:11,661 INFO] Step 100/50000; xent: 6.85; lr: 0.0000002;  16 docs/s;    122 sec\n","[2022-10-05 10:14:16,598 INFO] Step 150/50000; xent: 4.44; lr: 0.0000003;  16 docs/s;    187 sec\n","[2022-10-05 10:15:10,384 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.91.bert.pt, number of examples: 1998\n","[2022-10-05 10:15:22,274 INFO] Step 200/50000; xent: 3.65; lr: 0.0000004;  16 docs/s;    253 sec\n","[2022-10-05 10:16:27,534 INFO] Step 250/50000; xent: 3.58; lr: 0.0000005;  16 docs/s;    318 sec\n","[2022-10-05 10:17:33,360 INFO] Step 300/50000; xent: 3.45; lr: 0.0000006;  16 docs/s;    384 sec\n","[2022-10-05 10:18:39,083 INFO] Step 350/50000; xent: 3.39; lr: 0.0000007;  16 docs/s;    450 sec\n","[2022-10-05 10:19:19,611 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.39.bert.pt, number of examples: 2000\n","[2022-10-05 10:19:44,480 INFO] Step 400/50000; xent: 3.44; lr: 0.0000008;  16 docs/s;    515 sec\n","[2022-10-05 10:20:50,165 INFO] Step 450/50000; xent: 3.39; lr: 0.0000009;  16 docs/s;    581 sec\n","[2022-10-05 10:21:56,031 INFO] Step 500/50000; xent: 3.28; lr: 0.0000010;  17 docs/s;    646 sec\n","[2022-10-05 10:23:01,886 INFO] Step 550/50000; xent: 3.25; lr: 0.0000011;  15 docs/s;    712 sec\n","[2022-10-05 10:23:29,673 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.6.bert.pt, number of examples: 2001\n","[2022-10-05 10:24:07,866 INFO] Step 600/50000; xent: 3.39; lr: 0.0000012;  16 docs/s;    778 sec\n","[2022-10-05 10:25:13,608 INFO] Step 650/50000; xent: 3.33; lr: 0.0000013;  16 docs/s;    844 sec\n","[2022-10-05 10:26:19,499 INFO] Step 700/50000; xent: 3.31; lr: 0.0000014;  16 docs/s;    910 sec\n","[2022-10-05 10:27:24,804 INFO] Step 750/50000; xent: 3.15; lr: 0.0000015;  16 docs/s;    975 sec\n","[2022-10-05 10:27:42,029 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.81.bert.pt, number of examples: 2000\n","[2022-10-05 10:28:30,802 INFO] Step 800/50000; xent: 3.14; lr: 0.0000016;  16 docs/s;   1041 sec\n","[2022-10-05 10:29:36,711 INFO] Step 850/50000; xent: 3.24; lr: 0.0000017;  16 docs/s;   1107 sec\n","[2022-10-05 10:30:43,051 INFO] Step 900/50000; xent: 3.21; lr: 0.0000018;  16 docs/s;   1174 sec\n","[2022-10-05 10:31:48,939 INFO] Step 950/50000; xent: 3.22; lr: 0.0000019;  16 docs/s;   1239 sec\n","[2022-10-05 10:31:51,933 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.98.bert.pt, number of examples: 2000\n","[2022-10-05 10:32:55,592 INFO] Step 1000/50000; xent: 3.18; lr: 0.0000020;  16 docs/s;   1306 sec\n","[2022-10-05 10:32:55,606 INFO] Saving checkpoint MODEL_PATH/model_step_1000.pt\n","[2022-10-05 10:34:06,740 INFO] Step 1050/50000; xent: 3.25; lr: 0.0000021;  14 docs/s;   1377 sec\n","[2022-10-05 10:35:12,407 INFO] Step 1100/50000; xent: 3.26; lr: 0.0000022;  16 docs/s;   1443 sec\n","[2022-10-05 10:36:09,331 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.93.bert.pt, number of examples: 1997\n","[2022-10-05 10:36:18,599 INFO] Step 1150/50000; xent: 3.15; lr: 0.0000023;  16 docs/s;   1509 sec\n","[2022-10-05 10:37:24,658 INFO] Step 1200/50000; xent: 3.21; lr: 0.0000024;  16 docs/s;   1575 sec\n","[2022-10-05 10:38:30,420 INFO] Step 1250/50000; xent: 3.08; lr: 0.0000025;  16 docs/s;   1641 sec\n","[2022-10-05 10:39:36,181 INFO] Step 1300/50000; xent: 3.18; lr: 0.0000026;  16 docs/s;   1707 sec\n","[2022-10-05 10:40:21,040 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.63.bert.pt, number of examples: 2001\n","[2022-10-05 10:40:42,107 INFO] Step 1350/50000; xent: 3.19; lr: 0.0000027;  16 docs/s;   1773 sec\n","[2022-10-05 10:41:47,872 INFO] Step 1400/50000; xent: 3.19; lr: 0.0000028;  16 docs/s;   1838 sec\n","[2022-10-05 10:42:53,912 INFO] Step 1450/50000; xent: 3.15; lr: 0.0000029;  16 docs/s;   1904 sec\n","[2022-10-05 10:43:59,190 INFO] Step 1500/50000; xent: 3.14; lr: 0.0000030;  16 docs/s;   1970 sec\n","[2022-10-05 10:44:29,574 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.15.bert.pt, number of examples: 1999\n","[2022-10-05 10:45:05,243 INFO] Step 1550/50000; xent: 3.15; lr: 0.0000031;  16 docs/s;   2036 sec\n","[2022-10-05 10:46:11,274 INFO] Step 1600/50000; xent: 3.12; lr: 0.0000032;  16 docs/s;   2102 sec\n","[2022-10-05 10:47:17,057 INFO] Step 1650/50000; xent: 3.12; lr: 0.0000033;  16 docs/s;   2168 sec\n","[2022-10-05 10:48:22,529 INFO] Step 1700/50000; xent: 3.18; lr: 0.0000034;  16 docs/s;   2233 sec\n","[2022-10-05 10:48:40,012 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.64.bert.pt, number of examples: 2001\n","[2022-10-05 10:49:28,611 INFO] Step 1750/50000; xent: 3.11; lr: 0.0000035;  16 docs/s;   2299 sec\n","[2022-10-05 10:50:34,194 INFO] Step 1800/50000; xent: 3.12; lr: 0.0000036;  16 docs/s;   2365 sec\n","[2022-10-05 10:51:40,029 INFO] Step 1850/50000; xent: 3.11; lr: 0.0000037;  17 docs/s;   2430 sec\n","[2022-10-05 10:52:45,210 INFO] Step 1900/50000; xent: 3.18; lr: 0.0000038;  16 docs/s;   2496 sec\n","[2022-10-05 10:52:49,461 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.28.bert.pt, number of examples: 2000\n","[2022-10-05 10:53:51,396 INFO] Step 1950/50000; xent: 3.08; lr: 0.0000039;  16 docs/s;   2562 sec\n","[2022-10-05 10:54:57,560 INFO] Step 2000/50000; xent: 3.22; lr: 0.0000040;  16 docs/s;   2628 sec\n","[2022-10-05 10:54:57,574 INFO] Saving checkpoint MODEL_PATH/model_step_2000.pt\n","[2022-10-05 10:56:08,307 INFO] Step 2050/50000; xent: 3.10; lr: 0.0000041;  15 docs/s;   2699 sec\n","[2022-10-05 10:57:06,276 INFO] Loading train dataset from /content/PreSumm/bert_data/bert_data_cnndm_final/cnndm.train.32.bert.pt, number of examples: 1998\n","[2022-10-05 10:57:14,222 INFO] Step 2100/50000; xent: 3.18; lr: 0.0000042;  16 docs/s;   2765 sec\n","[2022-10-05 10:58:20,183 INFO] Step 2150/50000; xent: 3.14; lr: 0.0000043;  16 docs/s;   2831 sec\n","Traceback (most recent call last):\n","  File \"/content/PreSumm/src/train.py\", line 146, in <module>\n","    train_ext(args, device_id)\n","  File \"/content/PreSumm/src/train_extractive.py\", line 203, in train_ext\n","    train_single_ext(args, device_id)\n","  File \"/content/PreSumm/src/train_extractive.py\", line 245, in train_single_ext\n","    trainer.train(train_iter_fct, args.train_steps)\n","  File \"/content/PreSumm/src/models/trainer_ext.py\", line 152, in train\n","    report_stats)\n","  File \"/content/PreSumm/src/models/trainer_ext.py\", line 316, in _gradient_accumulation\n","    (loss / loss.numel()).backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 107, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 93, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}]}]}