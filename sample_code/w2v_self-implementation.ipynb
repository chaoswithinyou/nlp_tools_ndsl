{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3980,"status":"ok","timestamp":1664137810804,"user":{"displayName":"Lam","userId":"17841603162440265686"},"user_tz":-420},"id":"dL72O0FtqJcD","outputId":"8a781507-72e0-4519-9015-985b79cfbe7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-nlp\n","  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (4.64.1)\n","Installing collected packages: pytorch-nlp\n","Successfully installed pytorch-nlp-0.5.0\n"]}],"source":["!pip install pytorch-nlp\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hlhk27YjBA9j","executionInfo":{"status":"ok","timestamp":1664137813388,"user_tz":-420,"elapsed":2588,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"outputs":[],"source":["#%%printcell\n","import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import torch.functional as F\n","import torch.nn.functional as F\n","from torchnlp.datasets import imdb_dataset\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["#hyper parameter\n","num_epoch = 100\n","learning_rate = 0.01\n","vector_size = 300"],"metadata":{"id":"c8jx3p8ZZRAv","executionInfo":{"status":"ok","timestamp":1664137813389,"user_tz":-420,"elapsed":24,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ne5QyUBlpOq7","executionInfo":{"status":"ok","timestamp":1664137842089,"user_tz":-420,"elapsed":28719,"user":{"displayName":"Lam","userId":"17841603162440265686"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecbe90a4-6bed-42ab-fdfe-1caac5a7b0b3"},"outputs":[{"output_type":"stream","name":"stderr","text":["aclImdb_v1.tar.gz: 84.1MB [00:09, 8.57MB/s]                            \n"]}],"source":["train = imdb_dataset(train=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1967,"status":"ok","timestamp":1664137844054,"user":{"displayName":"Lam","userId":"17841603162440265686"},"user_tz":-420},"id":"qmVoyQHmB6xH","outputId":"85b6efed-2613-4cd0-814c-1ec0758a136b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"source":["from nltk import tokenize\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60348,"status":"ok","timestamp":1664137904398,"user":{"displayName":"Lam","userId":"17841603162440265686"},"user_tz":-420},"id":"8Muf1NxKgh-U","outputId":"e3aabff9-a6ee-4f55-d658-763074cc6b40"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 715693/715693 [00:59<00:00, 11989.87it/s]\n"]}],"source":["text = ' '.join([s[\"text\"] for s in train])\n","text = text.replace('<br /><br />',' ')\n","text = text.replace('\\x85','')\n","text = text.lower()\n","from tqdm import tqdm\n","\n","#sentence_tokenize = tokenize.sent_tokenize(text)\n","import re\n","tokenized_sentence = re.compile('[,.!?()]').split(text)\n","tokenized_corpus = [None]*len(tokenized_sentence)\n","for i in tqdm(range(len(tokenized_sentence))):\n","  tokenized_corpus[i] = tokenize.word_tokenize(tokenized_sentence[i])\n","#tokenized_corpus = [tokenize.word_tokenize(t) for t in tokenize.sent_tokenize(text)]"]},{"cell_type":"code","source":["del train\n","del text"],"metadata":{"id":"zbkn2qzSGwuQ","executionInfo":{"status":"ok","timestamp":1664137904399,"user_tz":-420,"elapsed":22,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":994,"status":"ok","timestamp":1664137905372,"user":{"displayName":"Lam","userId":"17841603162440265686"},"user_tz":-420},"id":"2vJZBFTe_Pn_","outputId":"b4e1107b-ab8a-46b3-fd49-819cfb727bb6"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 715693/715693 [00:00<00:00, 862199.07it/s]\n"]}],"source":["vocabulary = []\n","for sentence in tqdm(tokenized_corpus):\n","    for token in sentence:\n","        #if token not in vocabulary:\n","            vocabulary.append(token)\n","vocabulary = list(set(vocabulary))\n","\n","word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n","idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n","\n","vocabulary_size = len(vocabulary)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16254,"status":"ok","timestamp":1664137921622,"user":{"displayName":"Lam","userId":"17841603162440265686"},"user_tz":-420},"id":"TBsyHXL3_Vv7","outputId":"23b63281-237c-4458-ab57-681597e9bc3f"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 715693/715693 [00:16<00:00, 44681.91it/s]\n"]}],"source":["window_size = 2\n","pos_uv_list = [[] for _ in range(vocabulary_size)]\n","# for each sentence\n","for sentence in tqdm(tokenized_corpus):\n","    indices = [word2idx[word] for word in sentence]\n","    # for each word, threated as center word\n","    for center_word_pos in range(len(indices)):\n","        # for each window position\n","        for w in range(-window_size, window_size + 1):\n","            context_word_pos = center_word_pos + w\n","            # make soure not jump out sentence\n","            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n","                continue\n","            context_word_idx = indices[context_word_pos]\n","            pos_uv_list[indices[center_word_pos]].append(context_word_idx)\n","\n","#idx_pairs = np.array(pos_u) # it will be useful to have this as numpy array"]},{"cell_type":"code","source":["vocabulary_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJLT8aozR_W7","executionInfo":{"status":"ok","timestamp":1664137921622,"user_tz":-420,"elapsed":22,"user":{"displayName":"Lam","userId":"17841603162440265686"}},"outputId":"37e0af31-a44a-40c2-e804-d9b862d621fe"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["99167"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#neg_v = [list(range(vocabulary_size)) for _ in range(vocabulary_size)]\n","pos_u = []\n","pos_v = []\n","neg_v = []\n","for i in tqdm(range(vocabulary_size)):\n","    if pos_uv_list[i] != []:\n","        neg_set = set(range(vocabulary_size))\n","        neg_set.remove(i)\n","        neg_set = neg_set - set(pos_uv_list[i])\n","        neg_5 = np.random.choice(\n","            list(neg_set),\n","            size=(len(pos_uv_list[i]),5)\n","        )\n","        for j in range(len(pos_uv_list[i])):\n","            pos_u.append(i)\n","            pos_v.append(pos_uv_list[i][j])\n","            neg_v.append(neg_5[j])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jtwc4OYe46mT","outputId":"ed7a7e65-7881-4f25-98af-58ef02ab73b8","executionInfo":{"status":"ok","timestamp":1664141298479,"user_tz":-420,"elapsed":1127193,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 99167/99167 [18:46<00:00, 87.99it/s]\n"]}]},{"cell_type":"code","source":["pos_u = np.array(pos_u, dtype='int32')\n","pos_v = np.array(pos_v, dtype='int32')\n","neg_v = np.array(neg_v, dtype='int32')"],"metadata":{"id":"g1Ym60oDe_IA","executionInfo":{"status":"ok","timestamp":1664141695711,"user_tz":-420,"elapsed":7,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["indices = np.arange(pos_u.shape[0])\n","np.random.shuffle(indices)\n","\n","pos_u = pos_u[indices]\n","pos_v = pos_v[indices]\n","neg_v = neg_v[indices]"],"metadata":{"id":"QdtHbLyvP4XY","executionInfo":{"status":"ok","timestamp":1664141373985,"user_tz":-420,"elapsed":3839,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","  def __init__(self, x, y, z):\n","    self.pos_u = x\n","    self.pos_v = y\n","    self.neg_v = z\n","    #self.shuffle_index = shuffle_index\n","\n","  def __len__(self):\n","    return len(self.pos_u)\n","  \n","  def __getitem__(self, index):\n","    return self.pos_u[index], self.pos_v[index], self.neg_v[index]"],"metadata":{"id":"uUJL1gAHG9cl","executionInfo":{"status":"ok","timestamp":1664141699791,"user_tz":-420,"elapsed":650,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["dataset = MyDataset(pos_u,pos_v,neg_v)\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=1024, shuffle=False, num_workers=2)\n","#val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=2)\n","#vandeladorandom"],"metadata":{"id":"ID8tshLXOMCP","executionInfo":{"status":"ok","timestamp":1664142920583,"user_tz":-420,"elapsed":721,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","execution_count":66,"metadata":{"id":"iznc7SduGzsF","executionInfo":{"status":"ok","timestamp":1664141712270,"user_tz":-420,"elapsed":1767,"user":{"displayName":"Lam","userId":"17841603162440265686"}}},"outputs":[],"source":["class skipgramModel(nn.Module):\n","   def __init__(self, num_vocab, emb_dimension):\n","      super(skipgramModel, self).__init__()\n","      self.num_vocab = num_vocab\n","      self.emb_dimension = emb_dimension\n","      self.u_embeddings = nn.Embedding(num_vocab, emb_dimension, sparse=True)\n","      self.v_embeddings = nn.Embedding(num_vocab, emb_dimension, sparse=True)\n","      initrange = 0.5 / self.emb_dimension\n","      self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n","      self.v_embeddings.weight.data.uniform_(-0, 0)\n","      \n","   def forward(self, pos_u, pos_v, neg_v):\n","      losses = []\n","      emb_u = self.u_embeddings(Variable(pos_u))\n","      emb_v = self.v_embeddings(Variable(pos_v))\n","      score = torch.mul(emb_u, emb_v).squeeze()\n","      score = torch.sum(score, dim=1)\n","      score = F.logsigmoid(score)\n","      losses.append(sum(score))\n","      neg_emb_v = self.v_embeddings(Variable(neg_v))\n","      neg_score = torch.bmm(neg_emb_v, emb_u.unsqueeze(2)).squeeze()\n","      neg_score = torch.sum(neg_score, dim=1)\n","      neg_score = F.logsigmoid(-1 * neg_score)\n","      losses.append(sum(neg_score))\n","      return -sum(losses)\n","\n","model = skipgramModel(vocabulary_size, vector_size)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwGWwk4MLDCA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"716c0ec4-f8ec-4562-f92e-bd5bd92f0b57"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["loss: 130.92816: 100%|██████████| 19808/19808 [12:43<00:00, 25.95it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 117.25729: 100%|██████████| 19808/19808 [12:43<00:00, 25.93it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 107.69641: 100%|██████████| 19808/19808 [12:44<00:00, 25.91it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 99.69949: 100%|██████████| 19808/19808 [12:38<00:00, 26.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["loss: 93.62684: 100%|██████████| 19808/19808 [12:36<00:00, 26.19it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 6\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 88.45378: 100%|██████████| 19808/19808 [12:30<00:00, 26.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 7\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 83.83138: 100%|██████████| 19808/19808 [12:31<00:00, 26.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 8\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 79.44307: 100%|██████████| 19808/19808 [12:42<00:00, 25.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 9\n"]},{"output_type":"stream","name":"stderr","text":["loss: 75.41531: 100%|██████████| 19808/19808 [12:55<00:00, 25.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 10\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 71.89664: 100%|██████████| 19808/19808 [12:46<00:00, 25.86it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 11\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 68.78511: 100%|██████████| 19808/19808 [12:37<00:00, 26.15it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 12\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 65.92583: 100%|██████████| 19808/19808 [12:34<00:00, 26.24it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 13\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 63.23921: 100%|██████████| 19808/19808 [12:34<00:00, 26.25it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 14\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 60.70239: 100%|██████████| 19808/19808 [12:35<00:00, 26.23it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 15\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 58.30499: 100%|██████████| 19808/19808 [12:38<00:00, 26.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 16\n"]},{"output_type":"stream","name":"stderr","text":["loss: 56.03010: 100%|██████████| 19808/19808 [12:39<00:00, 26.09it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 17\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 53.86738: 100%|██████████| 19808/19808 [12:58<00:00, 25.44it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 18\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 51.91578:  91%|█████████ | 18071/19808 [11:38<01:06, 26.24it/s]"]}],"source":["model.train()\n","for epoch in range(20):\n","    print(\"\\nStarting epoch {}\".format(epoch+1))   \n","    total = 0\n","    running_loss = 0.0\n","    loader = tqdm(enumerate(train_loader), total=len(train_loader))\n","    for i, data in loader:\n","        pos_u_in, pos_v_in, neg_v_in = data\n","        pos_u_in, pos_v_in, neg_v_in = pos_u_in.to(device).long(), pos_v_in.to(device).long(), neg_v_in.to(device).long()\n","        optimizer.zero_grad()\n","        loss = model(pos_u_in, pos_v_in, neg_v_in)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","        total += 1\n","        loader.set_description(\"loss: {:.5f}\".format(running_loss/total))\n","\n","print('Finished Training')"]},{"cell_type":"code","source":["dataset.shuffle_indexhhhmmmmmmmm"],"metadata":{"id":"2e1s5LP_snKW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4819,"status":"ok","timestamp":1664124180977,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"},"user_tz":-420},"id":"03jTxy9KyBrp","outputId":"721ba593-8d9f-4bf9-8142-cda536edd4d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pickle\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["pickle.dump(model,open('/content/drive/MyDrive/NLP/w2v_300dim_negloss.p','wb'))"],"metadata":{"id":"S0utHR8lVgF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaiPTPhI1cuJ"},"outputs":[],"source":["model_load = pickle.load(open('/content/drive/MyDrive/NLP/w2v_300dim_negloss.p','rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbXVSXiD2Efi"},"outputs":[],"source":["model_load.embedding(torch.tensor([1,2]).to(device))"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1mQAurto3EVGoG1RP2XU7I624AXaacgmx","timestamp":1660668415917},{"file_id":"1D1w4S3z06bVH05AqJwBa9aFf5CzcDiK4","timestamp":1660548913907}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}