{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObnkmPfTI6eAGeo7ISRenY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.models import resnet50, ResNet50_Weights\n","\n","import numpy as np\n","from tensorflow import keras\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import cv2\n","import os"],"metadata":{"id":"Uqt6wbmlF0q4","executionInfo":{"status":"ok","timestamp":1663628263522,"user_tz":-420,"elapsed":10640,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Hyper-parameter\n","hidden_size = 64\n","num_classes = 5\n","num_epochs = 10\n","batch_size = 50\n","learning_rate = 0.001\n","\n","input_size = 300\n","sequence_length = 30\n","num_layers = 2\n","img_size = 224"],"metadata":{"id":"AFNSuhzn_piz","executionInfo":{"status":"ok","timestamp":1663628263522,"user_tz":-420,"elapsed":12,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!wget -q https://git.io/JGc31 -O ucf101_top5.tar.gz\n","!tar xf ucf101_top5.tar.gz"],"metadata":{"id":"D4XQge6lgaEM","executionInfo":{"status":"ok","timestamp":1663628270586,"user_tz":-420,"elapsed":7075,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv(\"train.csv\")\n","test_df = pd.read_csv(\"test.csv\")\n","\n","print(f\"Total videos for training: {len(train_df)}\")\n","print(f\"Total videos for testing: {len(test_df)}\")\n","\n","train_df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"gFWII6nRgla5","executionInfo":{"status":"ok","timestamp":1663628270587,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"87c7374a-8eec-4695-846e-48bfe5f4f324"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Total videos for training: 594\n","Total videos for testing: 224\n"]},{"output_type":"execute_result","data":{"text/plain":["                     video_name           tag\n","411  v_ShavingBeard_g16_c03.avi  ShavingBeard\n","503   v_TennisSwing_g11_c07.avi   TennisSwing\n","401  v_ShavingBeard_g14_c06.avi  ShavingBeard\n","468  v_ShavingBeard_g24_c05.avi  ShavingBeard\n","218  v_PlayingCello_g23_c02.avi  PlayingCello\n","439  v_ShavingBeard_g20_c04.avi  ShavingBeard\n","207  v_PlayingCello_g21_c03.avi  PlayingCello\n","151  v_PlayingCello_g12_c07.avi  PlayingCello\n","316         v_Punch_g19_c04.avi         Punch\n","442  v_ShavingBeard_g20_c07.avi  ShavingBeard"],"text/html":["\n","  <div id=\"df-a49d7d31-7121-4a86-ae7e-7018ec92b2cd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>video_name</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>411</th>\n","      <td>v_ShavingBeard_g16_c03.avi</td>\n","      <td>ShavingBeard</td>\n","    </tr>\n","    <tr>\n","      <th>503</th>\n","      <td>v_TennisSwing_g11_c07.avi</td>\n","      <td>TennisSwing</td>\n","    </tr>\n","    <tr>\n","      <th>401</th>\n","      <td>v_ShavingBeard_g14_c06.avi</td>\n","      <td>ShavingBeard</td>\n","    </tr>\n","    <tr>\n","      <th>468</th>\n","      <td>v_ShavingBeard_g24_c05.avi</td>\n","      <td>ShavingBeard</td>\n","    </tr>\n","    <tr>\n","      <th>218</th>\n","      <td>v_PlayingCello_g23_c02.avi</td>\n","      <td>PlayingCello</td>\n","    </tr>\n","    <tr>\n","      <th>439</th>\n","      <td>v_ShavingBeard_g20_c04.avi</td>\n","      <td>ShavingBeard</td>\n","    </tr>\n","    <tr>\n","      <th>207</th>\n","      <td>v_PlayingCello_g21_c03.avi</td>\n","      <td>PlayingCello</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>v_PlayingCello_g12_c07.avi</td>\n","      <td>PlayingCello</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>v_Punch_g19_c04.avi</td>\n","      <td>Punch</td>\n","    </tr>\n","    <tr>\n","      <th>442</th>\n","      <td>v_ShavingBeard_g20_c07.avi</td>\n","      <td>ShavingBeard</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a49d7d31-7121-4a86-ae7e-7018ec92b2cd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a49d7d31-7121-4a86-ae7e-7018ec92b2cd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a49d7d31-7121-4a86-ae7e-7018ec92b2cd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["def crop_center_square(frame):\n","    y, x = frame.shape[0:2]\n","    min_dim = min(y, x)\n","    start_x = (x // 2) - (min_dim // 2)\n","    start_y = (y // 2) - (min_dim // 2)\n","    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n","\n","\n","def load_video(path, max_frames=0, resize=(img_size, img_size)):\n","    cap = cv2.VideoCapture(path)\n","    frames = []\n","    try:\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame = crop_center_square(frame)\n","            frame = cv2.resize(frame, resize)\n","            frame = frame[:, :, [2, 1, 0]]\n","            frames.append(frame)\n","\n","            if len(frames) == max_frames:\n","                break\n","    finally:\n","        cap.release()\n","    return np.array(frames)"],"metadata":{"id":"Pv38F4lJikE6","executionInfo":{"status":"ok","timestamp":1663628270587,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["label_processor = keras.layers.StringLookup(\n","    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",")\n","print(label_processor.get_vocabulary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPt1GG83kH3o","executionInfo":{"status":"ok","timestamp":1663628273545,"user_tz":-420,"elapsed":2962,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"1e62cd10-91cd-4af5-ca64-812effc2ef21"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['CricketShot', 'PlayingCello', 'Punch', 'ShavingBeard', 'TennisSwing']\n"]}]},{"cell_type":"code","source":["def prepare_all_videos(df, root_dir):\n","    num_samples = len(df)\n","    video_paths = df[\"video_name\"].values.tolist()\n","    labels = df[\"tag\"].values\n","    labels = label_processor(labels[..., None]).numpy()\n","\n","    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n","    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n","    # masked with padding or not.\n","    #frame_masks = np.zeros(shape=(num_samples, sequence_length), dtype=\"bool\")\n","    frame_length = np.zeros(num_samples)\n","    frame_features = np.zeros(\n","        shape=(num_samples, sequence_length, 3, img_size, img_size), dtype=\"uint8\"\n","    )\n","\n","    # For each video.\n","    for idx, path in tqdm(enumerate(video_paths), total=len(video_paths)):\n","        # Gather all its frames and add a batch dimension.\n","        frames = load_video(os.path.join(root_dir, path))\n","        frames = frames[None, ...]\n","\n","        # Initialize placeholders to store the masks and features of the current video.\n","        temp_frame_mask = np.zeros(shape=(1, sequence_length,), dtype=\"bool\")\n","        temp_frame_features = np.zeros(\n","            shape=(1, sequence_length, 3, img_size, img_size), dtype=\"uint8\"\n","        )\n","\n","        # Extract features from the frames of the current video.\n","        for i, batch in enumerate(frames):\n","            video_length = batch.shape[0]\n","            if video_length < sequence_length:\n","              print('chuy')\n","            length = min(sequence_length, video_length)\n","            # for j in range(length):\n","            #     temp_frame_features[i, j, :] = cnn_net(preprocess(torch.tensor(batch[None, j, :].transpose(0,3,1,2)))).detach().numpy()\n","            temp_frame_features[i, 0:length, :] = np.concatenate([batch[None, ii, :].transpose(0,3,1,2) for ii in range(length)],0)\n","            #temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n","\n","        frame_features[idx,] = temp_frame_features.squeeze()\n","        frame_length[idx] = length\n","    return (frame_features, frame_length), labels\n","\n","train_data, train_labels = prepare_all_videos(train_df, \"train\")\n","test_data, test_labels = prepare_all_videos(test_df, \"test\")\n","\n","print(f\"Frame features in train set: {train_data[0].shape}\")\n","print(f\"Frame length in train set: {train_data[1].shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kwmvx6dwik7S","outputId":"7d8ac172-8976-44de-eeb6-aa08b7edb5e1","executionInfo":{"status":"ok","timestamp":1663628424939,"user_tz":-420,"elapsed":151404,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 594/594 [01:53<00:00,  5.24it/s]\n","100%|██████████| 224/224 [00:35<00:00,  6.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Frame features in train set: (594, 30, 3, 224, 224)\n","Frame length in train set: (594,)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","  def __init__(self, x, y, z):\n","    self.data = x\n","    self.labels = y\n","    self.lengths = z\n","\n","  def __len__(self):\n","    return len(self.labels)\n","  \n","  def __getitem__(self, index):\n","    return self.data[index], self.labels[index], self.lengths[index]"],"metadata":{"id":"ABk3b59M6lb2","executionInfo":{"status":"ok","timestamp":1663628435415,"user_tz":-420,"elapsed":375,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_dataset = MyDataset(train_data[0],train_labels,train_data[1])\n","test_dataset = MyDataset(test_data[0],test_labels,train_data[1])"],"metadata":{"id":"rXqZlfiB6qEu","executionInfo":{"status":"ok","timestamp":1663628438866,"user_tz":-420,"elapsed":360,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"],"metadata":{"id":"e3kxGS8evjcH","executionInfo":{"status":"ok","timestamp":1663628440009,"user_tz":-420,"elapsed":2,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"tSF-872jFEL2","executionInfo":{"status":"ok","timestamp":1663628447004,"user_tz":-420,"elapsed":4949,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}}},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","class CNNLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(CNNLSTM, self).__init__()\n","\n","        self.weights = ResNet50_Weights.DEFAULT\n","        self.preprocess = self.weights.transforms()\n","        self.pretrained_cnn = resnet50(weights=self.weights)\n","\n","        #self.resnet.fc = nn.Sequential(nn.Linear(self.resnet.fc.in_features, 300))\n","        self.pretrained_cnn.fc = nn.Linear(self.pretrained_cnn.fc.in_features, input_size)\n","\n","        self.num_layers =  num_layers\n","        self.hidden_size = hidden_size\n","\n","\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","\n","        # x -> (batch_size, sequence_length, input_size) because batch_size = true\n","        self.fc1 = nn.Linear(hidden_size, 32)\n","        self.fc2 = nn.Linear(32, num_classes)\n","        self.dropout = nn.Dropout(0.40)\n","\n","    def forward(self, x):\n","        hidden = None\n","        for i in range(x.size(1)):\n","            with torch.no_grad():\n","                out = self.pretrained_cnn(self.preprocess(x[:,i,:,:,:]))\n","            out, hidden = self.lstm(out.unsqueeze(1), hidden)\n","        \n","        # out -> (batch_size, sequence_length, hidden_size) because batch_size = true\n","        out = out[:, -1, :] # only the last time step\n","\n","        out = F.relu(self.fc1(out))\n","        out = self.fc2(self.dropout(out))\n","\n","        return out\n","\n","net = CNNLSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.5)"]},{"cell_type":"code","source":["#net = net.float()\n","net.train()\n","for epoch in range(num_epochs):  # loop over the dataset multiple times\n","    print(\"\\nStarting epoch {}\".format(epoch+1))\n","    \n","    total = 0\n","    running_loss = 0.0\n","\n","    # to make a beautiful progress bar\n","    loader = tqdm(enumerate(train_loader), total=len(train_loader))\n","    for i, data in loader:\n","        # get the data points\n","        inputs, labels,_ = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # zero the parameter gradients (else, they are accumulated)\n","        optimizer.zero_grad()\n","\n","        # forward the data through the network\n","        outputs = net(inputs)\n","        # calculate the loss given the output of the network and the target labels\n","        loss = criterion(outputs, labels.squeeze())\n","        # calculate the gradients of the network w.r.t. its parameters\n","        loss.backward()\n","        # Let the optimiser take an optimization step using the calculated gradients\n","        optimizer.step()\n","        \n","        running_loss += loss\n","        total += outputs.size(0)\n","\n","        loader.set_description(\"loss: {:.5f}\".format(running_loss/total))\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-N7T5viYqB8m","executionInfo":{"status":"ok","timestamp":1663629051270,"user_tz":-420,"elapsed":601021,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"d6c2b3f2-1ab5-4db9-eab6-0aae64865d23"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["loss: 0.03233: 100%|██████████| 12/12 [00:59<00:00,  4.94s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.02950: 100%|██████████| 12/12 [00:56<00:00,  4.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.02331: 100%|██████████| 12/12 [00:57<00:00,  4.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.01668: 100%|██████████| 12/12 [00:59<00:00,  4.92s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.01104: 100%|██████████| 12/12 [00:59<00:00,  4.98s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 6\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.00751: 100%|██████████| 12/12 [01:00<00:00,  5.05s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 7\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.00548: 100%|██████████| 12/12 [01:01<00:00,  5.08s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 8\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.00358: 100%|██████████| 12/12 [01:01<00:00,  5.12s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 9\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.00271: 100%|██████████| 12/12 [01:01<00:00,  5.14s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Starting epoch 10\n"]},{"output_type":"stream","name":"stderr","text":["\n","loss: 0.00182: 100%|██████████| 12/12 [01:01<00:00,  5.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Finished Training\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["net.eval()\n","class Accuracy:\n","    \"\"\"A class to keep track of the accuracy while training\"\"\"\n","    def __init__(self):\n","        self.correct = 0\n","        self.total = 0\n","        \n","    def reset(self):\n","        \"\"\"Resets the internal state\"\"\"\n","        self.correct = 0\n","        self.total = 0\n","        \n","    def update(self, output, labels):\n","        \"\"\"\n","        Updates the internal state to later compute the overall accuracy\n","        \n","        output: the output of the network for a batch\n","        labels: the target labels\n","        \"\"\"\n","        _, predicted = torch.max(output.data, 1) # predicted now contains the predicted class index/label\n","        \n","        self.total += labels.size(0)\n","        self.correct += (predicted == labels).sum().item() # .item() gets the number, not the tensor\n","\n","    def compute(self):\n","        return self.correct/self.total\n","\n","accuracy = Accuracy()\n","\n","accuracy.reset()\n","# Gradients are calculated on the forward pass for every iteration.\n","# As we do not need gradients now, we can disable the calculation.\n","with torch.no_grad():\n","    for data in tqdm(train_loader):\n","        # get the data points\n","        inputs, labels,_ = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # forward the data through the network\n","        outputs = net(inputs)\n","        \n","        accuracy.update(outputs, labels.squeeze())\n","\n","print(\"Training Accuracy: {:.2f}%\".format(100 * accuracy.compute()))\n","\n","accuracy.reset()        \n","with torch.no_grad():\n","    for data in tqdm(val_loader):\n","        # get the data points\n","        inputs, labels,_ = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # forward the data through the network\n","        outputs = net(inputs)\n","        \n","        accuracy.update(outputs, labels.squeeze())\n","        \n","print(\"\\nTesting Accuracy: {:.2f}%\".format(100 * accuracy.compute()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHdbki8zI2nQ","executionInfo":{"status":"ok","timestamp":1663629256136,"user_tz":-420,"elapsed":72743,"user":{"displayName":"Sơn Lam Nguyễn Đặng","userId":"11953831021002530128"}},"outputId":"56a9b033-c96c-4fed-e248-2a7d9562ae63"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 12/12 [00:52<00:00,  4.34s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Training Accuracy: 99.49%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:20<00:00,  4.12s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Testing Accuracy: 88.84%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}